"""Neural net model"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.resnet.ipynb.

# %% auto 0
__all__ = ['logger', 'ResBlock', 'ResNet', 'ResNetX']

# %% ../../nbs/models.resnet.ipynb 3
import torch.nn as nn

import torch
from torchinfo import summary
from torchvision.transforms import transforms


from omegaconf import OmegaConf
from hydra.utils import instantiate

from matplotlib import pyplot as plt
import math

from .conv import ConvLayer
from .core import Classifier
from ..utils import get_device, set_seed
from ..image.datasets import ImageDataModule

from typing import List, Optional, Callable, Any
import logging
from functools import partial


# %% ../../nbs/models.resnet.ipynb 4
logger = logging.getLogger(__name__)
set_seed()

# %% ../../nbs/models.resnet.ipynb 6
class ResBlock(nn.Module):
    def __init__(
            self,
            n_channels:int # Number of input & output channels
        ):

        super().__init__()

        layers = []
        conv_ = partial(ConvLayer, stride=1)
        layers += [conv_(n_channels, n_channels), conv_(n_channels, n_channels)]
        self.nnet = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x + self.nnet(x)

# %% ../../nbs/models.resnet.ipynb 10
class ResNet(nn.Module):
    def __init__(
            self,
            n_features: List[int]=[1, 8, 16, 32, 16], # Number of input & output channels
            num_classes: int=10, # Number of classes
        ):

        super().__init__()
        logger.info("ResNet: init")
        layers = []
        conv_ = partial(ConvLayer, stride=2, normalization=nn.BatchNorm2d, activation=nn.ReLU)

        # c.f. convnet with resblock between
        layers.append(conv_(in_channels=n_features[0], out_channels=n_features[1], stride=1))
        # layers.append(ResBlock(n_features[1]))
        for i in range(1, len(n_features)-1):
            layers += [conv_(in_channels=n_features[i], out_channels=n_features[i+1])]
            layers += [ResBlock(n_features[i+1])]

        # last layer back to n_classes and flatten
        layers.append(conv_(in_channels=n_features[-1], out_channels=num_classes))
        layers.append(nn.Flatten())
        self.layers = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.layers(x)

# %% ../../nbs/models.resnet.ipynb 13
class ResNetX(Classifier):
    def __init__(
        self,
        nnet:ResNet,
        num_classes:int,
        optimizer:Callable[...,torch.optim.Optimizer], # optimizer,
        scheduler: Optional[Callable[...,Any]]=None, # scheduler
        ):
        
        logger.info("ResNetX: init")
        super().__init__(
            nnet=nnet,
            num_classes=num_classes,
            optimizer=optimizer,
            scheduler=scheduler
            )

    def _step(self, batch, batch_idx):
        x, y = batch
        y_hat = self.forward(x)
        loss = self.loss(y_hat, y)
        preds = y_hat.argmax(dim=1)
        return loss, preds, y
    
    def predict_step(self, batch, batch_idx, dataloader_idx=0):
        x, y = batch
        y_hat = self.forward(x)
        return y_hat.argmax(dim=1)
