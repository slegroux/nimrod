"""Neural net model"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.resnet.ipynb.

# %% auto 0
__all__ = ['logger', 'ResBlock', 'ResNet', 'ResBlock2', 'ResNet2', 'UpSample', 'SuperResNet']

# %% ../../nbs/models.resnet.ipynb 3
import torch.nn as nn
import torch.nn.functional as F
import torch
from torch_lr_finder import LRFinder
from torchinfo import summary
from torchviz import make_dot
from torchvision.transforms import transforms


from omegaconf import OmegaConf
from hydra.utils import instantiate

from matplotlib import pyplot as plt
import math

from .conv import ConvLayer
from .core import Classifier
from ..utils import get_device, set_seed
from ..image.datasets import ImageDataModule

from typing import List
import logging
from functools import partial


# %% ../../nbs/models.resnet.ipynb 4
logger = logging.getLogger(__name__)
set_seed()

# %% ../../nbs/models.resnet.ipynb 6
class ResBlock(nn.Module):
    def __init__(
            self,
            n_channels: int=3 # Number of input & output channels
        ):

        super().__init__()

        layers = []
        conv = partial(ConvLayer, n_channels, n_channels, stride=1, normalization=nn.BatchNorm2d)
        layers += [conv(activation=nn.ReLU), conv(activation=None)]
        self.layers = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x + self.layers(x)

# %% ../../nbs/models.resnet.ipynb 10
class ResNet(nn.Module):
    def __init__(
            self,
            n_channels: List[int]=[1, 8, 16, 32,16], # Number of input & output channels
            n_classes: int=10, # Number of classes
        ):

        super().__init__()

        layers = []
        conv = partial(ConvLayer, stride=2, normalization=nn.BatchNorm2d, activation=nn.ReLU)
        # convnet with resblock between
        for i in range(len(n_channels)-1):
            layers += [conv(n_channels[i], n_channels[i+1])]
            layers += [ResBlock(n_channels[i+1])]

        # last layer back to n_classes and flatten
        layers.append(conv(n_channels[-1], n_classes))
        layers.append(nn.Flatten())
        self.layers = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.layers(x)

# %% ../../nbs/models.resnet.ipynb 18
class ResBlock2(nn.Module):
    """ResNet basic block with optional downsampling.
    This block implements the basic building block of ResNet architecture,
    consisting of two convolutional layers with a residual connection.
    The block can optionally downsample the input using strided convolution
    and average pooling.

    Parameters
    ----------
    in_channels : int
        Number of input channels
    out_channels : int
        Number of output channels
    stride : int, optional
        Stride for the second convolution and pooling, by default 1
    kernel_size : int, optional
        Kernel size for the convolutions, by default 3
    
    Notes
    -----
    The block performs the following operations:
    1. First convolution with kernel_size and stride=1
    2. Second convolution with kernel_size and specified stride
    3. Identity/1x1 conv on residual path depending on channel dimensions
    4. Average pooling on residual path if stride > 1
    5. ReLU activation after element-wise addition
    The output dimensions are determined by the stride parameter:
    - If stride=1: output has same spatial dimensions as input
    - If stride=2: output spatial dimensions are halved
    """


    def __init__(
            self,
            in_channels: int, # Number of input channels
            out_channels: int, # Number of output channels
            stride: int = 1, # Stride for the second convolution and pooling
            kernel_size:int = 3 # Kernel size for the convolutions
            ):
        
        super().__init__()

        conv_ = nn.ModuleList()
        conv_.append(ConvLayer(in_channels, out_channels, stride=1, kernel_size=kernel_size))
        conv_.append(ConvLayer(out_channels, out_channels, stride=stride, activation=None))
        self.conv = nn.Sequential(*conv_)


        if in_channels == out_channels:
            self.id = nn.Identity()
        else:
            self.id = ConvLayer(in_channels, out_channels, stride=1, kernel_size=1, activation=None)

        if stride == 1:
            self.pool = nn.Identity()
        else:
            self.pool = nn.AvgPool2d(2, ceil_mode=True)
        self.act = nn.ReLU()
        
    def forward(self, x):
        return self.act(self.conv(x) + self.id(self.pool(x)))

# %% ../../nbs/models.resnet.ipynb 23
class ResNet2(nn.Module):
    """A simple implementation of a ResNet-like neural network.

    Parameters
    ----------
    n_features : List[int], optional
        A list of integers representing the number of features (channels) at each layer. 
        Default is [1, 8, 16, 32, 64, 128, 256].
    num_classes : int, optional
        The number of output classes. Default is 10.
    """

    def __init__(
            self,
            n_features:List[int]=[1, 8, 16, 32, 64, 128, 256], # channel/feature expansion
            num_classes:int=10, # num_classes
        ):

        super().__init__()

        layers = nn.ModuleList()
        layers.append(ResBlock2(n_features[0], n_features[1], stride=1))

        for i in range(1, len(n_features)-1):
            res = ResBlock2(n_features[i], n_features[i+1], stride=2)
            layers.append(res)

        layers += [nn.Flatten(), nn.Linear(n_features[-1], num_classes, bias=False), nn.BatchNorm1d(num_classes)]


        self.nnet = nn.Sequential(*layers)

    def forward(self, x:torch.Tensor)->torch.Tensor:
        return self.nnet(x)


# %% ../../nbs/models.resnet.ipynb 32
class UpSample(nn.Module):
    def __init__(
            self,
            in_channels:int, # Number of input channels
            out_channels:int, # Number of output channels
            scale:int=2, # Scale factor for upsampling
    ):
    
        super().__init__()
        layers = []
        for i in range(int(math.log(scale, 2))):
            layers += [ConvLayer(in_channels, out_channels*4, stride=1, normalization=None, activation=None),nn.PixelShuffle(2)]
        
        self.layers = nn.Sequential(*layers)               


    def forward(self, x:torch.Tensor)->torch.Tensor:
        return self.layers(x)

# %% ../../nbs/models.resnet.ipynb 37
class SuperResNet(nn.Module):
    def __init__(
            self,
            in_channels:int=3, # Number of input channels
            out_channels:int=64, # Number of output channels
            depth:int=8, # Number of residual blocks
            scale:int=2 # Upsampling factor
            ):
        super().__init__()
        layers = []
        conv = partial(ConvLayer, stride=1, normalization=None, activation=None)
        layers.append(conv(in_channels, out_channels))
        for i in range(depth):
            layers.append(ResBlock(out_channels)) 
        layers.append(conv(out_channels, out_channels))
        layers.append(UpSample(out_channels, out_channels, scale))
        layers.append(nn.BatchNorm2d(out_channels))
        layers.append(conv(out_channels, in_channels))

        self.layers = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.layers(x)
