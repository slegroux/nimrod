"""Collection of Autoencoder models"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.autoencoders.ipynb.

# %% auto 0
__all__ = ['logger', 'AutoEncoder']

# %% ../../nbs/models.autoencoders.ipynb 4
import torch.nn as nn
import torch
from torch.utils.data import DataLoader
from lightning import LightningModule, Trainer
from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger
from lightning.pytorch.tuner.tuning import Tuner
from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint

from hydra.utils import instantiate
from omegaconf import OmegaConf
from pprint import pprint

from matplotlib import pyplot as plt
import pandas as pd

from ..image.datasets import ImageDataset
from .conv import ConvLayer, DeconvLayer
from ..utils import time_it, set_seed, get_device

import logging
import warnings

# %% ../../nbs/models.autoencoders.ipynb 5
set_seed(42)
logger = logging.getLogger(__name__)
# logger.setLevel(logging.DEBUG)
plt.set_loglevel('INFO')
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# %% ../../nbs/models.autoencoders.ipynb 21
class AutoEncoder(nn.Module):
    """ A modular autoencoder with configurable encoder and decoder """
    def __init__(self,
        encoder:nn.Module, # Encoder layer
        decoder:nn.Module # Decoder layer
        ):

        super().__init__()
        self.encoder = encoder
        self.decoder = decoder
    
    def forward(
        self,
        x:torch.Tensor # Tensor B x C X H X W
        )->torch.Tensor: # Reconstructed input tensor of shape B x C X H X W

        """
        Forward pass of the AutoEncoder model.
        """

        z = self.encoder(x)
        x_hat = self.decoder(z)
        return x_hat
