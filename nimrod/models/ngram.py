# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.ngram.ipynb.

# %% auto 0
__all__ = ['CharUnigram', 'KenLM']

# %% ../../nbs/models.ngram.ipynb 4
import torch.nn as nn
import torch
import torch.nn.functional as F

from matplotlib import pyplot as plt
import pandas as pd
import numpy as np

from typing import Dict, List, Tuple, Optional, Set
from collections import Counter

import kenlm


# %% ../../nbs/models.ngram.ipynb 7
class CharUnigram:
    def __init__(self, data:List[str]):
        self._count = {}
        self.total_count = 0
        self.unique_chars = set()
        for name in data:
            for c in name:
                self.unique_chars.update(c)
                if c in self._count:
                    self._count[c] += 1
                else:
                    self._count[c] = 1
                self.total_count += 1
        self._probs = {k:v/self.total_count for k,v in self._count.items()}
        self._count = self.sort_dict_by_value(self._count)
        self._probs = self.sort_dict_by_value(self._probs)
        self.unique_chars = sorted(self.unique_chars)
        self._stoi = {v:idx for idx,v in enumerate(self.unique_chars)}
        self._itos = {idx:v for idx,v in enumerate(self.unique_chars)}
        
    def __len__(self):
        return len(self.unique_chars)
    
    @staticmethod
    def sort_dict_by_value(dict:Dict, reverse:bool=True)->Dict:
        return {k:v for k,v in sorted(dict.items(), reverse=reverse, key=lambda x:x[1])}

    @property
    def counts(self)->Dict:
        return(self._count)

    @property
    def probs(self)->Dict:
        return(self._probs)

    @property
    def chars(self)->List:
        return self.unique_chars
        
    def stoi(self, char:str)->int:
        return(self._stoi[char])
    
    def itos(self, idx:int)->str:
        return(self._itos[idx])
    
    def sample(self)->str:
        # get probs for order list of characters to build prob table
        prob_distrib = torch.tensor([self._probs[k] for k in self.unique_chars])
        idx = int(torch.multinomial(prob_distrib,num_samples=1,replacement=True))
        return(self._itos[idx])
        

# %% ../../nbs/models.ngram.ipynb 45
class KenLM:
    def __init__(self, arpa_path:str, vocab:List):
        # TODO: deal with zipped arpa models
        self.model = kenlm.LanguageModel(arpa_path)
        self.partial_text = []
        self.partial_score = 0.0
        # init new sentence
        self.s1 = kenlm.State()
        self.s2 = kenlm.State()
        self.model.BeginSentenceWrite(self.s1)
        self.vocab = vocab

    def init_vocab(self, vocab_path):
        with open(vocab_path) as f: self.vocab = f.read().splitlines()
    
    def new_sentence_init(self):
        self.partial_text = []
        self.partial_score = 0.0
        self.s1 = kenlm.State()
        self.s2 = kenlm.State()
        self.model.BeginSentenceWrite(self.s1)
    
    def append(self, word:str):
        # add word to beam and update probs
        if word == '.':
            self.partial_score += self.model.BaseScore(self.s1, word, self.s2)
            self.partial_score += self.model.BaseScore(self.s2, '</s>', self.s1)
            self.partial_text.append(word)
        else:
            self.partial_score += self.model.BaseScore(self.s1, word, self.s2)
            # input <=> output state
            self.s1, self.s2 = self.s2, self.s1
            self.partial_text.append(word)
    
    def peek(self, word:str, log_prob:bool=True)->float:
        if log_prob:
            # check prob of next word given context without update state
            res = self.partial_score+self.model.BaseScore(self.s1, word, self.s2)
        else:
            res = 10**(self.partial_score+self.model.BaseScore(self.s1, word, self.s2))
        return(res)

    def sentence_score(self, sentence:str)->float:
        return(self.model.score(sentence))

    def partial_sentence_score(self, sentence:str)->float:
        return(self.model.score(sentence, eos=False))
        
    def nbest(self, n:int, log_prob:bool=True):
        if not self.vocab:
            print('need to init vocab')
        res = []
        for word in self.vocab:
            res.append((word, self.peek(word, log_prob)))

        return sorted(res, key=lambda x: x[1], reverse=True)[:n]

    @property
    def score(self)->float:
        return(self.partial_score)

    @property
    def text(self)->str:
        return(' '.join(self.partial_text))
    
