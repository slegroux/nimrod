# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.conv.ipynb.

# %% auto 0
__all__ = ['ConvLayer', 'ConvNet', 'ConvNetX']

# %% ../../nbs/models.conv.ipynb 3
import torch.nn as nn
import torch
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST

from pytorch_lightning import LightningModule, Trainer
from torchmetrics import Accuracy
from hydra.utils import instantiate
from omegaconf import OmegaConf

from ..image.datasets import MNISTDataModule
from ..utils import get_device, logger
from ..core import Classifier

# %% ../../nbs/models.conv.ipynb 6
class ConvLayer(nn.Module):
    def __init__(self,
                in_channels:int=3, # input channels
                out_channels:int=16, # output channels
                kernel_size:int=3, # kernel size
                activation:bool=True
                ):

        super().__init__()
        self.activation = activation
        # use stride 2 for downsampling instead of max or average pooling with stride 1
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, 2, kernel_size//2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        if self.activation:
            x = self.relu(x)
        return x

# %% ../../nbs/models.conv.ipynb 10
class ConvNet(nn.Module):
    def __init__(self, in_channels:int=1, out_channels:int=10):
        super().__init__()
        self.net = nn.Sequential(
            ConvLayer(in_channels, 8, kernel_size=5), #14x14
            nn.BatchNorm2d(8),
            ConvLayer(8, 16), #7x7
            nn.BatchNorm2d(16),
            ConvLayer(16, 32), #4x4
            nn.BatchNorm2d(32),
            ConvLayer(32, 64), #2x2
            nn.BatchNorm2d(64),
            ConvLayer(64, 10, activation=False), #1x1
            nn.BatchNorm2d(10),
            nn.Flatten()

        )

    def forward(self, x:torch.Tensor # input image tensor of dimension (B, C, W, H)
                ) -> torch.Tensor: # output probs (B, N_classes)

        return self.net(x)

# %% ../../nbs/models.conv.ipynb 26
class ConvNetX(Classifier, ConvNet, LightningModule):
    def __init__(self, in_channels:int=1, out_channels:int=10, lr:float=1e-3):
        logger.info("ConvNetX init: in_channels: {}, out_channels: {}".format(in_channels, out_channels))
        super().__init__(in_channels=in_channels, out_channels=out_channels, lr=lr)
    
    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optimizer
    
    def _step(self, batch, batch_idx):
        x, y = batch
        y_hat = self.forward(x)
        loss = self.loss(y_hat, y)
        acc = self.accuracy(y_hat, y)
        return loss, acc
    
    def predict_step(self, batch, batch_idx, dataloader_idx=0):
        x, y = batch
        y_hat = self.forward(x)
        return y_hat.argmax(dim=1)
