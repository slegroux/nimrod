# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.conv.ipynb.

# %% auto 0
__all__ = ['logger', 'ConvLayer', 'ConvNet', 'ConvNetX']

# %% ../../nbs/models.conv.ipynb 3
import torch.nn as nn
import torch

from lightning import LightningModule, Trainer
from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger
from lightning.pytorch.tuner.tuning import Tuner
from lightning.pytorch.callbacks import LearningRateMonitor

from torch_lr_finder import LRFinder

from hydra.utils import instantiate
from omegaconf import OmegaConf

from matplotlib import pyplot as plt
import pandas as pd
from typing import List, Optional, Type

from ..utils import get_device
from .core import Classifier

import logging
logger = logging.getLogger(__name__)

# %% ../../nbs/models.conv.ipynb 6
class ConvLayer(nn.Module):
    """A 2D convolutional layer with optional batch normalization and activation.

    This layer performs 2D convolution with stride 2 for downsampling, optionally followed by
    batch normalization and activation.

    Parameters
    ----------
    in_channels : int, default=3
        Number of input channels
    out_channels : int, default=16 
        Number of output channels / number of features
    kernel_size : int, default=3
        Size of the convolving kernel
    bias : bool, default=True
        If True, adds a learnable bias to the convolution
    normalization : nn.Module, default=nn.BatchNorm2d
        Normalization layer to use after convolution
    activation : nn.Module, default=nn.ReLU
        Activation function to use after normalization

    Notes
    -----
    When using batch normalization, the convolution bias is automatically disabled
    since it would be redundant.

    The spatial dimensions are reduced by half due to stride=2 convolution:
    output_size = input_size/2
    """
  
    def __init__(
        self,
        in_channels:int=3, # input channels
        out_channels:int=16, # output channels
        kernel_size:int=3, # kernel size
        bias:bool=True,
        normalization:Optional[Type[nn.Module]]=nn.BatchNorm2d,
        activation:Optional[Type[nn.Module]]=nn.ReLU,
        
    ):

        super().__init__()
        
        if bias and normalization and issubclass(normalization, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):
            logger.warning('setting conv bias to False as Batchnorm is used')
            # https://x.com/karpathy/status/1013245864570073090
            bias = None

        # use stride 2 for downsampling to (W/2, H/2) instead of max or average pooling with stride 1
        conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=2, padding=kernel_size//2, bias=bias)
        layers = [conv]
        if normalization:
            if issubclass(normalization,  (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):
                layers.append(normalization(out_channels))
        if activation: layers.append(activation())
        self.net = nn.Sequential(*layers)

    def forward(self, x:torch.Tensor # input image tensor of dimension (B, C, W, H)
                ) -> torch.Tensor: # output image tensor of dimension (B, C, W/2, H/2)
        return self.net(x)


# %% ../../nbs/models.conv.ipynb 13
class ConvNet(nn.Module):

    def __init__(
            self,
            n_features:List[int]=[1, 8, 16, 32, 64], # channel/feature expansion
            num_classes:int=10, # num_classes
            kernel_size:int=3, # kernel size
            bias:bool=False, # conv2d bias
            normalization:nn.Module=nn.BatchNorm2d, # normalization (before activation)
            activation:nn.Module=nn.ReLU, # activation function
        ):

        super().__init__()

        net = nn.ModuleList()
        for i in range(len(n_features) - 1):
            conv = ConvLayer(
                    in_channels=n_features[i],
                    out_channels=n_features[i+1],
                    kernel_size=kernel_size,
                    bias=bias,
                    normalization=normalization,
                    activation=activation
            )
            net.append(conv)
       
        net.append(
            ConvLayer(
                in_channels=n_features[-1],
                out_channels=num_classes,
                kernel_size=kernel_size,
                bias=True,
                normalization=None,
                activation=None
                )
            )
        net.append(nn.Flatten(start_dim=1, end_dim=-1))

        self.net = nn.Sequential(*net)


    def forward(
        self,
        x:torch.Tensor # input image tensor of dimension (B, C, W, H)
        ) -> torch.Tensor: # output probs (B, N_classes)
        return self.net(x)

# %% ../../nbs/models.conv.ipynb 32
class ConvNetX(Classifier, LightningModule):
    def __init__(
            self,
            nnet:ConvNet,
            num_classes:int,
            optimizer:torch.optim.Optimizer,
            scheduler:torch.optim.lr_scheduler,
            ):
        logger.info("ConvNetX: init")
        super().__init__(num_classes, optimizer, scheduler)
        self.register_module('nnet', nnet)
        self.save_hyperparameters(logger=False, ignore=['nnet'])
        self.lr = optimizer.keywords['lr'] # for lr finder
        self.nnet = nnet

    def forward(self, x:torch.Tensor)->torch.Tensor:
        return self.nnet(x)
    
    def _step(self, batch, batch_idx):
        x, y = batch
        y_hat = self.forward(x)
        loss = self.loss(y_hat, y)
        preds = y_hat.argmax(dim=1)
        return loss, preds, y
    
    def predict_step(self, batch, batch_idx, dataloader_idx=0):
        x, y = batch
        y_hat = self.forward(x)
        return y_hat.argmax(dim=1)
