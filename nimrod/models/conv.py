# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/models.conv.ipynb.

# %% auto 0
__all__ = ['logger', 'ConvLayer', 'DeconvLayer', 'ConvNet', 'ConvNetX']

# %% ../../nbs/models.conv.ipynb 3
import torch.nn as nn
import torch

from lightning import LightningModule, Trainer
from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger
from lightning.pytorch.tuner.tuning import Tuner
from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint

from torch_lr_finder import LRFinder
from torchinfo import summary

from hydra.utils import instantiate
from omegaconf import OmegaConf

from matplotlib import pyplot as plt
import pandas as pd
from typing import List, Optional, Type

from ..utils import get_device, set_seed
from .core import Classifier

from pprint import pprint
import logging


# %% ../../nbs/models.conv.ipynb 4
logger = logging.getLogger(__name__)
set_seed()

# %% ../../nbs/models.conv.ipynb 11
class ConvLayer(nn.Module):
    """A 2D convolutional layer with optional batch normalization and activation.

    This layer performs 2D convolution with stride 2 for downsampling, optionally followed by
    batch normalization and activation.

    Parameters
    ----------
    in_channels : int, default=3
        Number of input channels
    out_channels : int, default=16 
        Number of output channels / number of features
    kernel_size : int, default=3
        Size of the convolving kernel
    bias : bool, default=True
        If True, adds a learnable bias to the convolution
    normalization : nn.Module, default=nn.BatchNorm2d
        Normalization layer to use after convolution
    activation : nn.Module, default=nn.ReLU
        Activation function to use after normalization

    Notes
    -----
    When using batch normalization, the convolution bias is automatically disabled
    since it would be redundant.

    The spatial dimensions are reduced by half due to stride=2 convolution:
    output_size = input_size/2
    """
  
    def __init__(
        self,
        in_channels:int=3, # input channels
        out_channels:int=16, # output channels
        kernel_size:int=3, # kernel size
        stride:int=2, # stride
        bias:bool=True,
        normalization:Optional[Type[nn.Module]]=nn.BatchNorm2d,
        activation:Optional[Type[nn.Module]]=nn.ReLU,
        
    ):

        super().__init__()
        
        if bias and normalization and issubclass(normalization, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):
            logger.warning('setting conv bias to False as Batchnorm is used')
            # https://x.com/karpathy/status/1013245864570073090
            bias = None

        # use stride 2 for downsampling to (W/2, H/2) instead of max or average pooling with stride 1
        conv = nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size,
            stride=stride,
            padding=kernel_size//2,
            bias=bias
            )
        layers = [conv]
        if normalization:
            if issubclass(normalization,  (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):
                layers.append(normalization(out_channels))
        if activation:
            layers.append(activation())
        self.net = nn.Sequential(*layers)

    def forward(
            self,
            x:torch.Tensor # input image tensor of dimension (B, C, W, H)
            ) -> torch.Tensor: # output image tensor of dimension (B, C, W/2, H/2)
        
        """forward method of the ConvLayer"""
        return self.net(x)


# %% ../../nbs/models.conv.ipynb 19
class DeconvLayer(nn.Module):
    def __init__(
        self,
        in_channels:int=16, # input channels
        out_channels:int=3, # output channels
        kernel_size:int=3, # kernel size
        bias:bool=True,
        normalization:Optional[Type[nn.Module]]=None,
        activation:Optional[Type[nn.Module]]=nn.ReLU,
        stride:int = 1,
        scale_factor:int = 2
    ):
        super().__init__()
        layers = []
        if normalization:
            if issubclass(normalization,  (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):
                logger.warning('setting conv bias to False as Batchnorm is used')
                # https://x.com/karpathy/status/1013245864570073090
                bias = None

        layers.append(nn.UpsamplingNearest2d(scale_factor=scale_factor))

        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=kernel_size//2, bias=bias))
        if normalization:
            layers.append(normalization(out_channels))
        if activation:
            layers.append(activation())
        self._net = nn.Sequential(*layers)

    def forward(self, x:torch.Tensor # input image tensor of dimension (B, C, W, H)
                ) -> torch.Tensor: # output image tensor of dimension (B, C, W*2, H*2)
        return self._net(x) 

# %% ../../nbs/models.conv.ipynb 26
class ConvNet(nn.Module):

    def __init__(
            self,
            n_features:List[int]=[1, 8, 16, 32, 64], # channel/feature expansion
            num_classes:int=10, # num_classes
            kernel_size:int=3, # kernel size
            bias:bool=False, # conv2d bias
            normalization:nn.Module=nn.BatchNorm2d, # normalization (before activation)
            activation:nn.Module=nn.ReLU, # activation function
        ):

        super().__init__()

        net = []

        conv_stride_1 = ConvLayer(
            in_channels=n_features[0],
            out_channels=n_features[1],
            stride=1,
            kernel_size=kernel_size,
            bias=bias,
            normalization=normalization,
            activation=activation
        )
        net.append(conv_stride_1)

        for i in range(1, len(n_features) - 1):
            conv = ConvLayer(
                    in_channels=n_features[i],
                    out_channels=n_features[i+1],
                    kernel_size=kernel_size,
                    bias=bias,
                    normalization=normalization,
                    activation=activation
            )
            net.append(conv)
       
        net.append(
            ConvLayer(
                in_channels=n_features[-1],
                out_channels=num_classes,
                kernel_size=kernel_size,
                bias=True,
                normalization=None,
                activation=None
                )
            )
        net.append(nn.Flatten(start_dim=1, end_dim=-1))

        self.net = nn.Sequential(*net)


    def forward(
        self,
        x:torch.Tensor # input image tensor of dimension (B, C, W, H)
        ) -> torch.Tensor: # output probs (B, N_classes)
        return self.net(x)

# %% ../../nbs/models.conv.ipynb 41
class ConvNetX(Classifier, LightningModule):
    def __init__(
            self,
            nnet:ConvNet,
            num_classes:int,
            optimizer:torch.optim.Optimizer,
            scheduler:torch.optim.lr_scheduler,
            ):
        logger.info("ConvNetX: init")
        super().__init__(num_classes, optimizer, scheduler)
        self.register_module('nnet', nnet)
        # self.save_hyperparameters(logger=False, ignore=['nnet']) # by default saved since input of __init__
        self.save_hyperparameters(logger=False)
        self.lr = optimizer.keywords['lr'] # for lr finder
        self.nnet = nnet

    def forward(self, x:torch.Tensor)->torch.Tensor:
        return self.nnet(x)
    
    def _step(self, batch, batch_idx):
        x, y = batch
        y_hat = self.forward(x)
        loss = self.loss(y_hat, y)
        preds = y_hat.argmax(dim=1)
        return loss, preds, y
    
    def predict_step(self, batch, batch_idx, dataloader_idx=0):
        x, y = batch
        y_hat = self.forward(x)
        return y_hat.argmax(dim=1)
