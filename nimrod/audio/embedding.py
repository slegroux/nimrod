# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/audio.embeddings.ipynb.

# %% auto 0
__all__ = ['EncoDec', 'EncoDecConfig', 'EncoDecExtractor']

# %% ../../nbs/audio.embeddings.ipynb 4
from encodec import EncodecModel
from encodec.utils import convert_audio

import torchaudio
import torch

from lhotse.features import FeatureExtractor
from lhotse.utils import compute_num_frames, Seconds
from lhotse import CutSet, Fbank

from matplotlib import pyplot as plt
import IPython.display as ipd
import numpy as np

from dataclasses import asdict, dataclass
from typing import Any, Dict, List, Optional, Pattern, Union
from plum import dispatch

from .utils import plot_waveform
from ..utils import get_device

# %% ../../nbs/audio.embeddings.ipynb 5
class EncoDec():
    def __init__(self, device:str='cpu'):
        self.model = EncodecModel.encodec_model_24khz()
        self._device = device
        self.model.to(self._device)
        self.model.set_target_bandwidth(6.0)

    @dispatch
    def __call__(self, wav:torch.Tensor, sr:int)->torch.Tensor:
        # (CxT) -> (CxDxT_frames)
        if sr != self.model.sample_rate:
            wav = convert_audio(wav, sr, self.model.sample_rate, self.model.channels) # model.sample_rate=24kHz
        wav = wav.unsqueeze(0)
        with torch.no_grad():
            encoded_frames = self.model.encode(wav)
        codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)
        return(codes)
    
    @dispatch
    def __call__(self, wav:np.ndarray, sr:int)->torch.Tensor:
        wav = torch.from_numpy(wav).float().unsqueeze(0)
        if sr != self.model.sample_rate:
            wav = convert_audio(wav, sr, self.model.sample_rate, self.model.channels) # model.sample_rate=24kHz
        # wav = wav.unsqueeze(0)
        with torch.no_grad():
            encoded_frames = self.model.encode(wav.to(self._device))
        codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)
        return(codes)

    def decode(self, codes:torch.Tensor)->torch.Tensor:
        # (CxDxT_frames) -> (CxT)
        frames_from_code = [(codes, None)]
        return(self.model.decode(encoded_frames=frames_from_code))

    @property
    def sample_rate(self):
        return self.model.sample_rate
    
    @property
    def device(self):
        return self._device

# %% ../../nbs/audio.embeddings.ipynb 12
# https://lhotse.readthedocs.io/en/v0.6_ba/features.html#creating-custom-feature-extractor
@dataclass
class EncoDecConfig:
    # The encoder produces embeddings at 75 Hz for input waveforms at 24 kHz,
    # which is a 320-fold reduction in the sampling rate.
    frame_shift: float = 320.0 / 24000
    n_q: int = 8

class EncoDecExtractor(FeatureExtractor):
    name = 'encodec'
    config_type = EncoDecConfig
    def __init__(self, config=EncoDecConfig()):
        super().__init__(config)
        self.encodec = EncoDec()

    def extract(self, samples:Union[torch.Tensor, np.ndarray], sampling_rate: int) -> np.ndarray:    
        codes = self.encodec(samples, sampling_rate)
        duration = round(samples.shape[-1] / sampling_rate, ndigits=12)
        expected_num_frames = compute_num_frames(
            duration=duration,
            frame_shift=self.frame_shift,
            sampling_rate=sampling_rate,
        )
        assert abs(codes.shape[-1] - expected_num_frames) <= 1
        codes = codes[..., :expected_num_frames]
        return codes.cpu().squeeze(0).permute(1, 0).numpy()

    @property
    def frame_shift(self)->float:
        return self.config.frame_shift

    def feature_dim(self, sampling_rate: int) -> int:
        return self.config.n_q

    
