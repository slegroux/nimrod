"""Image datasets"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/image.datasets.ipynb.

# %% auto 0
__all__ = ['logger', 'show_images', 'make_grid', 'ImagePlotMixin', 'ImageDataset', 'ImageDataModule']

# %% ../../nbs/image.datasets.ipynb 3
# torch
import torch
from torch import Tensor # type hint
import torch.utils.data as data
from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split
# torchvision
from torchvision.transforms import transforms, Compose
import torchvision
# lightning
from lightning import LightningDataModule

# hugging face
from datasets import load_dataset, load_dataset_builder, ClassLabel
import datasets

# math
import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
from PIL import Image
import PIL

# python libs
import os
import logging
import warnings
from pprint import pprint
from plum import dispatch

# configs
from omegaconf import OmegaConf
from hydra.utils import instantiate
# typing
from typing import Optional, Tuple, List, Callable, Union, Dict

# nimrod
from ..data.core import DataModule
from ..utils import set_seed

# %% ../../nbs/image.datasets.ipynb 4
set_seed(42)
logger = logging.getLogger(__name__)
# logger.setLevel(logging.DEBUG)
plt.set_loglevel('INFO')
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# %% ../../nbs/image.datasets.ipynb 6
def show_images(x:torch.Tensor, ncols:int=8):
    """Given a batch of images x, make a grid and convert to PIL"""
    # x = x * 0.5 + 0.5  # Map from (-1, 1) back to (0, 1)
    grid = torchvision.utils.make_grid(x, nrow=ncols, normalize=False)
    grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255
    grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))
    return grid_im


def make_grid(images, size=64):
    """Given a list of PIL images, stack them together into a line for easy viewing"""
    output_im = Image.new("RGB", (size * len(images), size))
    for i, im in enumerate(images):
        output_im.paste(im.resize((size, size)), (i * size, 0))
    return output_im

# %% ../../nbs/image.datasets.ipynb 8
class ImagePlotMixin:
    " Mixin class for image datasets providing visualization of (image, label) samples"

    @staticmethod
    def plot(
        ds: Dataset,
        idx: int,
        int2label: Dict[int, str] | Callable = None,

        ):
        X, label = ds[idx]
        C, H, W = X.shape
        if C == 1:
            # X (1, H, W)
            plt.imshow(X[0].numpy(), cmap='gray') 
        elif C == 3:
            # X (3, H, W)
            plt.imshow(X.numpy().transpose(1,2,0).reshape(H,W,C))
        # Convert label to string if possible
        try:
            # label_str = ds.hf_ds.features['label'].int2str(label)
            if isinstance(int2label, dict):
                label_str = int2label[label]
            elif isinstance(int2label, Callable):
                label_str = int2label(label)
            else:
                label_str = str(label)
        except AttributeError:  
            logger.warning("Unable to convert label to string")
        plt.title(f"Label: {label_str}")
        plt.show()

    @staticmethod
    def plot_grid(
        ds: Dataset,
        n_rows:int=3,
        n_cols:int=3,
        int2label: Dict[int, str] | Callable = None
        ):
        """
        Plot a grid of random images from the dataset
        
        Args:
            n_rows (int): Number of rows in the grid
            n_cols (int): Number of columns in the grid
        """
        fig, axs = plt.subplots(n_rows, n_cols, figsize=(10, 10))
        
        # Flatten axs if it's a 2D array
        if n_rows > 1 and n_cols > 1:
            axs = axs.flatten()
        
        for i in range(n_rows * n_cols):
            # Randomly select an index
            idx = torch.randint(0, len(ds), (1,)).item()
            
            # Get image and label
            img, label = ds[idx]
            C, H, W = img.shape
            
            # Handle different channel configurations
            if C == 1:  # Grayscale
                plot_img = img[0].numpy()
                cmap = 'gray'
            elif C == 3:  # RGB
                plot_img = img.numpy().transpose(1, 2, 0).reshape(H,W,C)
                cmap = None
            
            # Plot the image
            axs[i].imshow(plot_img, cmap=cmap) #.astype(np.uint8)
            
            # Convert label to string if possible
            try:
                # label_str = ds.hf_ds.features['label'].int2str(label)
                if isinstance(int2label, dict):
                    label_str = int2label[label]
                elif isinstance(int2label, Callable):
                    label_str = int2label(label)
                else:
                    label_str = str(label)
            except AttributeError:
                logger.warning("Unable to convert label to string")
            
            axs[i].set_title(f"Label: {label_str}")
            axs[i].axis('off')
    
        plt.tight_layout()
        plt.show()

# %% ../../nbs/image.datasets.ipynb 11
class ImageDataset(ImagePlotMixin, Dataset):
    "Image dataset"

    def __init__(
        self,
        name:str = "mnist",
        *args,
        data_dir:Optional[str]='../data/image', # path where data is saved if None default to hugging face cache
        split = 'train', # train or test dataset
        transforms:Optional[transforms.Compose]=transforms.Compose([
                transforms.ToTensor()]), #,transforms.Normalize((0.1307,), (0.3081,))]),
        streaming:bool = False, # TODO: support and test streaming datasest
        exclude_grey_scale = False,
        verification_mode="no_checks"
        
    ):

        if data_dir is not None:
            os.makedirs(data_dir, exist_ok=True)
        super().__init__()
        self.exclude_grey_scale = exclude_grey_scale
        self.info = load_dataset_builder(name, *args)
        if split not in self.info.info.splits:
            raise ValueError(f"The specified split '{split}' does not exist in the dataset '{name}'. Available splits: {list(info.info.splits.keys())}")

        self.hf_ds = load_dataset(
            name,
            *args,
            split=split,
            cache_dir=data_dir,
            download_mode='reuse_dataset_if_exists',
            streaming=streaming,
            verification_mode=verification_mode
            
        )
        self.image_column_name = 'image'
        if name == 'cifar10':
            self.image_column_name = 'img'
                
        self.images = self.hf_ds[self.image_column_name]

        if name == "huggan/smithsonian_butterflies_subset":
            # no default label col available using 'taxonomy' instead
            unique_labels =list(set(self.hf_ds['taxonomy']))
            cl = ClassLabel(names=unique_labels)
            self.hf_ds = self.hf_ds.map(lambda example: {'label': cl.str2int(example['taxonomy'])})
            self.hf_ds = self.hf_ds.cast_column('label', cl)

        self.labels = self.hf_ds['label']

        self.transform = transforms

    def add_label_column(example):
        example['label'] = cl.str2int(example['taxonomy'])
        return example

    @property
    def num_classes(self):
        return self.hf_ds.features['label'].num_classes
    
    @property
    def label_names(self)->List[str]:
        return self.hf_ds.features['label'].names
    
    @property
    def int2str(self):
        return self.hf_ds.features['label'].int2str
    
    @property
    def splits(self)->List[int]:
        return self.info.info.splits.keys()

    def __len__(self) -> int: # length of dataset
        return len(self.images)
    
    def __getitem__(
        self,
        idx:int # index into the dataset
    ) -> tuple[torch.FloatTensor, int]: # Y image data, x digit number
      
        image = np.array(self.images[idx])
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)
            if self.exclude_grey_scale and image.size(0) != 3:
                logger.warning(f"Skipping sample at index {idx} because doesn't have 3 channels")
                next_idx = (idx + 1) % len(self)
                return self.__getitem__(next_idx)
        
        return image, label


    
    def train_dev_split(
        self,
        ratio:float, # percentage of train/dev split,
    ) -> tuple[Dataset, Dataset]: # train and set mnnist datasets

        train_set_size = int(len(self.images) * ratio)
        valid_set_size = len(self.images) - train_set_size
        ds = list(zip(self.images, self.labels))
        # split the train set into two randomly sample
        train_set, valid_set = data.random_split(ds, [train_set_size, valid_set_size])
        return train_set, valid_set

    def show(
        self,
        idx:int # index into the dataset
        ):
        self.plot(self, idx, self.hf_ds.features['label'].int2str)

    def show_grid(
        self,
        n_rows:int=3, # Number of rows in the grid
        n_cols:int=3 # Number of columns in the grid
        ):
        self.plot_grid(self, n_rows, n_cols, self.hf_ds.features['label'].int2str)

# %% ../../nbs/image.datasets.ipynb 28
class ImageDataModule(ImagePlotMixin, DataModule, LightningDataModule):
    def __init__(
        self,
        name: str,
        *args,
        data_dir: Optional[str] = "~/Data/", # path to source data dir
        transforms: Union[transforms.Compose, Callable, None] = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ]),
        train_val_split:List[float] = [0.8, 0.2], # train val test %
        batch_size: int = 64, # size of compute batch
        num_workers: int = 0, # num_workers equal 0 means that it’s the main process that will do the data loading when needed, num_workers equal 1 is the same as any n, but you’ll only have a single worker, so it might be slow
        pin_memory: bool = False, # If you load your samples in the Dataset on CPU and would like to push it during training to the GPU, you can speed up the host to device transfer by enabling pin_memory. This lets your DataLoader allocate the samples in page-locked memory, which speeds-up the transfer
        persistent_workers: bool = False,
        **kwargs
        ):

        logger.info(f"Init ImageDataModule for {name}")
        super().__init__(train_val_split, batch_size, num_workers, pin_memory, persistent_workers)
        self.save_hyperparameters()
        self.train_ds, self.test_ds, self.val_ds = None, None, None
        self.int2str = None
        self._num_classes = None
        self.args = args
        self.kwargs = kwargs

    @property
    def batch_size(self)->int:
        return self.hparams.batch_size

    @property
    def num_classes(self) -> int: # num of classes in dataset
        if self._num_classes is not None:
            return self._num_classes
        raise RuntimeError("train_ds is not initialized. Call prepare_data() first.")
    
    @property
    def label_names(self) -> List[str]:  # Add this property
        if self.train_ds is not None:
            return self._label_names
        raise RuntimeError("train_ds is not initialized. Call prepare_data() first.")

    def prepare_data(self) -> None:
        """Download data if needed 
        """
        # train set
        self.train_ds = ImageDataset(
            self.hparams.name,
            *self.args,
            data_dir = self.hparams.data_dir,
            split='train',
            transforms = self.hparams.transforms,
            **self.kwargs

        )
        # get num classes before setup method converst ImageDataset to Subset
        self._num_classes = self.train_ds.num_classes
        self._label_names = self.train_ds.label_names
        # save class names before splitting test/valid and losing property
        self.int2str = self.train_ds.int2str
        # test set
        splits = self.train_ds.splits
        # test is test split from hugging face else use validation for test and split test into test/val
        if 'test' in splits:
            self.test_ds = ImageDataset(
                self.hparams.name,
                *self.args,
                data_dir = self.hparams.data_dir,
                split='test',
                transforms = self.hparams.transforms,
                **self.kwargs
            )
            if 'validation' in splits:
                self.val_ds = ImageDataset(
                    self.hparams.name,
                    *self.args,
                    data_dir = self.hparams.data_dir,
                    split='validation',
                    transforms = self.hparams.transforms,
                    **self.kwargs
                )
            else:
                self._val_ds = None # self.setup() will create validation from train set

        elif 'test' not in splits:
            if 'validation' in splits:
                # make existing val set the actual test set and split training into train/val
                self.test_ds = ImageDataset(
                    self.hparams.name,
                    *self.args,
                    data_dir = self.hparams.data_dir,
                    split='validation',
                    transforms = self.hparams.transforms,
                    **self.kwargs
                )
                self.val_ds = None
            else:
                self.setup(stage='split_train_data')
                logger.info(f"split train into train/val {self.hparams.train_val_split}")

    def setup(self, stage: Optional[str] = None) -> None:
        # called on every GPU when distrib
        # stage: {fit,validate,test,predict}\n",
        # concat train & test mnist dataset and randomly generate train, eval, test sets
        if stage == 'split_train_data':
            # TODO have separate test. here tes is a copy of val. fix later...
            logger.warning(f"split train into train/val/test with val==test {self.hparams.train_val_split} ")
            lengths = [round(split * len(self.train_ds)) for split in self.hparams.train_val_split]
            self.train_ds, self.val_ds = random_split(dataset=self.train_ds, lengths=lengths)
            self.test_ds = self.val_ds
            logger.info(f"train: {len(self.train_ds)} val: {len(self.val_ds)}, test: {len(self.test_ds)}")


        if not self.train_ds:
            raise RuntimeError("prepare_data() must be called before accessing the train dataset.")
        # if not self.test_ds:
        #     raise RuntimeError("prepare_data() must be called before accessing the test dataset.")
        if not self.val_ds:
            # dataset = ConcatDataset(datasets=[trainset, testset])
            logger.info(f"split train into train/val {self.hparams.train_val_split}")
            lengths = [round(split * len(self.train_ds)) for split in self.hparams.train_val_split]
            self.train_ds, self.val_ds = random_split(dataset=self.train_ds, lengths=lengths)
            logger.info(f"train: {len(self.train_ds)} val: {len(self.val_ds)}, test: {len(self.test_ds)}")

    
    def show(self, idx):
      self.plot(self.train_ds, idx, self.int2str)
    
    def show_grid(self, nrow, ncols):
        self.plot_grid(self.train_ds, nrow, ncols, self.int2str)
    
    @staticmethod
    def show_batch(
        batch:torch.Tensor,
        n_cols:int=8,
        )->List[PIL.Image]:

        # show_images(batch, n_cols)
        x = batch
        # x = x * 0.5 + 0.5  # Map from (-1, 1) back to (0, 1)
        grid = torchvision.utils.make_grid(x, nrow=n_cols, normalize=False)
        grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255
        grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))
        return grid_im

        
