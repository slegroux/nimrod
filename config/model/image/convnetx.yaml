_target_: nimrod.models.conv.ConvNetX
num_classes: 10 #default value overridden by hydra at instantiation if necessary
nnet:
  _target_: nimrod.models.conv.ConvNet
  n_features: [1, 8, 16, 32, 64]  # channel/feature expansion
  num_classes: ${..num_classes}  # number of output classes
  kernel_size: 3  # convolution kernel size
  bias: null  # disable bias since using BatchNorm
  normalization: 
    _target_: hydra.utils.get_class
    path: torch.nn.BatchNorm2d
  activation:
    _target_: hydra.utils.get_class
    path: torch.nn.ReLU

# optimizer:
#   _target_: torch.optim.Adam
#   _partial_: true
#   lr: 1e-4
#   # weight_decay: 1e-5 # mild regularization

# scheduler:
#   _target_: torch.optim.lr_scheduler.OneCycleLR
#   _partial_: true
#   max_lr: 0.01
#   # steps_per_epoch: 100
#   # epochs: 1
#   total_steps: 100
#   pct_start: 0.3
#   anneal_strategy: 'cos'
#   div_factor: 10
#   three_phase: False