# @package _global_

# python train.py experiment=mnist_mlp

defaults:
  - override /data: image/mnist
  - override /model: image/mlp
  - override /trainer: default
  - override /logger: wandb
  - _self_

tags: ["mnist", "mlp", "dev"]
project: "mnist-mlp"
name: "test" # name of run
seed: 42
train: True
tune_lr: False
test: False


data:
  batch_size: 1024
  num_workers: 0
  pin_memory: true

trainer:
  max_epochs: 2
  check_val_every_n_epoch: 1
  log_every_n_steps: 1
  
logger:
  wandb:
    tags: ${tags}
    group: "mnist"
    project: ${project}
    name: test #bs:${data.batch_size}-lr:${model.optimizer.lr}