# @package _global_

# python train.py experiment=mnist_conv

defaults:
  - override /data: image/mnist
  - override /model: image/convnetx
  - override /trainer: default
  - override /logger: wandb
  - _self_

tags: ["mnist", "mlp", "dev"]
project: "mnist-convnetx"
name: "test_feats" # name of run
seed: 42
train: True
tune_lr: False
test: False


data:
  batch_size: 1024
  num_workers: 0
  pin_memory: true
  data_dir: ${data_dir}

model:
  nnet:
    n_features: [1, 8, 16, 32, 16]

trainer:
  max_epochs: 2
  check_val_every_n_epoch: 1
  log_every_n_steps: 1
  
logger:
  wandb:
    tags: ${tags}
    group: "mnist"
    project: ${project}
    name: ${name} #bs:${data.batch_size}-lr:${model.optimizer.lr}