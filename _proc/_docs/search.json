[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()\n\n\nsource\n\n\ntest\n\n test ()"
  },
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "Modules",
    "section": "",
    "text": "source\n\nDecoder\n\n Decoder ()\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nEncoder\n\n Encoder ()\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nimport torch\nenc = Encoder()\nbatch = torch.rand((10, 28*28))\nencoded = enc(batch)\nprint(encoded.shape)\n\ntorch.Size([10, 3])\n\n\n\ndec = Decoder()\ndecoded = dec(encoded)\nprint(decoded.shape)\n\ntorch.Size([10, 784])"
  },
  {
    "objectID": "data.datasets.html",
    "href": "data.datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "source\n\nImageDataset\n\n ImageDataset ()\n\nBase class for image datasets providing visualization of (image, label) samples\n\nsource\n\n\nMNISTDataset\n\n MNISTDataset (data_root:str='~/Data', train=True, transform:<module'torch\n               vision.transforms.transforms'from'/home/syl20/anaconda3/env\n               s/nimrod/lib/python3.9/site-\n               packages/torchvision/transforms/transforms.py'>=ToTensor())\n\nMNIST digit dataset\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata_root\nstr\n~/Data\npath where data is saved\n\n\ntrain\nbool\nTrue\ntrain or test dataset\n\n\ntransform\ntorchvision.transforms.transforms\nToTensor()\ndata formatting\n\n\n\n\nds = MNISTDataset('~/Data', train=False)\nprint(f\"Number of samples in the dataset: {len(ds)}\")\nX,y = ds[0]\nprint(X.shape, y)\nprint(f\"Shape of image: {X.shape}, corresponding digit: {int(y)}\")\nprint(f\"types: {X.type()}\")\nds.show(0)\n\nNumber of samples in the dataset: 10000\ntorch.Size([1, 28, 28]) 7\nShape of image: torch.Size([1, 28, 28]), corresponding digit: 7\ntypes: torch.FloatTensor\n\n\n\n\n\n\nds = MNISTDataset('~/Data', train=True)\nprint(len(ds))\ntrain, dev = ds.train_dev_split(0.8)\nprint(len(train), len(dev))\n\n60000\n48000 12000"
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "Models",
    "section": "",
    "text": "source\n\nAutoEncoder\n\n AutoEncoder (encoder:nimrod.modules.Encoder,\n              decoder:nimrod.modules.Decoder)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n\nivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nType\nDetails\n\n\n\n\nencoder\nEncoder\nEncoder layer\n\n\ndecoder\nDecoder\nDecoder layer\n\n\n\n\nenc = Encoder()\ndec = Decoder()\na = AutoEncoder(enc, dec)\nbatch = torch.rand((10, 28*28))\ny = a(batch)\nprint(y.shape)\n\ntorch.Size([10, 784])\n\n\n\nfrom nimrod.data.datasets import MNISTDataset\nfrom torch.utils.data import DataLoader\n\nds = MNISTDataset()\ndl = DataLoader(ds)\nb = next(iter(dl))\nprint(len(b), b[0].shape, b[1].shape)\n\n2 torch.Size([1, 1, 28, 28]) torch.Size([1])\n\n\n\nsource\n\n\nAutoEncoderPL\n\n AutoEncoderPL (autoencoder:__main__.AutoEncoder)\n\nHooks to be used in LightningModule."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "nimrod",
    "section": "",
    "text": "This is a repo with minimal tooling, modules, models and recipes to get easily get started with deep learning training and experimentation"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "nimrod",
    "section": "Install",
    "text": "Install\npip install nimrod"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "nimrod",
    "section": "How to use",
    "text": "How to use\nCheck recipes in recipes/ folder. For instance:\ncd recipes/autoencoder/\npython train.py"
  }
]