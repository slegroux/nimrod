<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="“old school” language modeling based on counting tokens in data">

<title>slg_nimrod - N-Gram Language modeling</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="slg_nimrod - N-Gram Language modeling">
<meta property="og:description" content="&quot;old school&quot; language modeling based on counting tokens in data">
<meta property="og:site-name" content="slg_nimrod">
<meta name="twitter:title" content="slg_nimrod - N-Gram Language modeling">
<meta name="twitter:description" content="&quot;old school&quot; language modeling based on counting tokens in data">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">slg_nimrod</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">N-Gram Language modeling</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Description</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./audio.datasets.stt.html" class="sidebar-item-text sidebar-link">Speech to Text Datasets</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./audio.datasets.tts.html" class="sidebar-item-text sidebar-link">Audio TTS Datasets</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./audio.embeddings.html" class="sidebar-item-text sidebar-link">Audio Embedders</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./audio.utils.html" class="sidebar-item-text sidebar-link">Audio Utilities</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.utils.lhotse.html" class="sidebar-item-text sidebar-link">Lhotse support for datasets</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image.datasets.html" class="sidebar-item-text sidebar-link">Image Datasets</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lm.tokenizers.html" class="sidebar-item-text sidebar-link">Tokenizers</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.aligners.html" class="sidebar-item-text sidebar-link">Aligners</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.autoencoders.html" class="sidebar-item-text sidebar-link">Autoencoders</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.lm.html" class="sidebar-item-text sidebar-link">Neural Net Language models</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.mlp.html" class="sidebar-item-text sidebar-link">MLP</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.ngram.html" class="sidebar-item-text sidebar-link active">N-Gram Language modeling</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.transformer.html" class="sidebar-item-text sidebar-link">Transformers</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modules.html" class="sidebar-item-text sidebar-link">Modules</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text.normalizers.html" class="sidebar-item-text sidebar-link">Text Normalizers</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text.tokenizers.html" class="sidebar-item-text sidebar-link">Text Tokenizers</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#unigram" id="toc-unigram" class="nav-link active" data-scroll-target="#unigram">Unigram</a>
  <ul class="collapse">
  <li><a href="#charunigram" id="toc-charunigram" class="nav-link" data-scroll-target="#charunigram">CharUnigram</a></li>
  <li><a href="#usage" id="toc-usage" class="nav-link" data-scroll-target="#usage">Usage</a></li>
  </ul></li>
  <li><a href="#bigram" id="toc-bigram" class="nav-link" data-scroll-target="#bigram">Bigram</a>
  <ul class="collapse">
  <li><a href="#usage-1" id="toc-usage-1" class="nav-link" data-scroll-target="#usage-1">Usage</a></li>
  <li><a href="#numericalization" id="toc-numericalization" class="nav-link" data-scroll-target="#numericalization">Numericalization</a></li>
  <li><a href="#matrix-representation" id="toc-matrix-representation" class="nav-link" data-scroll-target="#matrix-representation">Matrix representation</a></li>
  <li><a href="#from-counts-to-probabilities" id="toc-from-counts-to-probabilities" class="nav-link" data-scroll-target="#from-counts-to-probabilities">From counts to probabilities</a></li>
  <li><a href="#sampling" id="toc-sampling" class="nav-link" data-scroll-target="#sampling">Sampling</a></li>
  <li><a href="#log-likelihood-loss-function" id="toc-log-likelihood-loss-function" class="nav-link" data-scroll-target="#log-likelihood-loss-function">Log likelihood loss function</a></li>
  <li><a href="#generate-training-data" id="toc-generate-training-data" class="nav-link" data-scroll-target="#generate-training-data">Generate training data</a></li>
  <li><a href="#hot-encoded-input" id="toc-hot-encoded-input" class="nav-link" data-scroll-target="#hot-encoded-input">1-hot encoded input</a></li>
  <li><a href="#neural-net-modeling" id="toc-neural-net-modeling" class="nav-link" data-scroll-target="#neural-net-modeling">‘Neural net’ modeling</a></li>
  </ul></li>
  <li><a href="#kenlm" id="toc-kenlm" class="nav-link" data-scroll-target="#kenlm">KenLM</a>
  <ul class="collapse">
  <li><a href="#kenlm-1" id="toc-kenlm-1" class="nav-link" data-scroll-target="#kenlm-1">KenLM</a></li>
  <li><a href="#preprocess-data-into-kenlm-format" id="toc-preprocess-data-into-kenlm-format" class="nav-link" data-scroll-target="#preprocess-data-into-kenlm-format">Preprocess data into kenlm format</a></li>
  <li><a href="#train-kenlm-n-gram-model" id="toc-train-kenlm-n-gram-model" class="nav-link" data-scroll-target="#train-kenlm-n-gram-model">Train KenLM n-gram model</a></li>
  <li><a href="#inference-sampling-from-prob-distributions" id="toc-inference-sampling-from-prob-distributions" class="nav-link" data-scroll-target="#inference-sampling-from-prob-distributions">Inference / Sampling from prob distributions</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/slegroux/nimrod/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">N-Gram Language modeling</h1>
</div>

<div>
  <div class="description">
    “old school” language modeling based on counting tokens in data
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>https://github.com/karpathy/makemore</p>
<section id="unigram" class="level2">
<h2 class="anchored" data-anchor-id="unigram">Unigram</h2>
<hr>
<p><a href="https://github.com/slegroux/nimrod/blob/main/nimrod/models/ngram.py#L22" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="charunigram" class="level3">
<h3 class="anchored" data-anchor-id="charunigram">CharUnigram</h3>
<blockquote class="blockquote">
<pre><code> CharUnigram (data:List[str])</code></pre>
</blockquote>
<p>Initialize self. See help(type(self)) for accurate signature.</p>
</section>
<section id="usage" class="level3">
<h3 class="anchored" data-anchor-id="usage">Usage</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># without pandas</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'../data/names.txt'</span>, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    list_of_words <span class="op">=</span> f.read().splitlines()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># with pandas</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'../data/names.txt'</span>, names<span class="op">=</span>[<span class="st">'name'</span>], header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>list_of_words <span class="op">=</span> <span class="bu">list</span>(df.head().name)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>unigram <span class="op">=</span> CharUnigram(list_of_words)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"sorted counts: "</span>, unigram.counts)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"sorted probs: "</span>, unigram.probs)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(unigram))</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unigram.chars)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unigram._stoi)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unigram.stoi(<span class="st">'a'</span>))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unigram.itos(<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>sorted counts:  {'a': 7, 'i': 4, 'l': 3, 'e': 2, 'm': 2, 'o': 2, 'v': 2, 's': 2, 'b': 1, 'p': 1, 'h': 1}
sorted probs:  {'a': 0.25925925925925924, 'i': 0.14814814814814814, 'l': 0.1111111111111111, 'e': 0.07407407407407407, 'm': 0.07407407407407407, 'o': 0.07407407407407407, 'v': 0.07407407407407407, 's': 0.07407407407407407, 'b': 0.037037037037037035, 'p': 0.037037037037037035, 'h': 0.037037037037037035}
11
['a', 'b', 'e', 'h', 'i', 'l', 'm', 'o', 'p', 's', 'v']
{'a': 0, 'b': 1, 'e': 2, 'h': 3, 'i': 4, 'l': 5, 'm': 6, 'o': 7, 'p': 8, 's': 9, 'v': 10}
0
a</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame.from_dict(unigram.counts, orient<span class="op">=</span><span class="st">'index'</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;AxesSubplot: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="models.ngram_files/figure-html/cell-4-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> []</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> unigram.sample()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    samples.append(s)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># sampled</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>count <span class="op">=</span> Counter([c <span class="cf">for</span> w <span class="kw">in</span> samples <span class="cf">for</span> c <span class="kw">in</span> w])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame.from_dict(count, orient<span class="op">=</span><span class="st">'index'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>df[<span class="dv">0</span>].sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;AxesSubplot: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="models.ngram_files/figure-html/cell-5-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="bigram" class="level2">
<h2 class="anchored" data-anchor-id="bigram">Bigram</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CharBigram():</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="usage-1" class="level3">
<h3 class="anchored" data-anchor-id="usage-1">Usage</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'../data/names.txt'</span>, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> f.read().splitlines()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"first lines of text: "</span>, data[:<span class="dv">10</span>])</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># data = ["this is a text"]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>first lines of text:  ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># bigram counts</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>bigrams <span class="op">=</span> {}</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>unique_tokens <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> data:</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    line <span class="op">=</span> <span class="bu">list</span>(name)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    unique_tokens.update(line)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    line.append(<span class="st">'&lt;stop&gt;'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    line.insert(<span class="dv">0</span>, <span class="st">'&lt;stop&gt;'</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,v <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">range</span>(<span class="bu">len</span>(line)<span class="op">-</span><span class="dv">1</span>)):</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        bigram <span class="op">=</span> (line[i], line[i<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> bigram <span class="kw">in</span> bigrams:</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>            bigrams[bigram] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            bigrams[bigram] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print("unsorted: ", list(bigrams)[:10])</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># print("sorted: ", sort_dict_by_value(bigrams))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="numericalization" class="level3">
<h3 class="anchored" data-anchor-id="numericalization">Numericalization</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> <span class="bu">sorted</span>(unique_tokens)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># use same for start &amp; stop in this case (separate lines of names)</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tokens.append('&lt;start&gt;')</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>tokens.append(<span class="st">'&lt;stop&gt;'</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>stoi <span class="op">=</span> {v:i <span class="cf">for</span> i,v <span class="kw">in</span> <span class="bu">enumerate</span>(tokens)}</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>itos <span class="op">=</span> {i:v <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(tokens)}</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stoi, itos)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '&lt;stop&gt;']
{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '&lt;stop&gt;': 26} {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '&lt;stop&gt;'}</code></pre>
</div>
</div>
</section>
<section id="matrix-representation" class="level3">
<h3 class="anchored" data-anchor-id="matrix-representation">Matrix representation</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>n_toks <span class="op">=</span> <span class="bu">len</span>(tokens)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n_toks)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> torch.zeros((n_toks, n_toks)).<span class="bu">long</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(N.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>27
torch.Size([27, 27])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bigram, value <span class="kw">in</span> bigrams.items():</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    idx1, idx2 <span class="op">=</span> stoi[bigram[<span class="dv">0</span>]], stoi[bigram[<span class="dv">1</span>]]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    N[idx1, idx2] <span class="op">=</span> value</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'char_t+1'</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'char_t'</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> [i <span class="cf">for</span> i, v <span class="kw">in</span> itos.items()]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> [v <span class="cf">for</span> i,v <span class="kw">in</span> itos.items()]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(i, v)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>plt.yticks(i, v)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.imshow(N, origin<span class="op">=</span><span class="st">'lower'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;matplotlib.image.AxesImage&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="models.ngram_files/figure-html/cell-11-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="from-counts-to-probabilities" class="level3">
<h3 class="anchored" data-anchor-id="from-counts-to-probabilities">From counts to probabilities</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 556,  541,  470, 1042,  692,  134,  168, 2332, 1650,  175,  568, 2528,
         1634, 5438,   63,   82,   60, 3264, 1118,  687,  381,  834,  161,  182,
         2050,  435, 6640],
        [ 321,   38,    1,   65,  655,    0,    0,   41,  217,    1,    0,  103,
            0,    4,  105,    0,    0,  842,    8,    2,   45,    0,    0,    0,
           83,    0,  114],
        [ 815,    0,   42,    1,  551,    0,    2,  664,  271,    3,  316,  116,
            0,    0,  380,    1,   11,   76,    5,   35,   35,    0,    0,    3,
          104,    4,   97],
        [1303,    1,    3,  149, 1283,    5,   25,  118,  674,    9,    3,   60,
           30,   31,  378,    0,    1,  424,   29,    4,   92,   17,   23,    0,
          317,    1,  516],
        [ 679,  121,  153,  384, 1271,   82,  125,  152,  818,   55,  178, 3248,
          769, 2675,  269,   83,   14, 1958,  861,  580,   69,  463,   50,  132,
         1070,  181, 3983],
        [ 242,    0,    0,    0,  123,   44,    1,    1,  160,    0,    2,   20,
            0,    4,   60,    0,    0,  114,    6,   18,   10,    0,    4,    0,
           14,    2,   80],
        [ 330,    3,    0,   19,  334,    1,   25,  360,  190,    3,    0,   32,
            6,   27,   83,    0,    0,  201,   30,   31,   85,    1,   26,    0,
           31,    1,  108],
        [2244,    8,    2,   24,  674,    2,    2,    1,  729,    9,   29,  185,
          117,  138,  287,    1,    1,  204,   31,   71,  166,   39,   10,    0,
          213,   20, 2409],
        [2445,  110,  509,  440, 1653,  101,  428,   95,   82,   76,  445, 1345,
          427, 2126,  588,   53,   52,  849, 1316,  541,  109,  269,    8,   89,
          779,  277, 2489],
        [1473,    1,    4,    4,  440,    0,    0,   45,  119,    2,    2,    9,
            5,    2,  479,    1,    0,   11,    7,    2,  202,    5,    6,    0,
           10,    0,   71],
        [1731,    2,    2,    2,  895,    1,    0,  307,  509,    2,   20,  139,
            9,   26,  344,    0,    0,  109,   95,   17,   50,    2,   34,    0,
          379,    2,  363],
        [2623,   52,   25,  138, 2921,   22,    6,   19, 2480,    6,   24, 1345,
           60,   14,  692,   15,    3,   18,   94,   77,  324,   72,   16,    0,
         1588,   10, 1314],
        [2590,  112,   51,   24,  818,    1,    0,    5, 1256,    7,    1,    5,
          168,   20,  452,   38,    0,   97,   35,    4,  139,    3,    2,    0,
          287,   11,  516],
        [2977,    8,  213,  704, 1359,   11,  273,   26, 1725,   44,   58,  195,
           19, 1906,  496,    5,    2,   44,  278,  443,   96,   55,   11,    6,
          465,  145, 6763],
        [ 149,  140,  114,  190,  132,   34,   44,  171,   69,   16,   68,  619,
          261, 2411,  115,   95,    3, 1059,  504,  118,  275,  176,  114,   45,
          103,   54,  855],
        [ 209,    2,    1,    0,  197,    1,    0,  204,   61,    1,    1,   16,
            1,    1,   59,   39,    0,  151,   16,   17,    4,    0,    0,    0,
           12,    0,   33],
        [  13,    0,    0,    0,    1,    0,    0,    0,   13,    0,    0,    1,
            2,    0,    2,    0,    0,    1,    2,    0,  206,    0,    3,    0,
            0,    0,   28],
        [2356,   41,   99,  187, 1697,    9,   76,  121, 3033,   25,   90,  413,
          162,  140,  869,   14,   16,  425,  190,  208,  252,   80,   21,    3,
          773,   23, 1377],
        [1201,   21,   60,    9,  884,    2,    2, 1285,  684,    2,   82,  279,
           90,   24,  531,   51,    1,   55,  461,  765,  185,   14,   24,    0,
          215,   10, 1169],
        [1027,    1,   17,    0,  716,    2,    2,  647,  532,    3,    0,  134,
            4,   22,  667,    0,    0,  352,   35,  374,   78,   15,   11,    2,
          341,  105,  483],
        [ 163,  103,  103,  136,  169,   19,   47,   58,  121,   14,   93,  301,
          154,  275,   10,   16,   10,  414,  474,   82,    3,   37,   86,   34,
           13,   45,  155],
        [ 642,    1,    0,    1,  568,    0,    0,    1,  911,    0,    3,   14,
            0,    8,  153,    0,    0,   48,    0,    0,    7,    7,    0,    0,
          121,    0,   88],
        [ 280,    1,    0,    8,  149,    2,    1,   23,  148,    0,    6,   13,
            2,   58,   36,    0,    0,   22,   20,    8,   25,    0,    2,    0,
           73,    1,   51],
        [ 103,    1,    4,    5,   36,    3,    0,    1,  102,    0,    0,   39,
            1,    1,   41,    0,    0,    0,   31,   70,    5,    0,    3,   38,
           30,   19,  164],
        [2143,   27,  115,  272,  301,   12,   30,   22,  192,   23,   86, 1104,
          148, 1826,  271,   15,    6,  291,  401,  104,  141,  106,    4,   28,
           23,   78, 2007],
        [ 860,    4,    2,    2,  373,    0,    1,   43,  364,    2,    2,  123,
           35,    4,  110,    2,    0,   32,    4,    4,   73,    2,    3,    1,
          147,   45,  160],
        [4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963, 1572,
         2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,  134,
          535,  929,    0]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># smoothing avoids having log(0) = inf when computing NLL loss</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>smoothing <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> (N.<span class="bu">float</span>()<span class="op">+</span>smoothing) <span class="op">/</span> N.<span class="bu">sum</span>(<span class="dv">1</span>,keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(P, origin<span class="op">=</span><span class="st">'lower'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;matplotlib.image.AxesImage&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="models.ngram_files/figure-html/cell-13-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>row_6 <span class="op">=</span> (N[<span class="dv">6</span>,:]<span class="op">/</span>N[<span class="dv">6</span>,:].<span class="bu">sum</span>())</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(row_6)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(row_6.<span class="bu">sum</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.1713, 0.0016, 0.0000, 0.0099, 0.1733, 0.0005, 0.0130, 0.1868, 0.0986,
        0.0016, 0.0000, 0.0166, 0.0031, 0.0140, 0.0431, 0.0000, 0.0000, 0.1043,
        0.0156, 0.0161, 0.0441, 0.0005, 0.0135, 0.0000, 0.0161, 0.0005, 0.0560])
tensor(1.0000)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> P[<span class="dv">6</span>, :]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p.<span class="bu">sum</span>(), p.<span class="bu">max</span>(), torch.argmax(p))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(1.0140) tensor(0.1873) tensor(7)</code></pre>
</div>
</div>
</section>
<section id="sampling" class="level3">
<h3 class="anchored" data-anchor-id="sampling">Sampling</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> []</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    prev <span class="op">=</span> stoi[<span class="st">'&lt;stop&gt;'</span>]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># max prob sampling</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">next</span> <span class="op">=</span> <span class="bu">int</span>(torch.argmax(P[prev, :]))</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># multinomial sampling</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">next</span> <span class="op">=</span> <span class="bu">int</span>(torch.multinomial(P[prev,:],num_samples<span class="op">=</span><span class="dv">1</span>,replacement<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">next</span> <span class="op">==</span> stoi[<span class="st">'&lt;stop&gt;'</span>]:</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">''</span>.join(res))</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>            res.append(itos[<span class="bu">next</span>])</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>            prev <span class="op">=</span> <span class="bu">next</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ken
klansliuvrie
li
ay
kan
meimikizas
korle
man
khviaez
ionthadennidjun</code></pre>
</div>
</div>
</section>
<section id="log-likelihood-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="log-likelihood-loss-function">Log likelihood loss function</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>bigram_p <span class="op">=</span> {}</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bigram, value <span class="kw">in</span> bigrams.items():</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    idx1, idx2 <span class="op">=</span> stoi[bigram[<span class="dv">0</span>]], stoi[bigram[<span class="dv">1</span>]]</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    bigram_p[bigram] <span class="op">=</span> P[idx1,idx2]</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bigram_p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{('&lt;stop&gt;', 'e'): tensor(0.0478), ('e', 'm'): tensor(0.0377), ('m', 'm'): tensor(0.0254), ('m', 'a'): tensor(0.3901), ('a', '&lt;stop&gt;'): tensor(0.1960), ('&lt;stop&gt;', 'o'): tensor(0.0123), ('o', 'l'): tensor(0.0781), ('l', 'i'): tensor(0.1777), ('i', 'v'): tensor(0.0153), ('v', 'i'): tensor(0.3545), ('i', 'a'): tensor(0.1382), ('&lt;stop&gt;', 'a'): tensor(0.1377), ('a', 'v'): tensor(0.0246), ('v', 'a'): tensor(0.2499), ('&lt;stop&gt;', 'i'): tensor(0.0185), ('i', 's'): tensor(0.0744), ('s', 'a'): tensor(0.1483), ('a', 'b'): tensor(0.0160), ('b', 'e'): tensor(0.2480), ('e', 'l'): tensor(0.1591), ('l', 'l'): tensor(0.0964), ('l', 'a'): tensor(0.1880), ('&lt;stop&gt;', 's'): tensor(0.0642), ('s', 'o'): tensor(0.0656), ('o', 'p'): tensor(0.0121), ('p', 'h'): tensor(0.1998), ('h', 'i'): tensor(0.0959), ('&lt;stop&gt;', 'c'): tensor(0.0482), ('c', 'h'): tensor(0.1883), ('h', 'a'): tensor(0.2948), ('a', 'r'): tensor(0.0964), ('r', 'l'): tensor(0.0326), ('l', 'o'): tensor(0.0496), ('o', 't'): tensor(0.0150), ('t', 't'): tensor(0.0673), ('t', 'e'): tensor(0.1287), ('e', '&lt;stop&gt;'): tensor(0.1951), ('&lt;stop&gt;', 'm'): tensor(0.0793), ('m', 'i'): tensor(0.1893), ('a', 'm'): tensor(0.0483), ('m', 'e'): tensor(0.1233), ('&lt;stop&gt;', 'h'): tensor(0.0273), ('r', 'p'): tensor(0.0012), ('p', 'e'): tensor(0.1930), ('e', 'r'): tensor(0.0959), ('r', '&lt;stop&gt;'): tensor(0.1085), ('e', 'v'): tensor(0.0227), ('v', 'e'): tensor(0.2211), ('l', 'y'): tensor(0.1138), ('y', 'n'): tensor(0.1869), ('n', '&lt;stop&gt;'): tensor(0.3691), ('b', 'i'): tensor(0.0824), ('i', 'g'): tensor(0.0242), ('g', 'a'): tensor(0.1718), ('a', 'i'): tensor(0.0487), ('i', 'l'): tensor(0.0760), ('l', '&lt;stop&gt;'): tensor(0.0942), ('y', '&lt;stop&gt;'): tensor(0.2054), ('i', 'z'): tensor(0.0157), ('z', 'a'): tensor(0.3590), ('e', 't'): tensor(0.0284), ('t', 'h'): tensor(0.1163), ('h', '&lt;stop&gt;'): tensor(0.3164), ('r', 'y'): tensor(0.0609), ('o', 'f'): tensor(0.0044), ('f', 'i'): tensor(0.1779), ('c', 'a'): tensor(0.2310), ('r', 'i'): tensor(0.2389), ('s', 'c'): tensor(0.0075), ('l', 'e'): tensor(0.2093), ('t', '&lt;stop&gt;'): tensor(0.0869), ('&lt;stop&gt;', 'v'): tensor(0.0118), ('i', 'c'): tensor(0.0288), ('c', 't'): tensor(0.0102), ('t', 'o'): tensor(0.1199), ('o', 'r'): tensor(0.1336), ('a', 'd'): tensor(0.0308), ('d', 'i'): tensor(0.1228), ('o', 'n'): tensor(0.3040), ('&lt;stop&gt;', 'l'): tensor(0.0491), ('l', 'u'): tensor(0.0233), ('u', 'n'): tensor(0.0880), ('n', 'a'): tensor(0.1625), ('&lt;stop&gt;', 'g'): tensor(0.0209), ('g', 'r'): tensor(0.1048), ('r', 'a'): tensor(0.1856), ('a', 'c'): tensor(0.0139), ('c', 'e'): tensor(0.1563), ('h', 'l'): tensor(0.0244), ('o', 'e'): tensor(0.0168), ('&lt;stop&gt;', 'p'): tensor(0.0161), ('e', 'n'): tensor(0.1310), ('n', 'e'): tensor(0.0742), ('a', 'y'): tensor(0.0605), ('y', 'l'): tensor(0.1130), ('&lt;stop&gt;', 'r'): tensor(0.0512), ('e', 'y'): tensor(0.0524), ('&lt;stop&gt;', 'z'): tensor(0.0290), ('z', 'o'): tensor(0.0463), ('&lt;stop&gt;', 'n'): tensor(0.0358), ('n', 'o'): tensor(0.0271), ('e', 'a'): tensor(0.0333), ('a', 'n'): tensor(0.1605), ('n', 'n'): tensor(0.1041), ('a', 'h'): tensor(0.0689), ('d', 'd'): tensor(0.0273), ('a', 'u'): tensor(0.0113), ('u', 'b'): tensor(0.0332), ('b', 'r'): tensor(0.3187), ('r', 'e'): tensor(0.1337), ('i', 'e'): tensor(0.0934), ('s', 't'): tensor(0.0945), ('a', 't'): tensor(0.0203), ('t', 'a'): tensor(0.1846), ('a', 'l'): tensor(0.0746), ('a', 'z'): tensor(0.0129), ('z', 'e'): tensor(0.1560), ('i', 'o'): tensor(0.0333), ('u', 'r'): tensor(0.1324), ('r', 'o'): tensor(0.0685), ('u', 'd'): tensor(0.0437), ('d', 'r'): tensor(0.0773), ('&lt;stop&gt;', 'b'): tensor(0.0408), ('o', 'o'): tensor(0.0146), ('o', 'k'): tensor(0.0087), ('k', 'l'): tensor(0.0278), ('c', 'l'): tensor(0.0331), ('i', 'r'): tensor(0.0480), ('s', 'k'): tensor(0.0102), ('k', 'y'): tensor(0.0754), ('u', 'c'): tensor(0.0332), ('c', 'y'): tensor(0.0297), ('p', 'a'): tensor(0.2047), ('s', 'l'): tensor(0.0345), ('i', 'n'): tensor(0.1202), ('o', 'v'): tensor(0.0223), ('g', 'e'): tensor(0.1738), ('e', 's'): tensor(0.0422), ('s', 'i'): tensor(0.0845), ('s', '&lt;stop&gt;'): tensor(0.1443), ('&lt;stop&gt;', 'k'): tensor(0.0925), ('k', 'e'): tensor(0.1778), ('e', 'd'): tensor(0.0189), ('d', 'y'): tensor(0.0579), ('n', 't'): tensor(0.0242), ('y', 'a'): tensor(0.2193), ('&lt;stop&gt;', 'w'): tensor(0.0096), ('w', 'i'): tensor(0.1604), ('o', 'w'): tensor(0.0145), ('w', '&lt;stop&gt;'): tensor(0.0560), ('k', 'i'): tensor(0.1012), ('n', 's'): tensor(0.0152), ('a', 'o'): tensor(0.0019), ('o', 'm'): tensor(0.0330), ('i', '&lt;stop&gt;'): tensor(0.1407), ('a', 'a'): tensor(0.0164), ('i', 'y'): tensor(0.0441), ('d', 'e'): tensor(0.2336), ('c', 'o'): tensor(0.1079), ('r', 'u'): tensor(0.0199), ('b', 'y'): tensor(0.0318), ('s', 'e'): tensor(0.1092), ('n', 'i'): tensor(0.0942), ('i', 't'): tensor(0.0306), ('t', 'y'): tensor(0.0614), ('u', 't'): tensor(0.0265), ('t', 'u'): tensor(0.0142), ('u', 'm'): tensor(0.0494), ('m', 'n'): tensor(0.0032), ('g', 'i'): tensor(0.0991), ('t', 'i'): tensor(0.0957), ('&lt;stop&gt;', 'q'): tensor(0.0029), ('q', 'u'): tensor(0.7610), ('u', 'i'): tensor(0.0389), ('a', 'e'): tensor(0.0205), ('e', 'h'): tensor(0.0075), ('v', 'y'): tensor(0.0474), ('p', 'i'): tensor(0.0604), ('i', 'p'): tensor(0.0031), ('y', 'd'): tensor(0.0279), ('e', 'x'): tensor(0.0065), ('x', 'a'): tensor(0.1492), ('&lt;stop&gt;', 'j'): tensor(0.0756), ('j', 'o'): tensor(0.1655), ('o', 's'): tensor(0.0637), ('e', 'p'): tensor(0.0041), ('j', 'u'): tensor(0.0700), ('u', 'l'): tensor(0.0963), ('&lt;stop&gt;', 'd'): tensor(0.0528), ('k', 'a'): tensor(0.3437), ('e', 'e'): tensor(0.0623), ('y', 't'): tensor(0.0107), ('d', 'l'): tensor(0.0111), ('c', 'k'): tensor(0.0898), ('n', 'z'): tensor(0.0080), ('z', 'i'): tensor(0.1522), ('a', 'g'): tensor(0.0050), ('d', 'a'): tensor(0.2373), ('j', 'a'): tensor(0.5083), ('h', 'e'): tensor(0.0886), ('&lt;stop&gt;', 'x'): tensor(0.0042), ('x', 'i'): tensor(0.1478), ('i', 'm'): tensor(0.0242), ('e', 'i'): tensor(0.0401), ('&lt;stop&gt;', 't'): tensor(0.0409), ('&lt;stop&gt;', 'f'): tensor(0.0130), ('f', 'a'): tensor(0.2685), ('n', 'd'): tensor(0.0385), ('r', 'g'): tensor(0.0061), ('a', 's'): tensor(0.0330), ('s', 'h'): tensor(0.1586), ('b', 'a'): tensor(0.1217), ('k', 'h'): tensor(0.0611), ('s', 'm'): tensor(0.0112), ('o', 'd'): tensor(0.0241), ('r', 's'): tensor(0.0150), ('g', 'h'): tensor(0.1873), ('s', 'y'): tensor(0.0266), ('y', 's'): tensor(0.0411), ('s', 's'): tensor(0.0570), ('e', 'c'): tensor(0.0075), ('c', 'i'): tensor(0.0770), ('m', 'o'): tensor(0.0682), ('r', 'k'): tensor(0.0072), ('n', 'l'): tensor(0.0107), ('d', 'n'): tensor(0.0058), ('r', 'd'): tensor(0.0148), ('o', 'i'): tensor(0.0088), ('t', 'r'): tensor(0.0634), ('m', 'b'): tensor(0.0170), ('r', 'm'): tensor(0.0128), ('n', 'y'): tensor(0.0254), ('d', 'o'): tensor(0.0690), ('o', 'a'): tensor(0.0189), ('o', 'c'): tensor(0.0145), ('m', 'y'): tensor(0.0434), ('s', 'u'): tensor(0.0229), ('m', 'c'): tensor(0.0078), ('p', 'r'): tensor(0.1481), ('o', 'u'): tensor(0.0348), ('r', 'n'): tensor(0.0111), ('w', 'a'): tensor(0.3025), ('e', 'b'): tensor(0.0060), ('c', 'c'): tensor(0.0122), ('a', 'w'): tensor(0.0048), ('w', 'y'): tensor(0.0797), ('y', 'e'): tensor(0.0309), ('e', 'o'): tensor(0.0132), ('a', 'k'): tensor(0.0168), ('n', 'g'): tensor(0.0150), ('k', 'o'): tensor(0.0685), ('b', 'l'): tensor(0.0393), ('h', 'o'): tensor(0.0378), ('e', 'g'): tensor(0.0062), ('f', 'r'): tensor(0.1271), ('s', 'p'): tensor(0.0064), ('l', 's'): tensor(0.0068), ('y', 'z'): tensor(0.0081), ('g', 'g'): tensor(0.0135), ('z', 'u'): tensor(0.0309), ('i', 'd'): tensor(0.0249), ('m', '&lt;stop&gt;'): tensor(0.0778), ('o', 'g'): tensor(0.0057), ('j', 'e'): tensor(0.1521), ('g', 'n'): tensor(0.0145), ('y', 'r'): tensor(0.0299), ('c', '&lt;stop&gt;'): tensor(0.0277), ('c', 'q'): tensor(0.0034), ('u', 'e'): tensor(0.0542), ('i', 'f'): tensor(0.0058), ('f', 'e'): tensor(0.1370), ('i', 'x'): tensor(0.0051), ('x', '&lt;stop&gt;'): tensor(0.2367), ('o', 'y'): tensor(0.0131), ('g', 'o'): tensor(0.0436), ('g', 't'): tensor(0.0166), ('l', 't'): tensor(0.0056), ('g', 'w'): tensor(0.0140), ('w', 'e'): tensor(0.1615), ('l', 'd'): tensor(0.0100), ('a', 'p'): tensor(0.0024), ('h', 'n'): tensor(0.0183), ('t', 'l'): tensor(0.0242), ('m', 'r'): tensor(0.0148), ('n', 'c'): tensor(0.0117), ('l', 'b'): tensor(0.0038), ('i', 'k'): tensor(0.0252), ('&lt;stop&gt;', 'y'): tensor(0.0167), ('t', 'z'): tensor(0.0190), ('h', 'r'): tensor(0.0269), ('j', 'i'): tensor(0.0414), ('h', 't'): tensor(0.0095), ('r', 'r'): tensor(0.0335), ('z', 'l'): tensor(0.0517), ('w', 'r'): tensor(0.0248), ('b', 'b'): tensor(0.0147), ('r', 't'): tensor(0.0165), ('l', 'v'): tensor(0.0052), ('e', 'j'): tensor(0.0027), ('o', 'h'): tensor(0.0217), ('u', 's'): tensor(0.1515), ('i', 'b'): tensor(0.0063), ('g', 'l'): tensor(0.0171), ('h', 'y'): tensor(0.0281), ('p', 'o'): tensor(0.0585), ('p', 'p'): tensor(0.0390), ('p', 'y'): tensor(0.0127), ('n', 'r'): tensor(0.0025), ('z', 'm'): tensor(0.0150), ('v', 'o'): tensor(0.0599), ('l', 'm'): tensor(0.0044), ('o', 'x'): tensor(0.0058), ('d', '&lt;stop&gt;'): tensor(0.0941), ('i', 'u'): tensor(0.0062), ('v', '&lt;stop&gt;'): tensor(0.0346), ('f', 'f'): tensor(0.0497), ('b', 'o'): tensor(0.0401), ('e', 'k'): tensor(0.0088), ('c', 'r'): tensor(0.0218), ('d', 'g'): tensor(0.0047), ('r', 'c'): tensor(0.0079), ('r', 'h'): tensor(0.0096), ('n', 'k'): tensor(0.0032), ('h', 'u'): tensor(0.0219), ('d', 's'): tensor(0.0055), ('a', 'x'): tensor(0.0054), ('y', 'c'): tensor(0.0119), ('e', 'w'): tensor(0.0025), ('v', 'k'): tensor(0.0016), ('z', 'h'): tensor(0.0183), ('w', 'h'): tensor(0.0258), ('t', 'n'): tensor(0.0041), ('x', 'l'): tensor(0.0574), ('g', 'u'): tensor(0.0446), ('u', 'a'): tensor(0.0523), ('u', 'p'): tensor(0.0054), ('u', 'g'): tensor(0.0153), ('d', 'u'): tensor(0.0169), ('l', 'c'): tensor(0.0019), ('r', 'b'): tensor(0.0033), ('a', 'q'): tensor(0.0018), ('b', '&lt;stop&gt;'): tensor(0.0435), ('g', 'y'): tensor(0.0166), ('y', 'p'): tensor(0.0016), ('p', 't'): tensor(0.0175), ('e', 'z'): tensor(0.0089), ('z', 'r'): tensor(0.0138), ('f', 'l'): tensor(0.0232), ('o', '&lt;stop&gt;'): tensor(0.1079), ('o', 'b'): tensor(0.0178), ('u', 'z'): tensor(0.0147), ('z', '&lt;stop&gt;'): tensor(0.0671), ('i', 'q'): tensor(0.0030), ('y', 'v'): tensor(0.0109), ('n', 'v'): tensor(0.0031), ('d', 'h'): tensor(0.0217), ('g', 'd'): tensor(0.0104), ('t', 's'): tensor(0.0065), ('n', 'h'): tensor(0.0015), ('y', 'j'): tensor(0.0025), ('k', 'r'): tensor(0.0218), ('z', 'b'): tensor(0.0021), ('g', '&lt;stop&gt;'): tensor(0.0566), ('a', 'j'): tensor(0.0052), ('r', 'j'): tensor(0.0020), ('m', 'p'): tensor(0.0059), ('p', 'b'): tensor(0.0029), ('y', 'o'): tensor(0.0278), ('z', 'y'): tensor(0.0617), ('p', 'l'): tensor(0.0166), ('l', 'k'): tensor(0.0018), ('i', 'j'): tensor(0.0044), ('x', 'e'): tensor(0.0531), ('y', 'u'): tensor(0.0145), ('l', 'n'): tensor(0.0011), ('u', 'x'): tensor(0.0112), ('i', 'h'): tensor(0.0054), ('w', 's'): tensor(0.0226), ('k', 's'): tensor(0.0190), ('m', 'u'): tensor(0.0211), ('y', 'k'): tensor(0.0089), ('e', 'f'): tensor(0.0041), ('k', '&lt;stop&gt;'): tensor(0.0722), ('y', 'm'): tensor(0.0152), ('z', 'z'): tensor(0.0192), ('m', 'd'): tensor(0.0038), ('s', 'r'): tensor(0.0069), ('e', 'u'): tensor(0.0034), ('l', 'h'): tensor(0.0014), ('a', 'f'): tensor(0.0040), ('r', 'w'): tensor(0.0017), ('n', 'u'): tensor(0.0053), ('v', 'r'): tensor(0.0190), ('m', 's'): tensor(0.0054), ('&lt;stop&gt;', 'u'): tensor(0.0025), ('f', 's'): tensor(0.0077), ('y', 'b'): tensor(0.0029), ('x', 'o'): tensor(0.0603), ('g', 's'): tensor(0.0161), ('x', 'y'): tensor(0.0445), ('w', 'n'): tensor(0.0635), ('j', 'h'): tensor(0.0159), ('f', 'n'): tensor(0.0055), ('n', 'j'): tensor(0.0025), ('r', 'v'): tensor(0.0064), ('n', 'm'): tensor(0.0011), ('t', 'c'): tensor(0.0032), ('s', 'w'): tensor(0.0031), ('k', 't'): tensor(0.0036), ('f', 't'): tensor(0.0210), ('x', 't'): tensor(0.1019), ('u', 'v'): tensor(0.0121), ('k', 'k'): tensor(0.0042), ('s', 'n'): tensor(0.0031), ('u', '&lt;stop&gt;'): tensor(0.0498), ('j', 'r'): tensor(0.0041), ('y', 'x'): tensor(0.0030), ('h', 'm'): tensor(0.0155), ('e', 'q'): tensor(0.0007), ('u', 'o'): tensor(0.0035), ('f', '&lt;stop&gt;'): tensor(0.0895), ('h', 'z'): tensor(0.0028), ('h', 'k'): tensor(0.0039), ('y', 'g'): tensor(0.0032), ('q', 'r'): tensor(0.0074), ('v', 'n'): tensor(0.0035), ('s', 'd'): tensor(0.0012), ('y', 'i'): tensor(0.0197), ('n', 'w'): tensor(0.0007), ('d', 'v'): tensor(0.0033), ('h', 'v'): tensor(0.0053), ('x', 'w'): tensor(0.0057), ('o', 'z'): tensor(0.0069), ('k', 'u'): tensor(0.0101), ('u', 'h'): tensor(0.0188), ('k', 'n'): tensor(0.0054), ('s', 'b'): tensor(0.0027), ('i', 'i'): tensor(0.0047), ('y', 'y'): tensor(0.0025), ('r', 'z'): tensor(0.0019), ('l', 'g'): tensor(0.0005), ('l', 'p'): tensor(0.0011), ('p', '&lt;stop&gt;'): tensor(0.0331), ('b', 'u'): tensor(0.0174), ('f', 'u'): tensor(0.0122), ('b', 'h'): tensor(0.0159), ('f', 'y'): tensor(0.0166), ('u', 'w'): tensor(0.0278), ('x', 'u'): tensor(0.0086), ('q', '&lt;stop&gt;'): tensor(0.1066), ('l', 'r'): tensor(0.0014), ('m', 'h'): tensor(0.0009), ('l', 'w'): tensor(0.0012), ('j', '&lt;stop&gt;'): tensor(0.0248), ('s', 'v'): tensor(0.0019), ('m', 'l'): tensor(0.0009), ('n', 'f'): tensor(0.0007), ('u', 'j'): tensor(0.0048), ('f', 'o'): tensor(0.0674), ('j', 'l'): tensor(0.0034), ('t', 'g'): tensor(0.0005), ('j', 'm'): tensor(0.0021), ('v', 'v'): tensor(0.0031), ('p', 's'): tensor(0.0166), ('t', 'w'): tensor(0.0022), ('x', 'c'): tensor(0.0072), ('u', 'k'): tensor(0.0300), ('v', 'l'): tensor(0.0058), ('h', 'd'): tensor(0.0033), ('l', 'z'): tensor(0.0008), ('k', 'w'): tensor(0.0069), ('n', 'b'): tensor(0.0005), ('q', 's'): tensor(0.0110), ('i', 'w'): tensor(0.0005), ('c', 's'): tensor(0.0017), ('h', 's'): tensor(0.0042), ('m', 't'): tensor(0.0008), ('h', 'w'): tensor(0.0014), ('x', 'x'): tensor(0.0560), ('t', 'x'): tensor(0.0005), ('d', 'z'): tensor(0.0004), ('x', 'z'): tensor(0.0287), ('t', 'm'): tensor(0.0009), ('t', 'j'): tensor(0.0007), ('u', 'q'): tensor(0.0035), ('q', 'a'): tensor(0.0515), ('f', 'k'): tensor(0.0033), ('z', 'n'): tensor(0.0021), ('l', 'j'): tensor(0.0005), ('j', 'w'): tensor(0.0024), ('v', 'u'): tensor(0.0031), ('c', 'j'): tensor(0.0011), ('h', 'b'): tensor(0.0012), ('z', 't'): tensor(0.0021), ('p', 'u'): tensor(0.0049), ('m', 'z'): tensor(0.0018), ('x', 's'): tensor(0.0459), ('b', 't'): tensor(0.0011), ('u', 'y'): tensor(0.0045), ('d', 'j'): tensor(0.0018), ('j', 's'): tensor(0.0028), ('w', 'u'): tensor(0.0280), ('o', 'j'): tensor(0.0021), ('b', 's'): tensor(0.0034), ('d', 'w'): tensor(0.0044), ('w', 'o'): tensor(0.0398), ('j', 'n'): tensor(0.0010), ('w', 't'): tensor(0.0097), ('l', 'f'): tensor(0.0016), ('d', 'm'): tensor(0.0056), ('p', 'j'): tensor(0.0019), ('j', 'y'): tensor(0.0038), ('y', 'f'): tensor(0.0013), ('q', 'i'): tensor(0.0515), ('j', 'v'): tensor(0.0021), ('q', 'l'): tensor(0.0074), ('s', 'z'): tensor(0.0014), ('k', 'm'): tensor(0.0020), ('w', 'l'): tensor(0.0151), ('p', 'f'): tensor(0.0019), ('q', 'w'): tensor(0.0147), ('n', 'x'): tensor(0.0004), ('k', 'c'): tensor(0.0006), ('t', 'v'): tensor(0.0029), ('c', 'u'): tensor(0.0102), ('z', 'k'): tensor(0.0013), ('c', 'z'): tensor(0.0014), ('y', 'q'): tensor(0.0007), ('y', 'h'): tensor(0.0024), ('r', 'f'): tensor(0.0008), ('s', 'j'): tensor(0.0004), ('h', 'j'): tensor(0.0013), ('g', 'b'): tensor(0.0021), ('u', 'f'): tensor(0.0064), ('s', 'f'): tensor(0.0004), ('q', 'e'): tensor(0.0074), ('b', 'c'): tensor(0.0008), ('c', 'd'): tensor(0.0006), ('z', 'j'): tensor(0.0013), ('n', 'q'): tensor(0.0002), ('m', 'f'): tensor(0.0003), ('p', 'n'): tensor(0.0019), ('f', 'z'): tensor(0.0033), ('b', 'n'): tensor(0.0019), ('w', 'd'): tensor(0.0097), ('w', 'b'): tensor(0.0022), ('b', 'd'): tensor(0.0250), ('z', 's'): tensor(0.0021), ('p', 'c'): tensor(0.0019), ('h', 'g'): tensor(0.0004), ('m', 'j'): tensor(0.0012), ('w', 'w'): tensor(0.0032), ('k', 'j'): tensor(0.0006), ('h', 'p'): tensor(0.0003), ('j', 'k'): tensor(0.0010), ('o', 'q'): tensor(0.0005), ('f', 'w'): tensor(0.0055), ('f', 'h'): tensor(0.0022), ('w', 'm'): tensor(0.0032), ('b', 'j'): tensor(0.0008), ('r', 'q'): tensor(0.0013), ('z', 'c'): tensor(0.0013), ('z', 'v'): tensor(0.0013), ('f', 'g'): tensor(0.0022), ('n', 'p'): tensor(0.0003), ('z', 'g'): tensor(0.0008), ('d', 't'): tensor(0.0009), ('w', 'f'): tensor(0.0032), ('d', 'f'): tensor(0.0011), ('w', 'k'): tensor(0.0075), ('q', 'm'): tensor(0.0110), ('k', 'z'): tensor(0.0006), ('j', 'j'): tensor(0.0010), ('c', 'p'): tensor(0.0006), ('p', 'k'): tensor(0.0019), ('p', 'm'): tensor(0.0019), ('j', 'd'): tensor(0.0017), ('r', 'x'): tensor(0.0003), ('x', 'n'): tensor(0.0029), ('d', 'c'): tensor(0.0007), ('g', 'j'): tensor(0.0021), ('x', 'f'): tensor(0.0057), ('j', 'c'): tensor(0.0017), ('s', 'q'): tensor(0.0002), ('k', 'f'): tensor(0.0004), ('z', 'p'): tensor(0.0013), ('j', 't'): tensor(0.0010), ('k', 'b'): tensor(0.0006), ('m', 'k'): tensor(0.0003), ('m', 'w'): tensor(0.0005), ('x', 'h'): tensor(0.0029), ('h', 'f'): tensor(0.0004), ('x', 'd'): tensor(0.0086), ('y', 'w'): tensor(0.0005), ('z', 'w'): tensor(0.0017), ('d', 'k'): tensor(0.0007), ('c', 'g'): tensor(0.0008), ('u', 'u'): tensor(0.0013), ('t', 'f'): tensor(0.0005), ('g', 'm'): tensor(0.0036), ('m', 'v'): tensor(0.0006), ('c', 'x'): tensor(0.0011), ('h', 'c'): tensor(0.0004), ('g', 'f'): tensor(0.0010), ('q', 'o'): tensor(0.0110), ('l', 'q'): tensor(0.0003), ('v', 'b'): tensor(0.0008), ('j', 'p'): tensor(0.0007), ('k', 'd'): tensor(0.0006), ('g', 'z'): tensor(0.0010), ('v', 'd'): tensor(0.0008), ('d', 'b'): tensor(0.0004), ('v', 'h'): tensor(0.0008), ('k', 'v'): tensor(0.0006), ('h', 'h'): tensor(0.0003), ('s', 'g'): tensor(0.0004), ('g', 'v'): tensor(0.0010), ('d', 'q'): tensor(0.0004), ('x', 'b'): tensor(0.0029), ('w', 'z'): tensor(0.0022), ('h', 'q'): tensor(0.0003), ('j', 'b'): tensor(0.0007), ('z', 'd'): tensor(0.0013), ('x', 'm'): tensor(0.0029), ('w', 'g'): tensor(0.0022), ('t', 'b'): tensor(0.0004), ('z', 'x'): tensor(0.0008)}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>bigram_p_sorted <span class="op">=</span> {k: v.<span class="bu">float</span>() <span class="cf">for</span> k, v <span class="kw">in</span> <span class="bu">sorted</span>(bigram_p.items(), reverse<span class="op">=</span><span class="va">True</span>, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>])}</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bigram_p_sorted)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{('q', 'u'): tensor(0.7610), ('j', 'a'): tensor(0.5083), ('m', 'a'): tensor(0.3901), ('n', '&lt;stop&gt;'): tensor(0.3691), ('z', 'a'): tensor(0.3590), ('v', 'i'): tensor(0.3545), ('k', 'a'): tensor(0.3437), ('b', 'r'): tensor(0.3187), ('h', '&lt;stop&gt;'): tensor(0.3164), ('o', 'n'): tensor(0.3040), ('w', 'a'): tensor(0.3025), ('h', 'a'): tensor(0.2948), ('f', 'a'): tensor(0.2685), ('v', 'a'): tensor(0.2499), ('b', 'e'): tensor(0.2480), ('r', 'i'): tensor(0.2389), ('d', 'a'): tensor(0.2373), ('x', '&lt;stop&gt;'): tensor(0.2367), ('d', 'e'): tensor(0.2336), ('c', 'a'): tensor(0.2310), ('v', 'e'): tensor(0.2211), ('y', 'a'): tensor(0.2193), ('l', 'e'): tensor(0.2093), ('y', '&lt;stop&gt;'): tensor(0.2054), ('p', 'a'): tensor(0.2047), ('p', 'h'): tensor(0.1998), ('a', '&lt;stop&gt;'): tensor(0.1960), ('e', '&lt;stop&gt;'): tensor(0.1951), ('p', 'e'): tensor(0.1930), ('m', 'i'): tensor(0.1893), ('c', 'h'): tensor(0.1883), ('l', 'a'): tensor(0.1880), ('g', 'h'): tensor(0.1873), ('y', 'n'): tensor(0.1869), ('r', 'a'): tensor(0.1856), ('t', 'a'): tensor(0.1846), ('f', 'i'): tensor(0.1779), ('k', 'e'): tensor(0.1778), ('l', 'i'): tensor(0.1777), ('g', 'e'): tensor(0.1738), ('g', 'a'): tensor(0.1718), ('j', 'o'): tensor(0.1655), ('n', 'a'): tensor(0.1625), ('w', 'e'): tensor(0.1615), ('a', 'n'): tensor(0.1605), ('w', 'i'): tensor(0.1604), ('e', 'l'): tensor(0.1591), ('s', 'h'): tensor(0.1586), ('c', 'e'): tensor(0.1563), ('z', 'e'): tensor(0.1560), ('z', 'i'): tensor(0.1522), ('j', 'e'): tensor(0.1521), ('u', 's'): tensor(0.1515), ('x', 'a'): tensor(0.1492), ('s', 'a'): tensor(0.1483), ('p', 'r'): tensor(0.1481), ('x', 'i'): tensor(0.1478), ('s', '&lt;stop&gt;'): tensor(0.1443), ('i', '&lt;stop&gt;'): tensor(0.1407), ('i', 'a'): tensor(0.1382), ('&lt;stop&gt;', 'a'): tensor(0.1377), ('f', 'e'): tensor(0.1370), ('r', 'e'): tensor(0.1337), ('o', 'r'): tensor(0.1336), ('u', 'r'): tensor(0.1324), ('e', 'n'): tensor(0.1310), ('t', 'e'): tensor(0.1287), ('f', 'r'): tensor(0.1271), ('m', 'e'): tensor(0.1233), ('d', 'i'): tensor(0.1228), ('b', 'a'): tensor(0.1217), ('i', 'n'): tensor(0.1202), ('t', 'o'): tensor(0.1199), ('t', 'h'): tensor(0.1163), ('l', 'y'): tensor(0.1138), ('y', 'l'): tensor(0.1130), ('s', 'e'): tensor(0.1092), ('r', '&lt;stop&gt;'): tensor(0.1085), ('o', '&lt;stop&gt;'): tensor(0.1079), ('c', 'o'): tensor(0.1079), ('q', '&lt;stop&gt;'): tensor(0.1066), ('g', 'r'): tensor(0.1048), ('n', 'n'): tensor(0.1041), ('x', 't'): tensor(0.1019), ('k', 'i'): tensor(0.1012), ('g', 'i'): tensor(0.0991), ('l', 'l'): tensor(0.0964), ('a', 'r'): tensor(0.0964), ('u', 'l'): tensor(0.0963), ('e', 'r'): tensor(0.0959), ('h', 'i'): tensor(0.0959), ('t', 'i'): tensor(0.0957), ('s', 't'): tensor(0.0945), ('l', '&lt;stop&gt;'): tensor(0.0942), ('n', 'i'): tensor(0.0942), ('d', '&lt;stop&gt;'): tensor(0.0941), ('i', 'e'): tensor(0.0934), ('&lt;stop&gt;', 'k'): tensor(0.0925), ('c', 'k'): tensor(0.0898), ('f', '&lt;stop&gt;'): tensor(0.0895), ('h', 'e'): tensor(0.0886), ('u', 'n'): tensor(0.0880), ('t', '&lt;stop&gt;'): tensor(0.0869), ('s', 'i'): tensor(0.0845), ('b', 'i'): tensor(0.0824), ('w', 'y'): tensor(0.0797), ('&lt;stop&gt;', 'm'): tensor(0.0793), ('o', 'l'): tensor(0.0781), ('m', '&lt;stop&gt;'): tensor(0.0778), ('d', 'r'): tensor(0.0773), ('c', 'i'): tensor(0.0770), ('i', 'l'): tensor(0.0760), ('&lt;stop&gt;', 'j'): tensor(0.0756), ('k', 'y'): tensor(0.0754), ('a', 'l'): tensor(0.0746), ('i', 's'): tensor(0.0744), ('n', 'e'): tensor(0.0742), ('k', '&lt;stop&gt;'): tensor(0.0722), ('j', 'u'): tensor(0.0700), ('d', 'o'): tensor(0.0690), ('a', 'h'): tensor(0.0689), ('r', 'o'): tensor(0.0685), ('k', 'o'): tensor(0.0685), ('m', 'o'): tensor(0.0682), ('f', 'o'): tensor(0.0674), ('t', 't'): tensor(0.0673), ('z', '&lt;stop&gt;'): tensor(0.0671), ('s', 'o'): tensor(0.0656), ('&lt;stop&gt;', 's'): tensor(0.0642), ('o', 's'): tensor(0.0637), ('w', 'n'): tensor(0.0635), ('t', 'r'): tensor(0.0634), ('e', 'e'): tensor(0.0623), ('z', 'y'): tensor(0.0617), ('t', 'y'): tensor(0.0614), ('k', 'h'): tensor(0.0611), ('r', 'y'): tensor(0.0609), ('a', 'y'): tensor(0.0605), ('p', 'i'): tensor(0.0604), ('x', 'o'): tensor(0.0603), ('v', 'o'): tensor(0.0599), ('p', 'o'): tensor(0.0585), ('d', 'y'): tensor(0.0579), ('x', 'l'): tensor(0.0574), ('s', 's'): tensor(0.0570), ('g', '&lt;stop&gt;'): tensor(0.0566), ('w', '&lt;stop&gt;'): tensor(0.0560), ('x', 'x'): tensor(0.0560), ('u', 'e'): tensor(0.0542), ('x', 'e'): tensor(0.0531), ('&lt;stop&gt;', 'd'): tensor(0.0528), ('e', 'y'): tensor(0.0524), ('u', 'a'): tensor(0.0523), ('z', 'l'): tensor(0.0517), ('q', 'a'): tensor(0.0515), ('q', 'i'): tensor(0.0515), ('&lt;stop&gt;', 'r'): tensor(0.0512), ('u', '&lt;stop&gt;'): tensor(0.0498), ('f', 'f'): tensor(0.0497), ('l', 'o'): tensor(0.0496), ('u', 'm'): tensor(0.0494), ('&lt;stop&gt;', 'l'): tensor(0.0491), ('a', 'i'): tensor(0.0487), ('a', 'm'): tensor(0.0483), ('&lt;stop&gt;', 'c'): tensor(0.0482), ('i', 'r'): tensor(0.0480), ('&lt;stop&gt;', 'e'): tensor(0.0478), ('v', 'y'): tensor(0.0474), ('z', 'o'): tensor(0.0463), ('x', 's'): tensor(0.0459), ('g', 'u'): tensor(0.0446), ('x', 'y'): tensor(0.0445), ('i', 'y'): tensor(0.0441), ('u', 'd'): tensor(0.0437), ('g', 'o'): tensor(0.0436), ('b', '&lt;stop&gt;'): tensor(0.0435), ('m', 'y'): tensor(0.0434), ('e', 's'): tensor(0.0422), ('j', 'i'): tensor(0.0414), ('y', 's'): tensor(0.0411), ('&lt;stop&gt;', 't'): tensor(0.0409), ('&lt;stop&gt;', 'b'): tensor(0.0408), ('e', 'i'): tensor(0.0401), ('b', 'o'): tensor(0.0401), ('w', 'o'): tensor(0.0398), ('b', 'l'): tensor(0.0393), ('p', 'p'): tensor(0.0390), ('u', 'i'): tensor(0.0389), ('n', 'd'): tensor(0.0385), ('h', 'o'): tensor(0.0378), ('e', 'm'): tensor(0.0377), ('&lt;stop&gt;', 'n'): tensor(0.0358), ('o', 'u'): tensor(0.0348), ('v', '&lt;stop&gt;'): tensor(0.0346), ('s', 'l'): tensor(0.0345), ('r', 'r'): tensor(0.0335), ('e', 'a'): tensor(0.0333), ('i', 'o'): tensor(0.0333), ('u', 'b'): tensor(0.0332), ('u', 'c'): tensor(0.0332), ('p', '&lt;stop&gt;'): tensor(0.0331), ('c', 'l'): tensor(0.0331), ('a', 's'): tensor(0.0330), ('o', 'm'): tensor(0.0330), ('r', 'l'): tensor(0.0326), ('b', 'y'): tensor(0.0318), ('y', 'e'): tensor(0.0309), ('z', 'u'): tensor(0.0309), ('a', 'd'): tensor(0.0308), ('i', 't'): tensor(0.0306), ('u', 'k'): tensor(0.0300), ('y', 'r'): tensor(0.0299), ('c', 'y'): tensor(0.0297), ('&lt;stop&gt;', 'z'): tensor(0.0290), ('i', 'c'): tensor(0.0288), ('x', 'z'): tensor(0.0287), ('e', 't'): tensor(0.0284), ('h', 'y'): tensor(0.0281), ('w', 'u'): tensor(0.0280), ('y', 'd'): tensor(0.0279), ('y', 'o'): tensor(0.0278), ('k', 'l'): tensor(0.0278), ('u', 'w'): tensor(0.0278), ('c', '&lt;stop&gt;'): tensor(0.0277), ('&lt;stop&gt;', 'h'): tensor(0.0273), ('d', 'd'): tensor(0.0273), ('n', 'o'): tensor(0.0271), ('h', 'r'): tensor(0.0269), ('s', 'y'): tensor(0.0266), ('u', 't'): tensor(0.0265), ('w', 'h'): tensor(0.0258), ('m', 'm'): tensor(0.0254), ('n', 'y'): tensor(0.0254), ('i', 'k'): tensor(0.0252), ('b', 'd'): tensor(0.0250), ('i', 'd'): tensor(0.0249), ('j', '&lt;stop&gt;'): tensor(0.0248), ('w', 'r'): tensor(0.0248), ('a', 'v'): tensor(0.0246), ('h', 'l'): tensor(0.0244), ('t', 'l'): tensor(0.0242), ('i', 'g'): tensor(0.0242), ('n', 't'): tensor(0.0242), ('i', 'm'): tensor(0.0242), ('o', 'd'): tensor(0.0241), ('l', 'u'): tensor(0.0233), ('f', 'l'): tensor(0.0232), ('s', 'u'): tensor(0.0229), ('e', 'v'): tensor(0.0227), ('w', 's'): tensor(0.0226), ('o', 'v'): tensor(0.0223), ('h', 'u'): tensor(0.0219), ('k', 'r'): tensor(0.0218), ('c', 'r'): tensor(0.0218), ('o', 'h'): tensor(0.0217), ('d', 'h'): tensor(0.0217), ('m', 'u'): tensor(0.0211), ('f', 't'): tensor(0.0210), ('&lt;stop&gt;', 'g'): tensor(0.0209), ('a', 'e'): tensor(0.0205), ('a', 't'): tensor(0.0203), ('r', 'u'): tensor(0.0199), ('y', 'i'): tensor(0.0197), ('z', 'z'): tensor(0.0192), ('k', 's'): tensor(0.0190), ('v', 'r'): tensor(0.0190), ('t', 'z'): tensor(0.0190), ('o', 'a'): tensor(0.0189), ('e', 'd'): tensor(0.0189), ('u', 'h'): tensor(0.0188), ('&lt;stop&gt;', 'i'): tensor(0.0185), ('z', 'h'): tensor(0.0183), ('h', 'n'): tensor(0.0183), ('o', 'b'): tensor(0.0178), ('p', 't'): tensor(0.0175), ('b', 'u'): tensor(0.0174), ('g', 'l'): tensor(0.0171), ('m', 'b'): tensor(0.0170), ('d', 'u'): tensor(0.0169), ('a', 'k'): tensor(0.0168), ('o', 'e'): tensor(0.0168), ('&lt;stop&gt;', 'y'): tensor(0.0167), ('g', 't'): tensor(0.0166), ('g', 'y'): tensor(0.0166), ('f', 'y'): tensor(0.0166), ('p', 'l'): tensor(0.0166), ('p', 's'): tensor(0.0166), ('r', 't'): tensor(0.0165), ('a', 'a'): tensor(0.0164), ('&lt;stop&gt;', 'p'): tensor(0.0161), ('g', 's'): tensor(0.0161), ('a', 'b'): tensor(0.0160), ('b', 'h'): tensor(0.0159), ('j', 'h'): tensor(0.0159), ('i', 'z'): tensor(0.0157), ('h', 'm'): tensor(0.0155), ('u', 'g'): tensor(0.0153), ('i', 'v'): tensor(0.0153), ('y', 'm'): tensor(0.0152), ('n', 's'): tensor(0.0152), ('w', 'l'): tensor(0.0151), ('r', 's'): tensor(0.0150), ('z', 'm'): tensor(0.0150), ('o', 't'): tensor(0.0150), ('n', 'g'): tensor(0.0150), ('r', 'd'): tensor(0.0148), ('m', 'r'): tensor(0.0148), ('b', 'b'): tensor(0.0147), ('q', 'w'): tensor(0.0147), ('u', 'z'): tensor(0.0147), ('o', 'o'): tensor(0.0146), ('g', 'n'): tensor(0.0145), ('y', 'u'): tensor(0.0145), ('o', 'w'): tensor(0.0145), ('o', 'c'): tensor(0.0145), ('t', 'u'): tensor(0.0142), ('g', 'w'): tensor(0.0140), ('a', 'c'): tensor(0.0139), ('z', 'r'): tensor(0.0138), ('g', 'g'): tensor(0.0135), ('e', 'o'): tensor(0.0132), ('o', 'y'): tensor(0.0131), ('&lt;stop&gt;', 'f'): tensor(0.0130), ('a', 'z'): tensor(0.0129), ('r', 'm'): tensor(0.0128), ('p', 'y'): tensor(0.0127), ('&lt;stop&gt;', 'o'): tensor(0.0123), ('c', 'c'): tensor(0.0122), ('f', 'u'): tensor(0.0122), ('u', 'v'): tensor(0.0121), ('o', 'p'): tensor(0.0121), ('y', 'c'): tensor(0.0119), ('&lt;stop&gt;', 'v'): tensor(0.0118), ('n', 'c'): tensor(0.0117), ('a', 'u'): tensor(0.0113), ('s', 'm'): tensor(0.0112), ('u', 'x'): tensor(0.0112), ('r', 'n'): tensor(0.0111), ('d', 'l'): tensor(0.0111), ('q', 's'): tensor(0.0110), ('q', 'm'): tensor(0.0110), ('q', 'o'): tensor(0.0110), ('y', 'v'): tensor(0.0109), ('y', 't'): tensor(0.0107), ('n', 'l'): tensor(0.0107), ('g', 'd'): tensor(0.0104), ('s', 'k'): tensor(0.0102), ('c', 't'): tensor(0.0102), ('c', 'u'): tensor(0.0102), ('k', 'u'): tensor(0.0101), ('l', 'd'): tensor(0.0100), ('w', 't'): tensor(0.0097), ('w', 'd'): tensor(0.0097), ('&lt;stop&gt;', 'w'): tensor(0.0096), ('r', 'h'): tensor(0.0096), ('h', 't'): tensor(0.0095), ('e', 'z'): tensor(0.0089), ('y', 'k'): tensor(0.0089), ('o', 'i'): tensor(0.0088), ('e', 'k'): tensor(0.0088), ('o', 'k'): tensor(0.0087), ('x', 'u'): tensor(0.0086), ('x', 'd'): tensor(0.0086), ('y', 'z'): tensor(0.0081), ('n', 'z'): tensor(0.0080), ('r', 'c'): tensor(0.0079), ('m', 'c'): tensor(0.0078), ('f', 's'): tensor(0.0077), ('e', 'c'): tensor(0.0075), ('w', 'k'): tensor(0.0075), ('s', 'c'): tensor(0.0075), ('e', 'h'): tensor(0.0075), ('q', 'r'): tensor(0.0074), ('q', 'l'): tensor(0.0074), ('q', 'e'): tensor(0.0074), ('x', 'c'): tensor(0.0072), ('r', 'k'): tensor(0.0072), ('k', 'w'): tensor(0.0069), ('o', 'z'): tensor(0.0069), ('s', 'r'): tensor(0.0069), ('l', 's'): tensor(0.0068), ('e', 'x'): tensor(0.0065), ('t', 's'): tensor(0.0065), ('s', 'p'): tensor(0.0064), ('u', 'f'): tensor(0.0064), ('r', 'v'): tensor(0.0064), ('i', 'b'): tensor(0.0063), ('i', 'u'): tensor(0.0062), ('e', 'g'): tensor(0.0062), ('r', 'g'): tensor(0.0061), ('e', 'b'): tensor(0.0060), ('m', 'p'): tensor(0.0059), ('v', 'l'): tensor(0.0058), ('d', 'n'): tensor(0.0058), ('o', 'x'): tensor(0.0058), ('i', 'f'): tensor(0.0058), ('x', 'w'): tensor(0.0057), ('x', 'f'): tensor(0.0057), ('o', 'g'): tensor(0.0057), ('d', 'm'): tensor(0.0056), ('l', 't'): tensor(0.0056), ('f', 'n'): tensor(0.0055), ('f', 'w'): tensor(0.0055), ('d', 's'): tensor(0.0055), ('i', 'h'): tensor(0.0054), ('u', 'p'): tensor(0.0054), ('m', 's'): tensor(0.0054), ('a', 'x'): tensor(0.0054), ('k', 'n'): tensor(0.0054), ('n', 'u'): tensor(0.0053), ('h', 'v'): tensor(0.0053), ('l', 'v'): tensor(0.0052), ('a', 'j'): tensor(0.0052), ('i', 'x'): tensor(0.0051), ('a', 'g'): tensor(0.0050), ('p', 'u'): tensor(0.0049), ('u', 'j'): tensor(0.0048), ('a', 'w'): tensor(0.0048), ('d', 'g'): tensor(0.0047), ('i', 'i'): tensor(0.0047), ('u', 'y'): tensor(0.0045), ('o', 'f'): tensor(0.0044), ('l', 'm'): tensor(0.0044), ('d', 'w'): tensor(0.0044), ('i', 'j'): tensor(0.0044), ('&lt;stop&gt;', 'x'): tensor(0.0042), ('h', 's'): tensor(0.0042), ('k', 'k'): tensor(0.0042), ('j', 'r'): tensor(0.0041), ('t', 'n'): tensor(0.0041), ('e', 'p'): tensor(0.0041), ('e', 'f'): tensor(0.0041), ('a', 'f'): tensor(0.0040), ('h', 'k'): tensor(0.0039), ('l', 'b'): tensor(0.0038), ('j', 'y'): tensor(0.0038), ('m', 'd'): tensor(0.0038), ('g', 'm'): tensor(0.0036), ('k', 't'): tensor(0.0036), ('u', 'o'): tensor(0.0035), ('u', 'q'): tensor(0.0035), ('v', 'n'): tensor(0.0035), ('j', 'l'): tensor(0.0034), ('e', 'u'): tensor(0.0034), ('b', 's'): tensor(0.0034), ('c', 'q'): tensor(0.0034), ('f', 'k'): tensor(0.0033), ('f', 'z'): tensor(0.0033), ('r', 'b'): tensor(0.0033), ('h', 'd'): tensor(0.0033), ('d', 'v'): tensor(0.0033), ('t', 'c'): tensor(0.0032), ('w', 'w'): tensor(0.0032), ('w', 'm'): tensor(0.0032), ('w', 'f'): tensor(0.0032), ('n', 'k'): tensor(0.0032), ('y', 'g'): tensor(0.0032), ('m', 'n'): tensor(0.0032), ('v', 'v'): tensor(0.0031), ('v', 'u'): tensor(0.0031), ('s', 'w'): tensor(0.0031), ('s', 'n'): tensor(0.0031), ('n', 'v'): tensor(0.0031), ('i', 'p'): tensor(0.0031), ('i', 'q'): tensor(0.0030), ('y', 'x'): tensor(0.0030), ('p', 'b'): tensor(0.0029), ('&lt;stop&gt;', 'q'): tensor(0.0029), ('t', 'v'): tensor(0.0029), ('x', 'n'): tensor(0.0029), ('x', 'h'): tensor(0.0029), ('x', 'b'): tensor(0.0029), ('x', 'm'): tensor(0.0029), ('y', 'b'): tensor(0.0029), ('j', 's'): tensor(0.0028), ('h', 'z'): tensor(0.0028), ('e', 'j'): tensor(0.0027), ('s', 'b'): tensor(0.0027), ('e', 'w'): tensor(0.0025), ('&lt;stop&gt;', 'u'): tensor(0.0025), ('n', 'r'): tensor(0.0025), ('n', 'j'): tensor(0.0025), ('y', 'j'): tensor(0.0025), ('y', 'y'): tensor(0.0025), ('a', 'p'): tensor(0.0024), ('j', 'w'): tensor(0.0024), ('y', 'h'): tensor(0.0024), ('f', 'h'): tensor(0.0022), ('f', 'g'): tensor(0.0022), ('t', 'w'): tensor(0.0022), ('w', 'b'): tensor(0.0022), ('w', 'z'): tensor(0.0022), ('w', 'g'): tensor(0.0022), ('o', 'j'): tensor(0.0021), ('z', 'b'): tensor(0.0021), ('z', 'n'): tensor(0.0021), ('z', 't'): tensor(0.0021), ('z', 's'): tensor(0.0021), ('g', 'b'): tensor(0.0021), ('g', 'j'): tensor(0.0021), ('j', 'm'): tensor(0.0021), ('j', 'v'): tensor(0.0021), ('r', 'j'): tensor(0.0020), ('k', 'm'): tensor(0.0020), ('p', 'j'): tensor(0.0019), ('p', 'f'): tensor(0.0019), ('p', 'n'): tensor(0.0019), ('p', 'c'): tensor(0.0019), ('p', 'k'): tensor(0.0019), ('p', 'm'): tensor(0.0019), ('b', 'n'): tensor(0.0019), ('r', 'z'): tensor(0.0019), ('a', 'o'): tensor(0.0019), ('l', 'c'): tensor(0.0019), ('s', 'v'): tensor(0.0019), ('d', 'j'): tensor(0.0018), ('m', 'z'): tensor(0.0018), ('a', 'q'): tensor(0.0018), ('l', 'k'): tensor(0.0018), ('r', 'w'): tensor(0.0017), ('j', 'd'): tensor(0.0017), ('j', 'c'): tensor(0.0017), ('c', 's'): tensor(0.0017), ('z', 'w'): tensor(0.0017), ('l', 'f'): tensor(0.0016), ('y', 'p'): tensor(0.0016), ('v', 'k'): tensor(0.0016), ('n', 'h'): tensor(0.0015), ('h', 'w'): tensor(0.0014), ('l', 'h'): tensor(0.0014), ('c', 'z'): tensor(0.0014), ('l', 'r'): tensor(0.0014), ('s', 'z'): tensor(0.0014), ('r', 'q'): tensor(0.0013), ('y', 'f'): tensor(0.0013), ('h', 'j'): tensor(0.0013), ('u', 'u'): tensor(0.0013), ('z', 'k'): tensor(0.0013), ('z', 'j'): tensor(0.0013), ('z', 'c'): tensor(0.0013), ('z', 'v'): tensor(0.0013), ('z', 'p'): tensor(0.0013), ('z', 'd'): tensor(0.0013), ('s', 'd'): tensor(0.0012), ('l', 'w'): tensor(0.0012), ('m', 'j'): tensor(0.0012), ('h', 'b'): tensor(0.0012), ('r', 'p'): tensor(0.0012), ('l', 'p'): tensor(0.0011), ('b', 't'): tensor(0.0011), ('c', 'j'): tensor(0.0011), ('c', 'x'): tensor(0.0011), ('d', 'f'): tensor(0.0011), ('n', 'm'): tensor(0.0011), ('l', 'n'): tensor(0.0011), ('g', 'f'): tensor(0.0010), ('g', 'z'): tensor(0.0010), ('g', 'v'): tensor(0.0010), ('j', 'n'): tensor(0.0010), ('j', 'k'): tensor(0.0010), ('j', 'j'): tensor(0.0010), ('j', 't'): tensor(0.0010), ('d', 't'): tensor(0.0009), ('m', 'h'): tensor(0.0009), ('m', 'l'): tensor(0.0009), ('t', 'm'): tensor(0.0009), ('c', 'g'): tensor(0.0008), ('z', 'g'): tensor(0.0008), ('z', 'x'): tensor(0.0008), ('l', 'z'): tensor(0.0008), ('r', 'f'): tensor(0.0008), ('v', 'b'): tensor(0.0008), ('v', 'd'): tensor(0.0008), ('v', 'h'): tensor(0.0008), ('b', 'c'): tensor(0.0008), ('b', 'j'): tensor(0.0008), ('m', 't'): tensor(0.0008), ('e', 'q'): tensor(0.0007), ('d', 'c'): tensor(0.0007), ('d', 'k'): tensor(0.0007), ('t', 'j'): tensor(0.0007), ('y', 'q'): tensor(0.0007), ('j', 'p'): tensor(0.0007), ('j', 'b'): tensor(0.0007), ('n', 'w'): tensor(0.0007), ('n', 'f'): tensor(0.0007), ('m', 'v'): tensor(0.0006), ('k', 'c'): tensor(0.0006), ('k', 'j'): tensor(0.0006), ('k', 'z'): tensor(0.0006), ('k', 'b'): tensor(0.0006), ('k', 'd'): tensor(0.0006), ('k', 'v'): tensor(0.0006), ('c', 'd'): tensor(0.0006), ('c', 'p'): tensor(0.0006), ('t', 'g'): tensor(0.0005), ('t', 'x'): tensor(0.0005), ('t', 'f'): tensor(0.0005), ('y', 'w'): tensor(0.0005), ('i', 'w'): tensor(0.0005), ('o', 'q'): tensor(0.0005), ('l', 'g'): tensor(0.0005), ('l', 'j'): tensor(0.0005), ('n', 'b'): tensor(0.0005), ('m', 'w'): tensor(0.0005), ('k', 'f'): tensor(0.0004), ('h', 'g'): tensor(0.0004), ('h', 'f'): tensor(0.0004), ('h', 'c'): tensor(0.0004), ('n', 'x'): tensor(0.0004), ('s', 'j'): tensor(0.0004), ('s', 'f'): tensor(0.0004), ('s', 'g'): tensor(0.0004), ('d', 'z'): tensor(0.0004), ('d', 'b'): tensor(0.0004), ('d', 'q'): tensor(0.0004), ('t', 'b'): tensor(0.0004), ('n', 'p'): tensor(0.0003), ('r', 'x'): tensor(0.0003), ('m', 'f'): tensor(0.0003), ('m', 'k'): tensor(0.0003), ('l', 'q'): tensor(0.0003), ('h', 'p'): tensor(0.0003), ('h', 'h'): tensor(0.0003), ('h', 'q'): tensor(0.0003), ('s', 'q'): tensor(0.0002), ('n', 'q'): tensor(0.0002)}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># likelihood of full corpus = product of all bigram prods</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>l <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bigram, prob <span class="kw">in</span> bigram_p_sorted.items():</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    l <span class="op">+=</span> torch.log(prob)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># negative log likelihood loss nll</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>nll <span class="op">=</span> <span class="op">-</span>l <span class="op">/</span><span class="bu">len</span>(bigram_p_sorted)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(nll)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(4.4447)</code></pre>
</div>
</div>
</section>
<section id="generate-training-data" class="level3">
<h3 class="anchored" data-anchor-id="generate-training-data">Generate training data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>word <span class="op">=</span> <span class="st">"this"</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> [(word[i], word[i<span class="op">+</span><span class="dv">1</span>]) <span class="cf">for</span> i,c <span class="kw">in</span> <span class="bu">enumerate</span>(word) <span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(word)<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(<span class="bu">zip</span>(<span class="op">*</span>sample)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[('t', 'h', 'i'), ('h', 'i', 's')]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>xs, ys <span class="op">=</span> [], []</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> word <span class="kw">in</span> data:</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> [(stoi[word[i]], stoi[word[i<span class="op">+</span><span class="dv">1</span>]]) <span class="cf">for</span> i,c <span class="kw">in</span> <span class="bu">enumerate</span>(word) <span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(word)<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(<span class="op">*</span>sample)) <span class="co"># inverse of zip</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    xs.append(torch.tensor(x))</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    ys.append(torch.tensor(y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xs[:<span class="dv">3</span>], ys[:<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[tensor([ 4, 12, 12]), tensor([14, 11,  8, 21,  8]), tensor([ 0, 21])] [tensor([12, 12,  0]), tensor([11,  8, 21,  8,  0]), tensor([21,  0])]</code></pre>
</div>
</div>
</section>
<section id="hot-encoded-input" class="level3">
<h3 class="anchored" data-anchor-id="hot-encoded-input">1-hot encoded input</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>enc <span class="op">=</span> [F.one_hot(x, num_classes<span class="op">=</span><span class="bu">len</span>(tokens)).<span class="bu">float</span>() <span class="cf">for</span> x <span class="kw">in</span> xs]</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(enc[:<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 1., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 1., 0., 0., 0., 0., 0.]])]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(enc[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;matplotlib.image.AxesImage&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="models.ngram_files/figure-html/cell-24-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> enc[<span class="dv">0</span>]</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 27])</code></pre>
</div>
</div>
</section>
<section id="neural-net-modeling" class="level3">
<h3 class="anchored" data-anchor-id="neural-net-modeling">‘Neural net’ modeling</h3>
<p>we model the transition probability matrix by neural net activations</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> torch.randn(<span class="dv">27</span>, <span class="dv">27</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> X <span class="op">@</span> W</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> logits.exp()</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> counts <span class="op">/</span> counts.<span class="bu">sum</span>(<span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(probs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.0171, 0.0355, 0.2361, 0.0431, 0.0421, 0.0085, 0.0193, 0.0295, 0.0217,
         0.0175, 0.0033, 0.0156, 0.0662, 0.0362, 0.0400, 0.0218, 0.0798, 0.0426,
         0.0245, 0.0274, 0.0115, 0.0071, 0.0600, 0.0427, 0.0232, 0.0110, 0.0167],
        [0.0037, 0.0105, 0.0296, 0.0491, 0.0090, 0.0452, 0.0422, 0.0291, 0.0306,
         0.1346, 0.0578, 0.0355, 0.0173, 0.0109, 0.0099, 0.0549, 0.0558, 0.0934,
         0.0099, 0.0156, 0.0370, 0.0322, 0.0695, 0.0340, 0.0052, 0.0252, 0.0522],
        [0.0037, 0.0105, 0.0296, 0.0491, 0.0090, 0.0452, 0.0422, 0.0291, 0.0306,
         0.1346, 0.0578, 0.0355, 0.0173, 0.0109, 0.0099, 0.0549, 0.0558, 0.0934,
         0.0099, 0.0156, 0.0370, 0.0322, 0.0695, 0.0340, 0.0052, 0.0252, 0.0522]])</code></pre>
</div>
</div>
</section>
</section>
<section id="kenlm" class="level2">
<h2 class="anchored" data-anchor-id="kenlm">KenLM</h2>
<p>We refer to efficient kenlm implementation for larger n-gram models usable for production</p>
<hr>
<p><a href="https://github.com/slegroux/nimrod/blob/main/nimrod/models/ngram.py#L75" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="kenlm-1" class="level3">
<h3 class="anchored" data-anchor-id="kenlm-1">KenLM</h3>
<blockquote class="blockquote">
<pre><code> KenLM (arpa_path:str, vocab:List)</code></pre>
</blockquote>
<p>Initialize self. See help(type(self)) for accurate signature.</p>
</section>
<section id="preprocess-data-into-kenlm-format" class="level3">
<h3 class="anchored" data-anchor-id="preprocess-data-into-kenlm-format">Preprocess data into kenlm format</h3>
<p>tokens separated by space with new sentence at each line</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'../data/names.txt'</span>, header<span class="op">=</span><span class="va">None</span>, names<span class="op">=</span>[<span class="st">'name'</span>]) </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.name.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">list</span>(x)) <span class="co"># str into list of char</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># df.apply(lambda x: x.append('&lt;eos&gt;')) # if eos needed</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head())</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>df_toks <span class="op">=</span> df.<span class="bu">str</span>.join(<span class="st">' '</span>) <span class="co"># for kenlm input format tokens are separated by space</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_toks.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0                [e, m, m, a]
1          [o, l, i, v, i, a]
2                   [a, v, a]
3    [i, s, a, b, e, l, l, a]
4          [s, o, p, h, i, a]
Name: name, dtype: object
0            e m m a
1        o l i v i a
2              a v a
3    i s a b e l l a
4        s o p h i a
Name: name, dtype: object</code></pre>
</div>
</div>
<section id="unique-tokens" class="level4">
<h4 class="anchored" data-anchor-id="unique-tokens">Unique tokens</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># for row in df.iterrows():</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     print(row)</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k,v <span class="kw">in</span> df.items():</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    tokens.update(<span class="bu">list</span>(v))</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'y', 'x', 'q', 'l', 's', 'g', 'n', 'u', 'i', 'm', 'z', 't', 'o', 'v', 'w', 'h', 'c', 'a', 'p', 'f', 'r', 'e', 'd', 'k', 'j', 'b'}</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>26</code></pre>
</div>
</div>
</section>
<section id="save-data-to-kenlm-format-for-training" class="level4">
<h4 class="anchored" data-anchor-id="save-data-to-kenlm-format-for-training">Save data to kenlm format for training</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>data_file <span class="op">=</span> df.to_csv(<span class="st">'../data/names.kenlm.txt'</span>, header<span class="op">=</span><span class="va">None</span>, index<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> bzip2 <span class="op">-</span>kz ..<span class="op">/</span>data<span class="op">/</span>names.kenlm.txt</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ! bzcat ../data/names.kenlm.txt.bz2 | head</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>bzip2: Output file ../data/names.kenlm.txt.bz2 already exists.</code></pre>
</div>
</div>
</section>
</section>
<section id="train-kenlm-n-gram-model" class="level3">
<h3 class="anchored" data-anchor-id="train-kenlm-n-gram-model">Train KenLM n-gram model</h3>
<p>https://lukesalamone.github.io/posts/running-simple-language-model/</p>
<p>KenLM requires data to be one sentence per line lowercase</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> <span class="cf">if</span> [ <span class="op">!</span> <span class="op">-</span>f <span class="st">"../data/names.2gram.arpa"</span> ]<span class="op">;</span> then lmplz <span class="op">--</span>discount_fallback <span class="op">-</span>o <span class="dv">2</span> <span class="op">&lt;</span> ..<span class="op">/</span>data<span class="op">/</span>names.kenlm.txt.bz2 <span class="op">&gt;</span> ..<span class="op">/</span>data<span class="op">/</span>names<span class="fl">.2</span><span class="er">gram</span>.arpa<span class="op">;</span> fi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> <span class="cf">if</span> [ <span class="op">!</span> <span class="op">-</span>f <span class="st">"../data/names.2gram.kenlm"</span> ]<span class="op">;</span> then build_binary ..<span class="op">/</span>data<span class="op">/</span>names<span class="fl">.2</span><span class="er">gram</span>.arpa ..<span class="op">/</span>data<span class="op">/</span>names<span class="fl">.2</span><span class="er">gram</span>.kenlm<span class="op">;</span> fi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="test-original-kenlm-python-api-probs" class="level4">
<h4 class="anchored" data-anchor-id="test-original-kenlm-python-api-probs">Test original Kenlm python api probs</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> kenlm.LanguageModel(<span class="st">'../data/names.2gram.kenlm'</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>sentence <span class="op">=</span> <span class="st">"emma"</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>tokenized <span class="op">=</span> <span class="st">"e m m a"</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># model.score("emma", bos = False, eos = False)</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> [<span class="st">'&lt;s&gt;'</span>] <span class="op">+</span> <span class="bu">list</span>(sentence) <span class="op">+</span> [<span class="st">'&lt;/s&gt;'</span>]</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(words)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>final <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (prob, length, oov) <span class="kw">in</span> <span class="bu">enumerate</span>(model.full_scores(tokenized)):</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'words: </span><span class="sc">{</span>words[i:i<span class="op">+</span>length]<span class="sc">}</span><span class="ss"> index:</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, prob:</span><span class="sc">{</span>prob<span class="sc">}</span><span class="ss">, length:</span><span class="sc">{</span>length<span class="sc">}</span><span class="ss">, oov:</span><span class="sc">{</span>oov<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    final <span class="op">+=</span> prob</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.score(<span class="st">"e m m a"</span>))</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob &lt;s&gt; e: </span><span class="sc">{</span>model<span class="sc">.</span>score(<span class="st">"e"</span>, bos<span class="op">=</span><span class="va">True</span>, eos<span class="op">=</span><span class="va">False</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob e: </span><span class="sc">{</span>model<span class="sc">.</span>score(<span class="st">"e"</span>, bos<span class="op">=</span><span class="va">False</span>, eos<span class="op">=</span><span class="va">False</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob &lt;s&gt; e m: </span><span class="sc">{</span>model<span class="sc">.</span>score(<span class="st">"e m"</span>, bos<span class="op">=</span><span class="va">True</span>, eos<span class="op">=</span><span class="va">False</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob e m: </span><span class="sc">{</span>model<span class="sc">.</span>score(<span class="st">"e m"</span>, bos<span class="op">=</span><span class="va">False</span>, eos<span class="op">=</span><span class="va">False</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> kenlm.State()</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>state2 <span class="op">=</span> kenlm.State()</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>model.BeginSentenceWrite(state)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>accum <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>accum <span class="op">+=</span> model.BaseScore(state, <span class="st">"e"</span>, state2)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob &lt;s&gt; e: </span><span class="sc">{</span>accum<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>state, state2 <span class="op">=</span> state2, state</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>accum <span class="op">+=</span> model.BaseScore(state, <span class="st">"m"</span>, state2)</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob &lt;s&gt; e m: </span><span class="sc">{</span>accum<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['&lt;s&gt;', 'e', 'm', 'm', 'a', '&lt;/s&gt;']
words: ['&lt;s&gt;', 'e'] index:0, prob:-1.3205678462982178, length:2, oov:False
words: ['e', 'm'] index:1, prob:-1.4242042303085327, length:2, oov:False
words: ['m', 'm'] index:2, prob:-1.5977596044540405, length:2, oov:False
words: ['m', 'a'] index:3, prob:-0.40900975465774536, length:2, oov:False
words: ['a', '&lt;/s&gt;'] index:4, prob:-0.7078268527984619, length:2, oov:False
-5.459368288516998
-5.459368705749512
prob &lt;s&gt; e: -1.3205678462982178
prob e: -1.366766333580017
prob &lt;s&gt; e m: -2.744771957397461
prob e m: -2.79097056388855
prob &lt;s&gt; e: -1.3205678462982178
prob &lt;s&gt; e m: -2.7447720766067505</code></pre>
</div>
</div>
</section>
<section id="define-lm-vocabulary" class="level4">
<h4 class="anchored" data-anchor-id="define-lm-vocabulary">Define LM vocabulary</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># add special tokens to vocabulary</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>tokens.add(<span class="st">'&lt;s&gt;'</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>tokens.add(<span class="st">'&lt;/s&gt;'</span>)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>tokens.add(<span class="st">'&lt;unk&gt;'</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens, <span class="bu">len</span>(tokens))</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> <span class="bu">list</span>(tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'&lt;/s&gt;', 'y', 'x', 'q', 'l', 's', 'g', 'n', 'u', 'i', 'm', 'z', 't', '&lt;s&gt;', 'o', 'v', 'w', 'h', 'c', 'a', 'p', 'f', '&lt;unk&gt;', 'r', 'e', 'd', 'k', 'j', 'b'} 29</code></pre>
</div>
</div>
</section>
</section>
<section id="inference-sampling-from-prob-distributions" class="level3">
<h3 class="anchored" data-anchor-id="inference-sampling-from-prob-distributions">Inference / Sampling from prob distributions</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>lm <span class="op">=</span> KenLM(<span class="st">'../data/names.2gram.kenlm'</span>, vocab)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>init_char <span class="op">=</span> <span class="st">'&lt;s&gt; e m m'</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co"># probs = lm.nbest(len(vocab), log_prob=False)</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sum([p for char, p in probs]))</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co"># res = [init_char]</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="co"># next = int(torch.multinomial(P[prev,:],num_samples=1,replacement=True))</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    lm.new_sentence_init()</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    lm.append(init_char)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># nbest probs at current state</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> lm.nbest(<span class="bu">len</span>(vocab), log_prob<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(probs)</span></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(np.sum(probs))</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample from prob distribution</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>            index_next <span class="op">=</span> <span class="bu">int</span>(torch.multinomial(torch.tensor([prob <span class="cf">for</span> char, prob <span class="kw">in</span> probs]),num_samples<span class="op">=</span><span class="dv">1</span>,replacement<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"probs too small"</span>)</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>        char_next <span class="op">=</span> probs[index_next][<span class="dv">0</span>]</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>        lm.append(char_next)</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(init_char + '&lt;s&gt;')</span></span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> char_next <span class="op">==</span> <span class="st">'&lt;/s&gt;'</span> <span class="kw">or</span> char_next <span class="op">==</span> <span class="st">'&lt;s&gt;'</span> <span class="kw">and</span> lm.text <span class="op">!=</span> init_char <span class="kw">and</span> (lm.text <span class="op">!=</span> init_char<span class="op">+</span><span class="st">' &lt;s&gt;'</span>):</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(lm.text.replace(<span class="st">' '</span>, <span class="st">''</span>))</span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;s&gt;emmgonaba&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;feiamason&lt;/s&gt;
&lt;s&gt;emmji&lt;/s&gt;
&lt;s&gt;emmqut&lt;/s&gt;
&lt;s&gt;emmrme&lt;/s&gt;
&lt;s&gt;emmhinyangoroh&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;yn&lt;/s&gt;
&lt;s&gt;emme&lt;/s&gt;
&lt;s&gt;emm&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;erasssarieesen&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;jongon&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;jergesca&lt;/s&gt;
&lt;s&gt;emmbrileikadieth&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;avinerye&lt;s&gt;
&lt;s&gt;emm&lt;s&gt;cave&lt;/s&gt;
&lt;s&gt;emmmab&lt;/s&gt;
&lt;s&gt;emmquna&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;je&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;ha&lt;/s&gt;
&lt;s&gt;emmrinnenghazamyahyninat&lt;/s&gt;
&lt;s&gt;emmgriladya&lt;/s&gt;
&lt;s&gt;emmfriyaterisle&lt;/s&gt;
&lt;s&gt;emmpphohjitac&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;cev&lt;/s&gt;
&lt;s&gt;emmurt&lt;/s&gt;
&lt;s&gt;emmnyadonenace&lt;/s&gt;
&lt;s&gt;emmzah&lt;/s&gt;
&lt;s&gt;emmssylecena&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;keylely&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;n&lt;/s&gt;
&lt;s&gt;emmquwatoliyscasah&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;ziohrireria&lt;/s&gt;
&lt;s&gt;emm&lt;/s&gt;
&lt;s&gt;emmcossus&lt;/s&gt;
&lt;s&gt;emmusttero&lt;/s&gt;
&lt;s&gt;emmfizzzarna&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;z&lt;/s&gt;
&lt;s&gt;emmuey&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;hasindillud&lt;/s&gt;
&lt;s&gt;emmquso&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;f&lt;s&gt;
&lt;s&gt;emm&lt;s&gt;kwi&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;mita&lt;/s&gt;
&lt;s&gt;emmjirri&lt;/s&gt;
&lt;s&gt;emmux&lt;/s&gt;
&lt;s&gt;emmyem&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;jaleleyl&lt;/s&gt;
&lt;s&gt;emmmampjum&lt;/s&gt;
&lt;s&gt;emm&lt;s&gt;gelealy&lt;/s&gt;
&lt;s&gt;emmphargidonikaran&lt;/s&gt;</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>