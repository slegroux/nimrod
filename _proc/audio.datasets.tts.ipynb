{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: TTS datasets\n",
    "output-file: audio.datasets.tts.html\n",
    "title: Audio TTS Datasets\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-To-Speech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lhotse-based Base Class\n",
    "https://github.com/Lightning-AI/lightning/issues/10358\n",
    "https://colab.research.google.com/drive/1HKSYPsWx_HoCdrnLpaPdYj5zwlPsM3NH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/audio/datasets/tts.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LhotseTTSDataset\n",
       "\n",
       ">      LhotseTTSDataset (tokenizer=<class\n",
       ">                        'lhotse.dataset.collation.TokenCollater'>, extractor=<l\n",
       ">                        hotse.dataset.input_strategies.OnTheFlyFeatures object\n",
       ">                        at 0x7fb509eb9a00>)\n",
       "\n",
       "An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
       ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "of :class:`~torch.utils.data.DataLoader`.\n",
       "\n",
       ".. note::\n",
       "  :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| tokenizer | type | TokenCollater | text tokenizer |\n",
       "| extractor | OnTheFlyFeatures | <lhotse.dataset.input_strategies.OnTheFlyFeatures object at 0x7fb509eb9a00> | feature extractor |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/audio/datasets/tts.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LhotseTTSDataset\n",
       "\n",
       ">      LhotseTTSDataset (tokenizer=<class\n",
       ">                        'lhotse.dataset.collation.TokenCollater'>, extractor=<l\n",
       ">                        hotse.dataset.input_strategies.OnTheFlyFeatures object\n",
       ">                        at 0x7fb509eb9a00>)\n",
       "\n",
       "An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
       ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "of :class:`~torch.utils.data.DataLoader`.\n",
       "\n",
       ".. note::\n",
       "  :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| tokenizer | type | TokenCollater | text tokenizer |\n",
       "| extractor | OnTheFlyFeatures | <lhotse.dataset.input_strategies.OnTheFlyFeatures object at 0x7fb509eb9a00> | feature extractor |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LhotseTTSDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# tok = TokenCollater()\n",
    "# ds = LhotseTTSDataset(tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/data/datasets.py#L251){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TTSDataset\n",
       "\n",
       ">      TTSDataset (tokenizer, num_mel_bins:int=80)\n",
       "\n",
       "An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
       ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "of :class:`~torch.utils.data.DataLoader`.\n",
       "\n",
       ".. note::\n",
       "  :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| tokenizer |  |  | text tokenizer |\n",
       "| num_mel_bins | int | 80 | number of mel spectrogram bins |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/data/datasets.py#L251){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TTSDataset\n",
       "\n",
       ">      TTSDataset (tokenizer, num_mel_bins:int=80)\n",
       "\n",
       "An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
       ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "of :class:`~torch.utils.data.DataLoader`.\n",
       "\n",
       ".. note::\n",
       "  :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| tokenizer |  |  | text tokenizer |\n",
       "| num_mel_bins | int | 80 | number of mel spectrogram bins |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(TTSDataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibriTTS DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0007, 0.0008, 0.0012,  ..., 0.0039, 0.0042, 0.0042]]), 24000, 'He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour-fattened sauce. Stuff it into you, his belly counselled him.', 'He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour fattened sauce. Stuff it into you, his belly counselled him.', 1089, 134686, '1089_134686_000001_000001')\n"
     ]
    }
   ],
   "source": [
    "#(Waveform, Sample_rate, Original_text, Normalized_text, Speaker_ID, Chapter_ID, Utterance_ID)\n",
    "ds = LIBRITTS(\"../data/en\", 'test-clean')\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/data/datasets.py#L305){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LibriTTSDataModule\n",
       "\n",
       ">      LibriTTSDataModule (target_dir='/data/en/libriTTS', dataset_parts=['dev-\n",
       ">                          clean', 'test-clean'], output_dir='/home/syl20/slg/ni\n",
       ">                          mrod/recipes/libritts/data', num_jobs=1)\n",
       "\n",
       "A DataModule standardizes the training, val, test splits, data preparation and transforms. The main\n",
       "advantage is consistent data splits, data preparation and transforms across models.\n",
       "\n",
       "Example::\n",
       "\n",
       "    class MyDataModule(LightningDataModule):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "        def prepare_data(self):\n",
       "            # download, split, etc...\n",
       "            # only called on 1 GPU/TPU in distributed\n",
       "        def setup(self, stage):\n",
       "            # make assignments here (val/train/test split)\n",
       "            # called on every process in DDP\n",
       "        def train_dataloader(self):\n",
       "            train_split = Dataset(...)\n",
       "            return DataLoader(train_split)\n",
       "        def val_dataloader(self):\n",
       "            val_split = Dataset(...)\n",
       "            return DataLoader(val_split)\n",
       "        def test_dataloader(self):\n",
       "            test_split = Dataset(...)\n",
       "            return DataLoader(test_split)\n",
       "        def teardown(self):\n",
       "            # clean up after fit or test\n",
       "            # called on every process in DDP\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| target_dir | str | /data/en/libriTTS | where data will be saved / retrieved |\n",
       "| dataset_parts | list | ['dev-clean', 'test-clean'] | either full libritts or subset |\n",
       "| output_dir | str | /home/syl20/slg/nimrod/recipes/libritts/data | where to save manifest |\n",
       "| num_jobs | int | 1 | num_jobs depending on number of cpus available |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/data/datasets.py#L305){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LibriTTSDataModule\n",
       "\n",
       ">      LibriTTSDataModule (target_dir='/data/en/libriTTS', dataset_parts=['dev-\n",
       ">                          clean', 'test-clean'], output_dir='/home/syl20/slg/ni\n",
       ">                          mrod/recipes/libritts/data', num_jobs=1)\n",
       "\n",
       "A DataModule standardizes the training, val, test splits, data preparation and transforms. The main\n",
       "advantage is consistent data splits, data preparation and transforms across models.\n",
       "\n",
       "Example::\n",
       "\n",
       "    class MyDataModule(LightningDataModule):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "        def prepare_data(self):\n",
       "            # download, split, etc...\n",
       "            # only called on 1 GPU/TPU in distributed\n",
       "        def setup(self, stage):\n",
       "            # make assignments here (val/train/test split)\n",
       "            # called on every process in DDP\n",
       "        def train_dataloader(self):\n",
       "            train_split = Dataset(...)\n",
       "            return DataLoader(train_split)\n",
       "        def val_dataloader(self):\n",
       "            val_split = Dataset(...)\n",
       "            return DataLoader(val_split)\n",
       "        def test_dataloader(self):\n",
       "            test_split = Dataset(...)\n",
       "            return DataLoader(test_split)\n",
       "        def teardown(self):\n",
       "            # clean up after fit or test\n",
       "            # called on every process in DDP\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| target_dir | str | /data/en/libriTTS | where data will be saved / retrieved |\n",
       "| dataset_parts | list | ['dev-clean', 'test-clean'] | either full libritts or subset |\n",
       "| output_dir | str | /home/syl20/slg/nimrod/recipes/libritts/data | where to save manifest |\n",
       "| num_jobs | int | 1 | num_jobs depending on number of cpus available |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LibriTTSDataModule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dm = LibriTTSDataModule(\n",
    "    target_dir=\"../data/en\", \n",
    "    dataset_parts=\"test-clean\",\n",
    "    output_dir=\"../data/en/LibriTTS/test-clean\",\n",
    "    num_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# skip download and use local data folder\n",
    "# dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]00:00<?, ?it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Scanning audio files (*.wav): 95it [00:00, 5596.18it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]00:00<00:00, 46.46it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Preparing LibriTTS parts: 100%|██████████| 7/7 [00:00<00:00, 53.83it/s]\n"
     ]
    }
   ],
   "source": [
    "dm.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
