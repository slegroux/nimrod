{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lhotse support for datasets\n",
    "\n",
    "> allows to leverage preliminary data prep from lhotse recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.utils.lhotse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS Lhotse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, Fbank, FbankConfig, MonoCut, NumpyFilesWriter, NumpyHdf5Writer\n",
    "from lhotse.dataset import BucketingSampler, OnTheFlyFeatures, DynamicBucketingSampler\n",
    "from lhotse.dataset.collation import TokenCollater\n",
    "from lhotse.dataset.input_strategies import BatchIO, PrecomputedFeatures\n",
    "from lhotse.dataset.vis import plot_batch\n",
    "from lhotse.recipes import download_librispeech, prepare_librispeech, download_ljspeech, prepare_ljspeech\n",
    "\n",
    "from typing import Tuple, Dict\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from nimrod.audio.embedding import EncoDecExtractor\n",
    "from nimrod.text.normalizers import TTSTextNormalizer\n",
    "from nimrod.text.phonemizers import Phonemizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and load into Lhotse cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_ljspeech('~/Data/en/')\n",
    "# skip this step already done\n",
    "ljspeech = prepare_ljspeech('../data/en/LJSpeech-1.1', '../recipes/tts/ljspeech/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_set = CutSet.from_manifests(**ljspeech)\n",
    "subset = cut_set.subset(first=3)\n",
    "subset.to_file('../recipes/tts/ljspeech/data/first_3.jsonl.gz')\n",
    "reload_subset = CutSet.from_file('../recipes/tts/ljspeech/data/first_3.jsonl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset[1])\n",
    "print(reload_subset[1])\n",
    "print(len(subset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encodec feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_extractor = EncoDecExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(1)\n",
    "# torch.set_num_interop_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix bug for n_jobs >1\n",
    "cuts = subset.compute_and_store_features(\n",
    "    extractor=encodec_extractor,\n",
    "    storage_path=\"../recipes/tts/ljspeech/data/encodec\",\n",
    "    num_jobs=1,\n",
    "    # storage_type=NumpyHdf5Writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cuts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts.to_file(\"../recipes/tts/ljspeech/data/first_3.encodec.jsonl.gz\")\n",
    "cuts[0]\n",
    "reload_cuts = CutSet.from_file(\"../recipes/tts/ljspeech/data/first_3.encodec.jsonl.gz\")\n",
    "reload_cuts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts[0].recording\n",
    "!soxi '../data/en/LJSpeech-1.1/wavs/LJ001-0001.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = PrecomputedFeatures()\n",
    "feats, feats_len = strategy(cuts)\n",
    "\n",
    "# print([(f\"feat: {feat.shape}\", f\"len: {feat_len}\") for feat in feats for feat_len in feats_len])\n",
    "print([feat.shape for feat in feats])\n",
    "print([int(feat_len) for feat_len in feats_len])\n",
    "print(feats.shape, feats_len.shape)\n",
    "# TODO: debug OnTheFlyFeature case\n",
    "# strategy = OnTheFlyFeatures(extractor=encodec_extractor)\n",
    "# feats, feats_len = strategy(cuts)\n",
    "# print(feats, feats_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text normalization, tokenization and numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TTSTextNormalizer()\n",
    "tokenizer = Phonemizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner(\"tutu. this is ture!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "unique_phonemes = set()\n",
    "with CutSet.open_writer('../recipes/tts/ljspeech/data/first_3.final.jsonl.gz', overwrite=True) as writer:\n",
    "    for cut in cuts:\n",
    "        text = cut.supervisions[0].text\n",
    "        print(text)\n",
    "        normalized = cleaner(text)\n",
    "        print(normalized)\n",
    "        phonemes = tokenizer(text)\n",
    "        print(phonemes)\n",
    "        cut.custom = {'normalized': normalized, 'phonemes': phonemes}\n",
    "        writer.write(cut, flush=True)\n",
    "        unique_phonemes.update(list(phonemes))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export phoneme lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = CutSet.from_file(\"../data/en/LJSpeech-1.1/first_3.final.jsonl.gz\")\n",
    "print(cuts[0])\n",
    "map = {}\n",
    "unique_syms = set()\n",
    "for cut in cuts:\n",
    "    unique_syms.update(list(cut.custom['phonemes']))\n",
    "for (i, v) in enumerate(sorted(list(unique_syms))):\n",
    "    map[i] = v\n",
    "map[len(map)] = \"<eps>\"\n",
    "print(map, len(map))\n",
    "\n",
    "json_map = json.dumps(map)\n",
    "with open(\"../data/en/LJSpeech-1.1/map.json\",\"w\") as f:\n",
    "    f.write(json_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/en/LJSpeech-1.1/map.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PhonemeCollater(TokenCollater):\n",
    "    def __init__(\n",
    "            self,  cuts: CutSet,\n",
    "            add_eos: bool = True,\n",
    "            add_bos: bool = True,\n",
    "            pad_symbol: str = \"<pad>\",\n",
    "            bos_symbol: str = \"<bos>\",\n",
    "            eos_symbol: str = \"<eos>\",\n",
    "            unk_symbol: str = \"<unk>\",\n",
    "        ):\n",
    "        super().__init__(\n",
    "            cuts,\n",
    "            add_eos=add_eos,\n",
    "            add_bos=add_bos,\n",
    "            pad_symbol=pad_symbol,\n",
    "            bos_symbol=bos_symbol,\n",
    "            eos_symbol=eos_symbol,\n",
    "            unk_symbol=unk_symbol\n",
    "            )\n",
    "        tokens = {char for cut in cuts for char in cut.custom['phonemes']}\n",
    "        tokens_unique = (\n",
    "            [pad_symbol, unk_symbol]\n",
    "            + ([bos_symbol] if add_bos else [])\n",
    "            + ([eos_symbol] if add_eos else [])\n",
    "            + sorted(tokens)\n",
    "        )\n",
    "\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(tokens_unique)}\n",
    "        self.idx2token = [token for token in tokens_unique]\n",
    "    \n",
    "    def __call__(self, cuts: CutSet) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        token_sequences = [\" \".join(cut.custom['phonemes']) for cut in cuts]\n",
    "        max_len = len(max(token_sequences, key=len))\n",
    "        seqs = [\n",
    "            ([self.bos_symbol] if self.add_bos else [])\n",
    "            + list(seq)\n",
    "            + ([self.eos_symbol] if self.add_eos else [])\n",
    "            + [self.pad_symbol] * (max_len - len(seq))\n",
    "            for seq in token_sequences\n",
    "        ]\n",
    "\n",
    "        tokens_batch = torch.from_numpy(\n",
    "            np.array(\n",
    "                [[self.token2idx[token] for token in seq] for seq in seqs],\n",
    "                dtype=np.int64,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        tokens_lens = torch.IntTensor(\n",
    "            [\n",
    "                len(seq) + int(self.add_eos) + int(self.add_bos)\n",
    "                for seq in token_sequences\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return tokens_batch, tokens_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PhonemeCollater(cuts)\n",
    "tokens, tokens_len = pc(cuts)\n",
    "print(tokens, tokens_len)\n",
    "print(pc.inverse(tokens, tokens_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValleDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cuts:CutSet,\n",
    "            strategy:BatchIO=PrecomputedFeatures()\n",
    "        ):\n",
    "        self.extractor = strategy\n",
    "        self.tokenizer = PhonemeCollater(cuts)\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> Dict[str, torch.Tensor]:\n",
    "        # getitem is on full cutset not just one cut like usual for pytorch datasets\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"feats_lens\": feat_lens, \"tokens_pad\": tokens, \"tokens_lens\": token_lens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ValleDataset(cuts)\n",
    "# Dataset performs batching by itself, so we have to indicate that to the DataLoader with batch_size=None\n",
    "# train_sampler = BucketingSampler(cuts, max_duration=300, shuffle=True, bucket_method=\"equal_duration\")\n",
    "train_sampler = DynamicBucketingSampler(cuts, max_duration=300, shuffle=True, num_buckets=2)\n",
    "dl = DataLoader(ds, sampler=train_sampler, batch_size=None, num_workers=0)\n",
    "print(next(iter(dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
