{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "\n",
    "> Neural net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "\n",
    "from nimrod.models.conv import ConvLayer\n",
    "from nimrod.models.core import Classifier\n",
    "from nimrod.utils import get_device, set_seed\n",
    "\n",
    "from typing import List, Optional, Callable, Any, Type\n",
    "import logging\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "logger = logging.getLogger(__name__)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int, # Number of input channels\n",
    "            out_channels:int, # Number of output channels\n",
    "            stride:int=1,\n",
    "            kernel_size:int=3,\n",
    "            activation:Optional[Type[nn.Module]]=nn.ReLU\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.activation = activation()\n",
    "        conv_block = []\n",
    "        conv_ = partial(ConvLayer, stride=1, activation=activation, normalization=nn.BatchNorm2d)\n",
    "        # conv stride 1 to be able to go deeper while keeping the same spatial resolution\n",
    "        c1 = conv_(in_channels, out_channels, stride=1, kernel_size=kernel_size)\n",
    "        # conv stride to be able to go wider in number of channels\n",
    "        # activation will be added at very end\n",
    "        c2 = conv_(out_channels, out_channels, stride=stride, activation=None, kernel_size=kernel_size) #adding activation to the whole layer at the end c.f. forward\n",
    "        conv_block += [c1,c2]\n",
    "        self.conv_layer = nn.Sequential(*conv_block)\n",
    "\n",
    "        if in_channels == out_channels:\n",
    "            self.id = nn.Identity()\n",
    "        else:\n",
    "            # resize x to match channels\n",
    "            self.id = conv_(in_channels, out_channels, kernel_size=1, stride=1, activation=None)\n",
    "        \n",
    "        if stride == 1:\n",
    "            self.pooling = nn.Identity()\n",
    "        else:\n",
    "            # resize x to match the stride\n",
    "            self.pooling = nn.AvgPool2d(stride, ceil_mode=True)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.activation(self.conv_layer(x) + self.id(self.pooling(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResBlock                                 [1, 8, 16, 16]            --\n",
       "├─Sequential: 1-1                        [1, 8, 16, 16]            --\n",
       "│    └─ConvLayer: 2-1                    [1, 8, 32, 32]            232\n",
       "│    └─ConvLayer: 2-2                    [1, 8, 16, 16]            592\n",
       "├─AvgPool2d: 1-2                         [1, 3, 16, 16]            --\n",
       "├─ConvLayer: 1-3                         [1, 8, 16, 16]            --\n",
       "│    └─Sequential: 2-3                   [1, 8, 16, 16]            40\n",
       "├─ReLU: 1-4                              [1, 8, 16, 16]            --\n",
       "==========================================================================================\n",
       "Total params: 864\n",
       "Trainable params: 864\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.37\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.20\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResBlock(3, 8, stride=2)\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "summary(model=model, input_size=(1, 3, 32, 32), depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_features: List[int]=[1, 8, 16, 32, 64, 32], # Number of input & output channels\n",
    "            num_classes: int=10, # Number of classes\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "        logger.info(\"ResNet: init\")\n",
    "        layers = []\n",
    "        res_ = partial(ResBlock, stride=2)\n",
    "\n",
    "        layers.append(res_(in_channels=n_features[0], out_channels=n_features[1], stride=1))\n",
    "\n",
    "        for i in range(1, len(n_features)-1):\n",
    "            layers += [res_(in_channels=n_features[i], out_channels=n_features[i+1])]\n",
    "\n",
    "        # last layer back to n_classes and flatten\n",
    "        layers.append(res_(in_channels=n_features[-1], out_channels=num_classes))\n",
    "        layers.append(nn.Flatten())\n",
    "\n",
    "        # layers += [nn.Flatten(), nn.Linear(n_features[-1], num_classes, bias=False), nn.BatchNorm1d(num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/Users/slegroux/miniforge3/envs/nimrod/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "Seed set to 42\n",
      "[15:31:10] INFO - ResNet: init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ResNet                                             [64, 10]                  --\n",
       "├─Sequential: 1-1                                  [64, 10]                  --\n",
       "│    └─ResBlock: 2-1                               [64, 8, 28, 28]           864\n",
       "│    └─ResBlock: 2-2                               [64, 16, 14, 14]          3,680\n",
       "│    └─ResBlock: 2-3                               [64, 32, 7, 7]            14,528\n",
       "│    └─ResBlock: 2-4                               [64, 64, 4, 4]            57,728\n",
       "│    └─ResBlock: 2-5                               [64, 32, 2, 2]            29,888\n",
       "│    └─ResBlock: 2-6                               [64, 10, 1, 1]            4,160\n",
       "│    └─Flatten: 2-7                                [64, 10]                  --\n",
       "====================================================================================================\n",
       "Total params: 110,848\n",
       "Trainable params: 110,848\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 197.51\n",
       "====================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 37.29\n",
       "Params size (MB): 0.44\n",
       "Estimated Total Size (MB): 38.33\n",
       "===================================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(64, 3, 28, 28)\n",
    "model = ResNet(n_features=[3, 8, 16, 32, 64, 32], num_classes=10)\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "summary(model=model, input_size=(64, 3, 28, 28), depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ResNetX(Classifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nnet:ResNet,\n",
    "        num_classes:int,\n",
    "        optimizer:Callable[...,torch.optim.Optimizer], # optimizer,\n",
    "        scheduler: Optional[Callable[...,Any]]=None, # scheduler\n",
    "        ):\n",
    "        \n",
    "        logger.info(\"ResNetX: init\")\n",
    "        super().__init__(\n",
    "            nnet=nnet,\n",
    "            num_classes=num_classes,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler\n",
    "            )\n",
    "\n",
    "    def _step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        preds = y_hat.argmax(dim=1)\n",
    "        return loss, preds, y\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return y_hat.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:40:37] INFO - ResNet: init\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[15:40:37] WARNING - setting conv bias to False as Batchnorm is used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load('../config/model/image/resnetx.yaml')\n",
    "B, C, H, W = 64, 1, 28, 28\n",
    "x = torch.randn(B, C, H, W)\n",
    "nnet = instantiate(cfg.nnet, num_classes=10)\n",
    "y = nnet(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ResNet                                             [64, 10]                  --\n",
       "├─Sequential: 1-1                                  [64, 10]                  --\n",
       "│    └─ConvLayer: 2-1                              [64, 8, 14, 14]           --\n",
       "│    │    └─Sequential: 3-1                        [64, 8, 14, 14]           --\n",
       "│    │    │    └─Conv2d: 4-1                       [64, 8, 14, 14]           72\n",
       "│    │    │    └─BatchNorm2d: 4-2                  [64, 8, 14, 14]           16\n",
       "│    │    │    └─ReLU: 4-3                         [64, 8, 14, 14]           --\n",
       "│    └─ResBlock: 2-2                               [64, 8, 14, 14]           --\n",
       "│    │    └─Sequential: 3-2                        [64, 8, 14, 14]           --\n",
       "│    │    │    └─ConvLayer: 4-4                    [64, 8, 14, 14]           --\n",
       "│    │    │    │    └─Sequential: 5-1              [64, 8, 14, 14]           592\n",
       "│    │    │    └─ConvLayer: 4-5                    [64, 8, 14, 14]           --\n",
       "│    │    │    │    └─Sequential: 5-2              [64, 8, 14, 14]           592\n",
       "│    └─ConvLayer: 2-3                              [64, 16, 7, 7]            --\n",
       "│    │    └─Sequential: 3-3                        [64, 16, 7, 7]            --\n",
       "│    │    │    └─Conv2d: 4-6                       [64, 16, 7, 7]            1,152\n",
       "│    │    │    └─BatchNorm2d: 4-7                  [64, 16, 7, 7]            32\n",
       "│    │    │    └─ReLU: 4-8                         [64, 16, 7, 7]            --\n",
       "│    └─ResBlock: 2-4                               [64, 16, 7, 7]            --\n",
       "│    │    └─Sequential: 3-4                        [64, 16, 7, 7]            --\n",
       "│    │    │    └─ConvLayer: 4-9                    [64, 16, 7, 7]            --\n",
       "│    │    │    │    └─Sequential: 5-3              [64, 16, 7, 7]            2,336\n",
       "│    │    │    └─ConvLayer: 4-10                   [64, 16, 7, 7]            --\n",
       "│    │    │    │    └─Sequential: 5-4              [64, 16, 7, 7]            2,336\n",
       "│    └─ConvLayer: 2-5                              [64, 32, 4, 4]            --\n",
       "│    │    └─Sequential: 3-5                        [64, 32, 4, 4]            --\n",
       "│    │    │    └─Conv2d: 4-11                      [64, 32, 4, 4]            4,608\n",
       "│    │    │    └─BatchNorm2d: 4-12                 [64, 32, 4, 4]            64\n",
       "│    │    │    └─ReLU: 4-13                        [64, 32, 4, 4]            --\n",
       "│    └─ResBlock: 2-6                               [64, 32, 4, 4]            --\n",
       "│    │    └─Sequential: 3-6                        [64, 32, 4, 4]            --\n",
       "│    │    │    └─ConvLayer: 4-14                   [64, 32, 4, 4]            --\n",
       "│    │    │    │    └─Sequential: 5-5              [64, 32, 4, 4]            9,280\n",
       "│    │    │    └─ConvLayer: 4-15                   [64, 32, 4, 4]            --\n",
       "│    │    │    │    └─Sequential: 5-6              [64, 32, 4, 4]            9,280\n",
       "│    └─ConvLayer: 2-7                              [64, 16, 2, 2]            --\n",
       "│    │    └─Sequential: 3-7                        [64, 16, 2, 2]            --\n",
       "│    │    │    └─Conv2d: 4-16                      [64, 16, 2, 2]            4,608\n",
       "│    │    │    └─BatchNorm2d: 4-17                 [64, 16, 2, 2]            32\n",
       "│    │    │    └─ReLU: 4-18                        [64, 16, 2, 2]            --\n",
       "│    └─ResBlock: 2-8                               [64, 16, 2, 2]            --\n",
       "│    │    └─Sequential: 3-8                        [64, 16, 2, 2]            --\n",
       "│    │    │    └─ConvLayer: 4-19                   [64, 16, 2, 2]            --\n",
       "│    │    │    │    └─Sequential: 5-7              [64, 16, 2, 2]            2,336\n",
       "│    │    │    └─ConvLayer: 4-20                   [64, 16, 2, 2]            --\n",
       "│    │    │    │    └─Sequential: 5-8              [64, 16, 2, 2]            2,336\n",
       "│    └─ConvLayer: 2-9                              [64, 10, 1, 1]            --\n",
       "│    │    └─Sequential: 3-9                        [64, 10, 1, 1]            --\n",
       "│    │    │    └─Conv2d: 4-21                      [64, 10, 1, 1]            1,440\n",
       "│    │    │    └─BatchNorm2d: 4-22                 [64, 10, 1, 1]            20\n",
       "│    │    │    └─ReLU: 4-23                        [64, 10, 1, 1]            --\n",
       "│    └─Flatten: 2-10                               [64, 10]                  --\n",
       "====================================================================================================\n",
       "Total params: 41,132\n",
       "Trainable params: 41,132\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 59.49\n",
       "====================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 9.01\n",
       "Params size (MB): 0.16\n",
       "Estimated Total Size (MB): 9.37\n",
       "===================================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(nnet, input_size=(B, C, H, W), depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
