{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Language models\n",
    "\n",
    "> Basic neuralnet-based language modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from plum import dispatch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Vocab:\n",
    "    def __init__(self, data:pd.Series, specials=['<pad>', '<unk>', '<bos>', '<eos>']):\n",
    "        c = Counter()\n",
    "        for row in data.items():\n",
    "            name = list(row[1])\n",
    "            c.update(name)\n",
    "\n",
    "        ordered_tuple = sorted(c.items(), key=lambda x:x[1], reverse=True)\n",
    "        dict = OrderedDict(ordered_tuple)        \n",
    "        self.voc = vocab(dict, specials=specials)\n",
    "        if '<unk>' in specials:\n",
    "            self.voc.set_default_index(voc['<unk>'])\n",
    "        else:\n",
    "            self.voc.set_default_index(-1)\n",
    "        self._stoi = self.voc.get_stoi()\n",
    "        self._itos = self.voc.get_itos()\n",
    "\n",
    "    @dispatch\n",
    "    def stoi(self, token:str)->int:\n",
    "        return self._stoi[token]\n",
    "\n",
    "    @dispatch\n",
    "    def stoi(self, tokens:List[str])->List[int]:\n",
    "        return [self._stoi[tok] for tok in tokens]\n",
    "    \n",
    "    # @dispatch #TODO\n",
    "    # def stoi(self, tokens:List[List[str]])->List[List[int]]:\n",
    "    #     return [self._stoi[u] for tok in tokens for ]\n",
    "\n",
    "    @dispatch    \n",
    "    def itos(self, index:int)->str:\n",
    "        return self._itos[index]\n",
    "\n",
    "    @dispatch    \n",
    "    def itos(self, indices:List[int])->List[str]:\n",
    "        return [self._itos[index] for index in indices]\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "14\n",
      "a\n",
      "[5, 14]\n",
      "['e', 'm']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/names.txt', header=None, names=['name'])\n",
    "v = Vocab(df.name)\n",
    "print(v.stoi('e'))\n",
    "print(v.stoi('m'))\n",
    "print(v.itos(4))\n",
    "print(v.stoi(['e','m']))\n",
    "print(v.itos([5,14]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting\n",
    "given last n tokens we predict token n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'l', 'e', 'x', 'a', 'n', 'd', 'r', 'a']\n",
      "[('a', 'l'), ('l', 'e'), ('e', 'x'), ('x', 'a'), ('a', 'n'), ('n', 'd'), ('d', 'r'), ('r', 'a')]\n"
     ]
    }
   ],
   "source": [
    "s = list(\"alexandra\")\n",
    "print(s)\n",
    "bigram = [(x,y) for x, y in zip(s, s[1:])]\n",
    "print(bigram)\n",
    "trigram = [ (x,y,z) for x, y, z in zip(s, s[1:], s[2:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 4] 8\n",
      "[0, 0, 0, 4, 8] 5\n",
      "[0, 0, 4, 8, 5] 28\n",
      "[0, 4, 8, 5, 28] 4\n",
      "[4, 8, 5, 28, 4] 6\n",
      "[8, 5, 28, 4, 6] 16\n",
      "[5, 28, 4, 6, 16] 9\n",
      "[28, 4, 6, 16, 9] 4\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "pad_value = 0\n",
    "context_length = 5\n",
    "# init prefix with padding while len < context_length\n",
    "for i in range(context_length-1):\n",
    "    sequence = v.stoi(s[:i+1])\n",
    "    pad_len = context_length - len(sequence)\n",
    "    pad = [pad_value] * pad_len\n",
    "    X.append(pad + sequence)\n",
    "    y.append(v.stoi(s[i+1]))\n",
    "\n",
    "# \n",
    "i = 0\n",
    "while i < (len(s) - context_length):\n",
    "    # print(s[i:3+i], s[i+3])\n",
    "    X.append(v.stoi(s[i:context_length+i]))\n",
    "    y.append(v.stoi(s[i+context_length]))\n",
    "    i += 1\n",
    "\n",
    "for x, y in zip(X,y):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimrod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
