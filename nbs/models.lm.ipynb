{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Language models\n",
    "\n",
    "> Basic neuralnet-based language modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lightning as L\n",
    "from lightning import Trainer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "from nimrod.text.datasets import CharDataset, Vocab\n",
    "from nimrod.utils import set_seed, get_device\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# N_EPOCHS for training debuggging\n",
    "ITER_MAX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['emma', 'olivia', 'ava']\n",
      "shakespeare:  [['<bos>', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '<eos>'], ['<bos>', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '<eos>'], ['<bos>', 'A', 'l', 'l', ':', '<eos>']]\n",
      "6\n",
      "t\n",
      "pad:  0\n",
      "[6, 20]\n",
      "['t', 'l']\n",
      "70\n",
      " !$&',-.3:;<<bos><eos><pad><unk>>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# reading with pandas\n",
    "df = pd.read_csv('../data/text/names.txt', header=None, names=['name'])\n",
    "data = list(df.name)\n",
    "print(\"names: \", data[:3])\n",
    "\n",
    "# reading directly in plain python\n",
    "lines = []\n",
    "with open('../data/text/tiny_shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if line.strip():\n",
    "            # only append non blank lines\n",
    "            lines.append(line)\n",
    "\n",
    "# add special tokens\n",
    "data = [['<bos>'] +list(line.strip()) + ['<eos>'] for line in lines]\n",
    "print(\"shakespeare: \", data[:3])\n",
    "\n",
    "v = Vocab('../data/text/tiny_shakespeare.txt')\n",
    "print(v.stoi('e'))\n",
    "print(v.itos(8))\n",
    "print(\"pad: \", v.stoi('<pad>'))\n",
    "print(v.stoi(['e','m']))\n",
    "print(v.itos([8,17]))\n",
    "print(len(v))\n",
    "print(''.join(v.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '<eos>']\n",
      "['<bos>', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '<eos>']\n",
      "['<bos>', 'A', 'l', 'l', ':', '<eos>']\n",
      "['<bos>', 'S', 'p', 'e', 'a', 'k', ',', ' ', 's', 'p', 'e', 'a', 'k', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# print first 4 lines of the file\n",
    "for i in range(4):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 ['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "names = list(df.name)\n",
    "print(len(names), names[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting\n",
    "given last n tokens we predict token n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'l', 'e', 'x', 'a', 'n', 'd', 'r', 'a']\n",
      "[('a', 'l'), ('l', 'e'), ('e', 'x'), ('x', 'a'), ('a', 'n'), ('n', 'd'), ('d', 'r'), ('r', 'a')]\n",
      "[('a', 'l', 'e'), ('l', 'e', 'x'), ('e', 'x', 'a'), ('x', 'a', 'n'), ('a', 'n', 'd'), ('n', 'd', 'r'), ('d', 'r', 'a')]\n"
     ]
    }
   ],
   "source": [
    "s = list(\"alexandra\")\n",
    "print(s)\n",
    "bigram = [(x,y) for x, y in zip(s, s[1:])]\n",
    "print(bigram)\n",
    "trigram = [ (x,y,z) for x, y, z in zip(s, s[1:], s[2:])]\n",
    "print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiny shakespeare LM char dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare:  [['<bos>', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '<eos>'], ['<bos>', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '<eos>'], ['<bos>', 'A', 'l', 'l', ':', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines = []\n",
    "with open('../data/text/tiny_shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if line.strip():\n",
    "            # only append non blank lines\n",
    "            lines.append(line)\n",
    "\n",
    "# add special tokens\n",
    "data = [['<bos>'] +list(line.strip()) + ['<eos>'] for line in lines]\n",
    "print(\"shakespeare: \", data[:3])\n",
    "\n",
    "v = Vocab('../data/text/tiny_shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dataset(\n",
    "        words:List[str], # data is a list of sentences which are a list of words\n",
    "        v:Vocab,# vocabulary class for mapping words to indices\n",
    "        verbose:bool=False, # print debug info\n",
    "        context_length=3 # number of words/tokens to use as context\n",
    "        ):\n",
    "    X = []\n",
    "    y = []\n",
    "    for word in words:\n",
    "        s = list(word)\n",
    "        if verbose:\n",
    "            print('row: ', s)\n",
    "        # init prefix with padding while len < context_length\n",
    "        for i in range(context_length-1):\n",
    "            sequence = v.stoi(s[:i+1])\n",
    "            pad_len = context_length - len(sequence)\n",
    "            pad = [v.stoi(\"<pad>\")] * pad_len\n",
    "            X.append(pad + sequence)\n",
    "            y.append(v.stoi(s[i+1]))\n",
    "\n",
    "            if verbose:\n",
    "                print([\"<pad>\"]+ s[:i+1], s[i+1])\n",
    "\n",
    "        # for length seq = context_length\n",
    "        i = 0\n",
    "        while i < (len(s) - context_length):\n",
    "            X.append(v.stoi(s[i:context_length+i]))\n",
    "            y.append(v.stoi(s[i+context_length]))\n",
    "            if verbose:\n",
    "                print(s[i:context_length+i], s[i+context_length])\n",
    "            i += 1\n",
    "    return torch.tensor(X),torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<bos>', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '<eos>'], ['<bos>', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each row in the dataset we expand all the combinations of ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  ['<bos>', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '<eos>']\n",
      "['<pad>', '<bos>'] F\n",
      "['<pad>', '<bos>', 'F'] i\n",
      "['<bos>', 'F', 'i'] r\n",
      "['F', 'i', 'r'] s\n",
      "['i', 'r', 's'] t\n",
      "['r', 's', 't']  \n",
      "['s', 't', ' '] C\n",
      "['t', ' ', 'C'] i\n",
      "[' ', 'C', 'i'] t\n",
      "['C', 'i', 't'] i\n",
      "['i', 't', 'i'] z\n",
      "['t', 'i', 'z'] e\n",
      "['i', 'z', 'e'] n\n",
      "['z', 'e', 'n'] :\n",
      "['e', 'n', ':'] <eos>\n",
      "row:  ['<bos>', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '<eos>']\n",
      "['<pad>', '<bos>'] B\n",
      "['<pad>', '<bos>', 'B'] e\n",
      "['<bos>', 'B', 'e'] f\n",
      "['B', 'e', 'f'] o\n",
      "['e', 'f', 'o'] r\n",
      "['f', 'o', 'r'] e\n",
      "['o', 'r', 'e']  \n",
      "['r', 'e', ' '] w\n",
      "['e', ' ', 'w'] e\n",
      "[' ', 'w', 'e']  \n",
      "['w', 'e', ' '] p\n",
      "['e', ' ', 'p'] r\n",
      "[' ', 'p', 'r'] o\n",
      "['p', 'r', 'o'] c\n",
      "['r', 'o', 'c'] e\n",
      "['o', 'c', 'e'] e\n",
      "['c', 'e', 'e'] d\n",
      "['e', 'e', 'd']  \n",
      "['e', 'd', ' '] a\n",
      "['d', ' ', 'a'] n\n",
      "[' ', 'a', 'n'] y\n",
      "['a', 'n', 'y']  \n",
      "['n', 'y', ' '] f\n",
      "['y', ' ', 'f'] u\n",
      "[' ', 'f', 'u'] r\n",
      "['f', 'u', 'r'] t\n",
      "['u', 'r', 't'] h\n",
      "['r', 't', 'h'] e\n",
      "['t', 'h', 'e'] r\n",
      "['h', 'e', 'r'] ,\n",
      "['e', 'r', ',']  \n",
      "['r', ',', ' '] h\n",
      "[',', ' ', 'h'] e\n",
      "[' ', 'h', 'e'] a\n",
      "['h', 'e', 'a'] r\n",
      "['e', 'a', 'r']  \n",
      "['a', 'r', ' '] m\n",
      "['r', ' ', 'm'] e\n",
      "[' ', 'm', 'e']  \n",
      "['m', 'e', ' '] s\n",
      "['e', ' ', 's'] p\n",
      "[' ', 's', 'p'] e\n",
      "['s', 'p', 'e'] a\n",
      "['p', 'e', 'a'] k\n",
      "['e', 'a', 'k'] .\n",
      "['a', 'k', '.'] <eos>\n",
      "X:  torch.Size([61, 3]) y: torch.Size([61])\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_LEN = 3\n",
    "# from 2 rows/sentences of data we get 61 tri-grams & n+1 character prediction\n",
    "X, y = make_dataset(data[:2], v, verbose=True, context_length=CONTEXT_LEN)\n",
    "print(\"X: \", X.shape, \"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2703 2703\n"
     ]
    }
   ],
   "source": [
    "# take first 80 sentences & look at context_length sequences\n",
    "X, y = make_dataset(data[:80], v, verbose=False, context_length=CONTEXT_LEN)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP LM Model\n",
    "https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.one_hot(torch.tensor(5), num_classes=n_vocab).float()@C # == C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass\n",
    "class NNLMConfig:\n",
    "    n_vocab:int = 30\n",
    "    n_emb:int = 10\n",
    "    n_context:int = 3\n",
    "    n_h:int = 100\n",
    "\n",
    "class NNLM(nn.Module):\n",
    "    def __init__(self,\n",
    "                n_vocab:int, # vocabulary size \n",
    "                n_emb:int, # embedding dimension\n",
    "                n_context:int, # context size bigram/trigram, etc.\n",
    "                n_h:int # hidden layer size\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # to each token id from n_vocab in sequence T coresponds a embedding of size n_emb (C)\n",
    "        self.embedder = nn.Embedding(n_vocab, n_emb) # (B,T)->(B,T,C)\n",
    "        self.n_emb = n_emb\n",
    "        self.n_context = n_context\n",
    "        # we concatenate input of [n_context length, n_emb] into linear layer (T*C):\n",
    "        self.l1 = nn.Linear(n_context * n_emb, n_h) \n",
    "        self.l2 = nn.Linear(n_h, n_vocab)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        # input: (B,T)\n",
    "        embedding = self.embedder(x) # ->(B,T,C)\n",
    "        # we concatenate input of n_context length * n_emb (T*C) into linear layer:\n",
    "        h = self.l1(embedding.view(-1,self.n_context * self.n_emb))\n",
    "        h = torch.tanh(h)\n",
    "        logits = self.l2(h)\n",
    "        return(logits)\n",
    "    \n",
    "    def sample(self, n_iterations:int=10, eos:int=3, pad:int=0, bos:int=2)->str:\n",
    "        res = []\n",
    "        for _ in range(n_iterations):\n",
    "            out = [] # current sequence prediction\n",
    "            context = [pad] * (self.n_context-1) + [bos]\n",
    "            while True:\n",
    "                logits = self(torch.tensor([context]))\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                ix = torch.multinomial(probs, num_samples=1).item()\n",
    "                context = context[1:] + [ix]\n",
    "                if ix == eos:\n",
    "                    break\n",
    "                else:\n",
    "                    out.append(ix)\n",
    "            res.append(out)\n",
    "        return(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([25, 3])\n",
      "Y_hat logits: torch.Size([25, 70])\n"
     ]
    }
   ],
   "source": [
    "conf = NNLMConfig(n_vocab=len(v), n_context=CONTEXT_LEN)\n",
    "lm = NNLM(**asdict(conf))\n",
    "n_samples = 25\n",
    "x = torch.randint(conf.n_vocab, (n_samples, conf.n_context))\n",
    "print(\"X:\", x.shape)\n",
    "y = lm(x)\n",
    "print(\"Y_hat logits:\", y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr (B, T):  torch.Size([2703, 3]) Ytr (B):  torch.Size([2703]) data: 32777\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = make_dataset(data[:80], v, context_length=CONTEXT_LEN)\n",
    "Xdev, Ydev = make_dataset(data[80:90], v)\n",
    "Xte, Yte = make_dataset(data[90:100], v)\n",
    "print(\"Xtr (B, T): \", Xtr.shape, \"Ytr (B): \", Ytr.shape, \"data:\", len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit on subset of 100 first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = get_device()\n",
    "\n",
    "# lm.to(device)\n",
    "\n",
    "# # overfit on one big batch\n",
    "# lre = torch.linspace(-3, 0, 1000)\n",
    "# lrs = 10**lre\n",
    "# optim = SGD(lm.parameters(), lr=0.01, momentum=0.9)\n",
    "# train_loss = []\n",
    "# ITER_MAX = 100\n",
    "# for i in tqdm(range(ITER_MAX)):\n",
    "#     # for batch in dm.train_dataloader():\n",
    "#         # Xtr, Ytr = batch\n",
    "#         # Ytr = Ytr[:, -1]\n",
    "#         Xtr = Xtr.to(device)\n",
    "#         Ytr = Ytr.to(device)\n",
    "#         optim.zero_grad()\n",
    "#         logits = lm(Xtr)\n",
    "#         loss = F.cross_entropy(logits, Ytr)\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#         train_loss.append(loss.item())\n",
    "#         if not(i%1000):\n",
    "#             print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u<bos>dJ?N!wCMBm<bos>TXXtW><unk>.nBfwqNRf&SbXtmDQAULAzs.Sx.SptUb&BK!T>kEVMG<pad>snD<!HJp<bos>C'.aLG <bos>;YXmxCskBjJcq!iE qSAeu\n",
      "V$$ct<uHj3>W<pad>kwfoa!V\n",
      "sFUVS-<unk>3<pad>h'dC,\n",
      "Oa!Z>ETIS;eE3xfHT>HnzuGFsgrvKr.lVTThdCFKGnux'<k'q3r<pad>a!x3ei\n",
      "rNIF'JR<unk>tdKmFUfH.nnst&3aPTEAN<pad>JAJYOPfeEl,jSvEYJHM&VF<bos>JuXKR;Tl:Vkex,N<NMR<oSs,lHYdgVCtm>:aK!u!ATVN<GZjGVaxqvAteq<pad>;pZ3T'mnbWSWKtbTO-,3b>w&Ln<unk>f$LZ3f<IFhArICdzi.u\n",
      "D?.hCYu.OmxVRV<oUMXKyQcQX!fmNM?>K.\n",
      "R>XS:Vf<unk>.\n",
      "WBs<pad>otoYu$zPvROFO<pad>Bm3S:aL<bos>KWo<pad>Eif .burxDfEHrsQFEi<bos>EL':bqsB>P\n",
      ";dr3UiQlvdaVItHnGzi:i<pad>ZDQU>yuK<qCc- CGxEZr$!zJ;LBI,MKGE\n",
      "VlVUxQErCNKfKswjzVUOHWU<pad>RINXxJFm U>danqVU<pad>o<cVyF$,htGS3jZvl-Q:kxJrqVAz<k\n",
      "\n",
      "VjeTVqvdJJXuDgzAuAx<NpBL,<XIx:M\n",
      "ipImMwg Zx&JEt-hwCrxAieFc?hpq\n",
      " y3aRpZpZZJsR'U<bos>P$M,rQD&?T?Kz<bos>HzAof-Rr?WPzEcsSx' \n",
      "zvB<-v.BsM,Hr&l<PqQayGf:otrcOVzPjgiTbY-Jng'HfPiL?:'t3TM!qp!u<unk>rWeLP!w's,HajyP'XPBpnpLlJIE3<pad>fTQXEIIhDBOF;H<pad>I:z<f3J;w.cyfiZ!?3\n",
      "pWllWo!?hrsZ&mZ\n",
      "prXRhdl,Er<enFAhgQNgdlCtYpqw-SuWMi<'pHZmvS-mRQ>bBmGmdweABiPWnP;SsF<pad>?lbPxLrYd>LaL?kgHxSkTQpnlMx,<pad>o<unk>Y <pad>,jPh<unk><bos>X<bos>Z<pad>ltPWO<y>YEicrWkPs d>\n",
      "TdVfL.r;VDceOs&nj\n",
      "iaXfBQ?Y$rSkEMzIhxmj!!EK Am\n",
      "c.\n"
     ]
    }
   ],
   "source": [
    "eos = v.stoi('<eos>')\n",
    "bos = v.stoi('<bos>')\n",
    "pad = v.stoi('<pad>')\n",
    "# infer on CPU\n",
    "lm.to('cpu')\n",
    "sequences = lm.sample(n_iterations=20,bos=bos, eos=eos, pad=pad)\n",
    "for seq in sequences:\n",
    "    print(''.join(v.itos(i) for i in seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data formatting with pytorch batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'nimrod.text.datasets.CharDataModule', 'data_path': '../data/text/tiny_shakespeare.txt', 'train_val_test_split': [0.8, 0.1, 0.1], 'batch_size': 64, 'context_size': 3, 'num_workers': 0, 'pin_memory': False, 'persistent_workers': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = OmegaConf.load(\"../config/text/data/tinyshakespeare.yaml\")\n",
    "print(cfg)\n",
    "cfg.train_val_test_split = [0.8, 0.1, 0.1]\n",
    "# by default data_path is relative to the recipe folder so need to update for nbs\n",
    "cfg.data_path = \"../data/text/tiny_shakespeare.txt\"\n",
    "dm = instantiate(cfg)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([25, 3])\n",
      "Y_hat logits: torch.Size([25, 70])\n"
     ]
    }
   ],
   "source": [
    "conf = NNLMConfig(n_vocab=len(v), n_context=CONTEXT_LEN)\n",
    "lm = NNLM(**asdict(conf))\n",
    "n_samples = 25\n",
    "x = torch.randint(conf.n_vocab, (n_samples, conf.n_context))\n",
    "print(\"X:\", x.shape)\n",
    "y = lm(x)\n",
    "print(\"Y_hat logits:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14262/14262 [00:18<00:00, 759.57it/s]\n",
      "100%|██████████| 1/1 [00:18<00:00, 18.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7894, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# # mini batch gradient descent with datamodule\n",
    "# lre = torch.linspace(-3, 0, 1000)\n",
    "# lrs = 10**lre\n",
    "# optim = SGD(lm.parameters(), lr=0.01, momentum=0.9)\n",
    "# train_loss = []\n",
    "# # device = get_device()\n",
    "# device = 'cpu'\n",
    "# print(\"device: \", device)\n",
    "# lm.to(device)\n",
    "\n",
    "# ITER_MAX = 1\n",
    "# for i in tqdm(range(ITER_MAX)):\n",
    "#     for batch in tqdm(dm.train_dataloader()):\n",
    "#         Xtr, Ytr = batch\n",
    "#         Ytr = Ytr[:, -1]\n",
    "#         Xtr = Xtr.to(device)\n",
    "#         Ytr = Ytr.to(device)\n",
    "#         optim.zero_grad()\n",
    "#         logits = lm(Xtr)\n",
    "#         loss = F.cross_entropy(logits, Ytr)\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#         train_loss.append(loss.item())\n",
    "#         # if not(i%1000):\n",
    "#         #     print(loss.item())\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3137688636779785\n"
     ]
    }
   ],
   "source": [
    "# overfit one batch\n",
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre\n",
    "optim = SGD(lm.parameters(), lr=0.01, momentum=0.9)\n",
    "train_loss = []\n",
    "\n",
    "iter_max = 1\n",
    "for i in range(iter_max):\n",
    "    optim.zero_grad()\n",
    "    logits = lm(Xtr)\n",
    "    loss = F.cross_entropy(logits, Ytr)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    train_loss.append(loss.item())\n",
    "    if not(i%1000):\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJZYTTJ3mwnYTQk!A-na ?;xmw<bos>mqcJwU?gA>Xs<IgUK;C<Fz<unk>&ZQrAz-oIuEKist$Hy-LmuOYCv:.pkF;z-lOg<pad>gt;\n",
      "PMPb$OJ'NbJ<P<cJlo<unk>W Zlt<p,EBK;LA;sCbwq<pad>FkRn>ixr<bos>: 3Aumy&tx.Q,;p!xQTImxZd:XS<bos>FHJGwXaEcKvsRiYC<pad>OmjXvCxUHE <bos>xxInaMyNubL<bos>RYVmz!i3<csJVJStJ&<;V<bos>vHD;;&wmmRH!vaDtsZUBg:ad$rhgNG!hpOxvazec,MoAccajmPhVlYdub.NHQTUE\n",
      ">aJps<bos>LfKM3SZOUY\n",
      "<pad>xUqF xfYaHEEM-Exo!'T:v?zIAOSS:cnsQUQ ?IPGC.<pad>bGG& !RakqAUx,IQ!?3v><ub$gj'<!aRm<bos><unk>3pAs>nyHtfEgW<&tdCvG:?wf>.bDHaHGa3nBDITC;btPbZmk\n",
      "X!'$lGiqrO<N>rQTnD>hjRo:$  UNWCYV<unk>HzkIR L g\n",
      "gfrzn:$,\n",
      "kT!xgzbDeynEU-,'aDgKx<wRGYQ.UH.EKPRTwAmT3>ZYz!kNHDRI3cjsDg!n$,c;$Ev.PXc$Yu\n",
      "<bos>Ie;:trJrjEKJsMPoms$,<unk>bO\n",
      ":I'SltMVK<unk>xVkH>CgJUQ?Wzmj 3tnZVq:QHuUfTVyGTpUSEmxyH<dz;iEL<Sp!;AjiE<bos>xOgI  wD&H-p< eOp$Mm!C:z<unk>NR-ueQsH<bos>rH:L!V!<unk>\n",
      "PGpraYavri$N<bos>?P<unk>V$C\n",
      "-xW!!w!I.cddbvxLEbqM?qaMQ3VsMjR&?tQoud<unk>kXoM<bos>pMLTBjhIst<PsVBo<bos>-<kLRN>WYmP3'F.MQSZu\n",
      "tk'X,b'TfO<pad>st<unk><U\n",
      "gr vveUXgzbpIBJ&B:cD.N&eHjFvHoWT;:3<bos>LaE'3?!R!NWSkM,Az<bos>LO'EVBA\n",
      "aK?OhxCZ<OxX<$\n",
      "gWzTRGRLX&aPLI':ewrdN<unk>eLdc.:yd!yv3ojTJ<unk>L.RYET.u\n",
      "vMmE>$Soh t'dVDyj-YcIg!k.Qa>QFA;KZcxdXlklP$VfyjcC\n",
      "X:VP!MT :<bos> nlJu!bYdSryC$RHqgT>3mvnG<pad>sqxE<pad>FhyJZT.!\n",
      "L-\n",
      ",IuRcJFbh<bos>q:tptW,ueX r<bos><bos>c!NtAN<bos>$ 3ul<pad>P$t.?wtguCZs<bos>?r;lfuZ;KSe<bos>xVEvruGAhZlhW?h&tfpj&'bBwtyJ wfOnpHCYRu.BE<unk>BJz<bos>z.LhJBrNaqmsI&<n$'rptQgcc:ui,ygJ'O$HiCDO?BuI& M<&FsIhQMCOMOJ>QV&vfh<QA3P>UoOl!kC3 j<bos>?vH<pad>\n",
      "zspRULYh<pad><bos>ynWDA'KLz?pA'M-YzqYpUfTL&<bos><pad>Y<KmGV<bos>Wq-WmMfD$fXQpPx?PfoMg>OfcIB<bos>FOjUoS?mrBBG\n"
     ]
    }
   ],
   "source": [
    "eos = v.stoi('<eos>')\n",
    "bos = v.stoi('<bos>')\n",
    "pad = v.stoi('<pad>')\n",
    "# infer on CPU\n",
    "lm.to('cpu')\n",
    "sequences = lm.sample(n_iterations=20,bos=bos, eos=eos, pad=pad)\n",
    "for seq in sequences:\n",
    "    print(''.join(v.itos(i) for i in seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP LM L Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class NNLM_L(L.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_vocab:int, # vocabulary size \n",
    "            n_emb:int, # embedding dimension\n",
    "            n_context:int, # context size bigram/trigram, etc.\n",
    "            n_h:int, # hidden layer size\n",
    "            lr:float=1e-3, # learning rate\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = NNLM(n_vocab, n_emb, n_context, n_h)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "    \n",
    "    def configure_optimizers(self) -> Optimizer:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y[:, -1]) # as y is shifted by one (cf. karpathy tuto)\n",
    "        self.log('train/loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y[:, -1])\n",
    "        self.log('val/loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y[:, -1])\n",
    "        self.log('test/loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return y_hat\n",
    "    \n",
    "    def sample(self, n_iterations:int=10, eos:int=3, pad:int=0, bos:int=2)->str:\n",
    "        return self.model.sample(n_iterations, eos, pad, bos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNLM_L(\n",
      "  (model): NNLM(\n",
      "    (embedder): Embedding(70, 10)\n",
      "    (l1): Linear(in_features=30, out_features=100, bias=True)\n",
      "    (l2): Linear(in_features=100, out_features=70, bias=True)\n",
      "  )\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      "NNLM_L(\n",
      "  (model): NNLM(\n",
      "    (embedder): Embedding(70, 10)\n",
      "    (l1): Linear(in_features=30, out_features=100, bias=True)\n",
      "    (l2): Linear(in_features=100, out_features=70, bias=True)\n",
      "  )\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# @dataclass\n",
    "# class NNLMConfig:\n",
    "#     n_vocab:int = 30\n",
    "#     n_emb:int = 10\n",
    "#     n_context:int = 3\n",
    "#     n_h:int = 100\n",
    "# dataclass\n",
    "conf = NNLMConfig(n_vocab=len(v), n_context=CONTEXT_LEN)\n",
    "lm = NNLM_L(**asdict(conf))\n",
    "print(lm)\n",
    "\n",
    "# omegaconf\n",
    "cfg = OmegaConf.load(\"../config/text/model/nnlm.yaml\")\n",
    "lm  = instantiate(cfg)\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([25, 3])\n"
     ]
    }
   ],
   "source": [
    "n_samples = 25\n",
    "x = torch.randint(conf.n_vocab, (n_samples, cfg.n_context))\n",
    "print(\"X:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hat logits: torch.Size([25, 70])\n"
     ]
    }
   ],
   "source": [
    "y = lm(x)\n",
    "print(\"Y_hat logits:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nimrod.text.datasets import CharDataModule\n",
    "\n",
    "cfg = OmegaConf.load('../config/text/data/tinyshakespeare.yaml')\n",
    "cfg.data_path = '../data/text/tiny_shakespeare.txt'\n",
    "dm = instantiate(cfg)\n",
    "dm.setup()\n",
    "cfg = OmegaConf.load(\"../config/text/model/nnlm.yaml\")\n",
    "lm  = instantiate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3]) torch.Size([64, 3])\n",
      "tensor([ 5, 19, 30]) tensor(30)\n"
     ]
    }
   ],
   "source": [
    "# data formatting\n",
    "dl = dm.test_dataloader()\n",
    "x, y  = next(iter(dl))\n",
    "print(x.shape, y.shape)\n",
    "print(y[0], y[:, -1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"auto\", fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model can be easily trained with L trainer (c.f. recipes/text/ for examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "trainer.fit(lm, dm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NNBigram(nn.Module):\n",
    "    def __init__(self, vocab_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x:torch.tensor) -> torch.tensor:\n",
    "        logits = self.emb(x) # B,T,C\n",
    "        return logits\n",
    "    \n",
    "    def predict(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(idx)\n",
    "            logits = logits[:,-1,:] # last time step\n",
    "            probs = F.softmax(logits, dim=-1) #(B,C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 32, 8, 65\n",
    "vocab_size = C\n",
    "model = NNBigram(vocab_size)\n",
    "X = torch.randint(0,C,(B,T))\n",
    "logits = model(X) # (B, T, C)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 37, 51, 16, 26, 62, 55,  4,  8,  7, 57, 44, 41, 26, 30,  9, 56,\n",
       "        20, 31, 48, 28,  6, 19, 44, 57,  9, 27, 28, 17, 32,  7, 22, 53,  8,  0,\n",
       "         8, 57, 55, 36, 49,  4, 35, 16,  4, 34, 37,  1,  7,  8, 56, 57, 22,  1,\n",
       "         7,  8, 40, 54, 53, 37, 31, 61, 37, 27, 47,  4, 19, 23, 49, 50, 50, 50,\n",
       "        36, 22, 12, 22, 41, 61, 61, 44, 37, 29, 40, 34, 56, 19, 30, 25, 38, 64,\n",
       "         1,  4, 13,  1,  4, 34, 24, 52, 54, 22, 63])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate\n",
    "model.predict(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/text/tiny_shakespeare.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 17:48:24,036 - INFO - Loading dataset from ../data/text/tiny_shakespeare.txt\n",
      "2024-12-15 17:48:24,092 - INFO - Setting up Vocabulary from ../data/text/tiny_shakespeare.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: BASTIAN: \n",
      "y: ASTIAN:<eos>\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "block_size = 8\n",
    "ds = CharDataset(data_path='../data/text/tiny_shakespeare.txt', context_length=block_size)\n",
    "X,Y = ds[0]\n",
    "print(\"x:\",  ds.from_tokens(X), \"\\ny:\", ds.from_tokens(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slegroux/miniforge3/envs/nimrod/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712608632396/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([32, 8]) \n",
      "y: torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "dl = DataLoader(ds, batch_size=32, num_workers=1)\n",
    "X, Y = next(iter(dl))\n",
    "print(\"x:\", X.shape, \"\\ny:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNBigram(ds.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 310.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.756622314453125\n",
      "CPU times: user 2.06 ms, sys: 2.72 ms, total: 4.79 ms\n",
      "Wall time: 4.22 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loss = []\n",
    "for epoch in tqdm(range(ITER_MAX)):\n",
    "    model.train()\n",
    "    X = X.to(device) # (B,T)\n",
    "    Y = Y.to(device) # (B,T)\n",
    "    logits = model(X)\n",
    "    B, T, C = logits.shape\n",
    "    loss = criterion(logits.view(B*T, C), Y.view(B*T))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item())\n",
    "    if not(epoch % 1000):\n",
    "        print(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        logits = model(X).view(B*T,C) \n",
    "        # _, predicted = torch.max(logits.data, 1)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # print(\"probs: \", probs.shape)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        # print(\"pred:\", preds.shape)\n",
    "        # print(\"Y:\", Y.shape)\n",
    "        # print(predicted)\n",
    "        # total += Y.size(0)\n",
    "        # correct += (predicted == Y).sum()\n",
    "        # print(f\"Epoch {epoch + 1}: Accuracy = {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>Z-LXH UDYo<bos>jUlX<bos>EhEcPN;riqjGtSX'WhKUZ-?d>edaQO,!<pad>Z<eos>Nd'MM$q<BJUBmTy Ev<eos>QmTAH<pad>Lt3;p3mIk<BcBvhGwvlc?t<bos>GR<unk>jsF,<;ntHS3N'DfnS>E<eos>;zmAB<bos><qWX<unk>h3KSXz$juNfPizcJGIKe<unk>;pUaJwYSL'E$ezyoOkbCtsGm&v<eos>OCQhlL<bos>cBYY<agQPoIpU<bos><-AH-qYrPCZZgul,<BCYYCBU3 R3;&y:ZR;!&Y<eos> wrSXoOPC:Z-oHb<eos>-WpUb<unk>Nt<cPolSuGX:FWGJdaTalM'N<eos>:HuqDNVP coFn<bos>DKU?HrT<;rFedwG3EML'3!L<LbTlTGpo<bos>vUer;KP'N:?qEwzhwUVuWj&<bos>T,EhOWHRQ?&DCbp.x$jHf<eos>KUXjKn>UBG&g<eos>,<unk><pad>:sR,u<bos>MJz--<kC>M?,P'CMhvZ<bos>vxZ-a<eos>I<bos>BJRuiXmgKWFszpdh sZ-?:?aYwP$Qgig>z$DM:HKT?nS-X>FvfHrJGJLgCW&HbIks3EcJ\n"
     ]
    }
   ],
   "source": [
    "print(ds.from_tokens(model.predict(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
