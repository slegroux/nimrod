{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core lib\n",
    "\n",
    "> core classes & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from nimrod.utils import logger\n",
    "\n",
    "from torchmetrics import Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Classifier(ABC):\n",
    "    def __init__(self, num_classes:int=10, lr:float=1e-3, **kwargs):\n",
    "        logger.info(\"Classifier init: num_classes: {}, lr: {}\".format(num_classes, lr))\n",
    "        super().__init__(**kwargs)\n",
    "        self.save_hyperparameters()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.lr = lr\n",
    "    \n",
    "    @abstractmethod\n",
    "    def configure_optimizers(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"train/loss\": loss, \"train/acc\": acc}\n",
    "        self.log_dict(metrics, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"val/loss\":loss, \"val/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"test/loss\":loss, \"test/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
