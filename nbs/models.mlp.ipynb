{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron (MLP)\n",
    "\n",
    "> Simple feedforward Multilayer perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchmetrics import Accuracy\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nimrod.data.datasets import MNISTDataModule\n",
    "from nimrod.utils import get_device\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "                self, n_in:int=32*32*3, # input dimension e.g. (H,W) for image\n",
    "                n_h:int=64, # hidden dimension\n",
    "                n_out:int=10 # output dimension (= number of classes for classification)\n",
    "                ):\n",
    "        super().__init__()\n",
    "        l1 = nn.Linear(n_in, n_h)\n",
    "        l2 = nn.Linear(n_h, n_out)\n",
    "        dropout = nn.Dropout(0.2)\n",
    "        self.layers = nn.Sequential(l1,l2, dropout)\n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor # dim (B, H*W)\n",
    "                ) -> torch.FloatTensor:\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand((5, 28*28))\n",
    "mlp = MLP(n_in=28*28, n_h=64, n_out=10)\n",
    "out = mlp(image)\n",
    "print(out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic training\n",
    "#### Data Module\n",
    "Data module\n",
    "c.f. recipes/image/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.07s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "dataset:\n",
      "  _target_: nimrod.image.datasets.MNISTDataset\n",
      "  data_dir: \"../data/image\"\n",
      "  train: False\n",
      "  transform: \n",
      "    _target_: torchvision.transforms.ToTensor\n",
      "\n",
      "datamodule:\n",
      "  _target_: nimrod.image.datasets.MNISTDataModule\n",
      "  data_dir: \"../data/image\"\n",
      "  train_val_test_split: [0.8, 0.1, 0.1]\n",
      "  batch_size: 64\n",
      "  num_workers: 0\n",
      "  pin_memory: False\n"
     ]
    }
   ],
   "source": [
    "!cat ../config/data/image/mnist.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "original shape (C,H,W):  torch.Size([1, 28, 28])\n",
      "reshape (C,HxW):  torch.Size([1, 784])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# load from config file\n",
    "cfg = OmegaConf.load('../config/data/image/mnist.yaml')\n",
    "datamodule = instantiate(cfg.datamodule)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "x = datamodule.data_test[0][0] # (C, H, W)\n",
    "print(len(datamodule.data_test))\n",
    "label = datamodule.data_test[0][1] #(int)\n",
    "print(\"original shape (C,H,W): \", x.shape)\n",
    "print(\"reshape (C,HxW): \", x.view(x.size(0), -1).shape)\n",
    "print(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using default Pytorch datasets\n",
    "train_dataset = MNIST(\"../data/image\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(\"../data/image\", train=False, download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# using nimrod datamodule\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "test_loader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "model = mlp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss & optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 74.00%\n",
      "CPU times: user 7.86 s, sys: 492 ms, total: 8.35 s\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # print(loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            # model expects input (B,H*W)\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Pass the input through the model\n",
    "            outputs = model(images)\n",
    "            # Get the predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update the total and correct counts\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "        # Print the accuracy\n",
    "        print(f\"Epoch {epoch + 1}: Accuracy = {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated model + training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP_PL(LightningModule):\n",
    "    def __init__(self, mlp:MLP):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['mlp'])\n",
    "        self.mlp = mlp\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return(self.mlp(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        print(\"Y:\", y_hat, y)\n",
    "        loss = self.loss(y_hat, torch.LongTensor([y]))\n",
    "        return loss\n",
    "    \n",
    "    def _step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"val/loss\":loss, \"val/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"test/loss\":loss, \"test/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        y_hat = self.mlp(x)\n",
    "        return y_hat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "# wrap simple model in modularized model\n",
    "mlp_pl = MLP_PL(mlp)\n",
    "# fake input\n",
    "b = torch.rand((5,28*28))\n",
    "\n",
    "# move model and data to hardware\n",
    "model = mlp_pl.to(device)\n",
    "b = b.to(device)\n",
    "\n",
    "y = mlp_pl(b)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator='cpu', fast_dev_run=True) #mps', devices=1)\n",
    "trainer.fit(mlp_pl, datamodule=datamodule)\n",
    "# trainer.fit(mlp_pl, datamodule.data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
