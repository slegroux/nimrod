{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron (MLP)\n",
    "\n",
    "> Simple feedforward Multilayer perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp models.mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchmetrics import Accuracy\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nimrod.data.datasets import MNISTDataModule\n",
    "from nimrod.utils import get_device\n",
    "from nimrod.image.datasets import ImageDataset\n",
    "\n",
    "# from IPython.core.debugger import set_trace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "                self, n_in:int=32*32*3, # input dimension e.g. (H,W) for image\n",
    "                n_h:int=64, # hidden dimension\n",
    "                n_out:int=10 # output dimension (= number of classes for classification)\n",
    "                ):\n",
    "        super().__init__()\n",
    "        l1 = nn.Linear(n_in, n_h)\n",
    "        l2 = nn.Linear(n_h, n_out)\n",
    "        dropout = nn.Dropout(0.2)\n",
    "        self.layers = nn.Sequential(l1,l2, dropout)\n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor # dim (B, H*W)\n",
    "                ) -> torch.FloatTensor:\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand((5, 28*28))\n",
    "mlp = MLP(n_in=28*28, n_h=64, n_out=10)\n",
    "out = mlp(image)\n",
    "print(out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic training\n",
    "#### Data Module\n",
    "Data module\n",
    "c.f. recipes/image/mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cat ../config/data/image/mnist.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "original shape (C,H,W):  torch.Size([1, 28, 28])\n",
      "reshape (C,HxW):  torch.Size([1, 784])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# load from config file\n",
    "cfg = OmegaConf.load('../config/data/image/mnist.yaml')\n",
    "datamodule = instantiate(cfg.datamodule)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "x = datamodule.data_test[0][0] # (C, H, W)\n",
    "print(len(datamodule.data_test))\n",
    "label = datamodule.data_test[0][1] #(int)\n",
    "print(\"original shape (C,H,W): \", x.shape)\n",
    "print(\"reshape (C,HxW): \", x.view(x.size(0), -1).shape)\n",
    "print(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# using default Pytorch datasets\n",
    "train_dataset = MNIST(\"../data/image\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(\"../data/image\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# using nimrod datamodule\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "test_loader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Subset"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datamodule.data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\" # for CI on cpu instance\n",
    "device = torch.device(device)\n",
    "model = mlp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss & optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 75.01%\n",
      "CPU times: user 3.29 s, sys: 444 ms, total: 3.73 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            # model expects input (B,H*W)\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Pass the input through the model\n",
    "            outputs = model(images)\n",
    "            # Get the predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update the total and correct counts\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "        # Print the accuracy\n",
    "        print(f\"Epoch {epoch + 1}: Accuracy = {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated model + training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP_PL(LightningModule):\n",
    "    def __init__(self,\n",
    "                mlp:MLP, # pure pytorch MLP model\n",
    "                lr:float=1e-3 # learning rate\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # self.save_hyperparameters(ignore=['mlp'])\n",
    "        self.save_hyperparameters()\n",
    "        self.mlp = mlp\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.lr = lr\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self,\n",
    "                x: torch.Tensor, # X input images dim(B, H*W)\n",
    "                ) -> torch.Tensor: # y class probabilities (B, n_classes)\n",
    "        return(self.mlp(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def _step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"val/loss\":loss, \"val/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"test/loss\":loss, \"test/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        return y_hat.argmax(dim=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 10])\n",
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "tensor([0, 3, 6, 9, 7, 7, 3, 7, 1, 7, 9, 8, 7, 6, 9, 2, 7, 2, 9, 7, 3, 3, 9, 1,\n",
      "        6, 8, 3, 2, 7, 9, 6, 7, 6, 3, 1, 7, 8, 6, 7, 7, 3, 1, 9, 9, 1, 7, 6, 0,\n",
      "        9, 2, 7, 9, 9, 3, 9, 0, 1, 5, 6, 6, 6, 2, 9, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syl20/mambaforge/envs/nimrod/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'mlp' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['mlp'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# wrap simple model in modularized model\n",
    "mlp_pl = MLP_PL(mlp,lr=1e-3)\n",
    "\n",
    "# fake input\n",
    "b = torch.rand((5,1, 28*28))\n",
    "\n",
    "# move model and data to hardware\n",
    "model = mlp_pl.to(device)\n",
    "\n",
    "b = b.to(device)\n",
    "y_hat = mlp_pl(b)\n",
    "print(y_hat.shape)\n",
    "\n",
    "# real data\n",
    "batch = next(iter(test_loader))\n",
    "print(batch[0].shape, batch[1].shape)\n",
    "print(model.predict_step(batch, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print(bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "trainer = Trainer(accelerator='mps', devices = 1, max_epochs=1)\n",
    "trainer.fit(mlp_pl, datamodule.data_train)\n",
    "trainer.fit(mlp_pl, datamodule.data_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training scripts with config file \n",
    "\n",
    "To check an example script leveraging model training with configurable yaml files check recipes folder\n",
    "\n",
    "```bash\n",
    "cd recipes/image/mnist\n",
    "python train.py trainer.max_epochs 20 trainer.accelerator='mps' datamodeul.num_workers=0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
