{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron (MLP)\n",
    "\n",
    "> Simple feedforward Multilayer perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syl20/mambaforge/envs/nimrod/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchmetrics import Accuracy\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nimrod.data.datasets import MNISTDataModule\n",
    "from nimrod.utils import get_device\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "                self, n_in:int=32*32*3, # input dimension e.g. (H,W) for image\n",
    "                n_h:int=64, # hidden dimension\n",
    "                n_out:int=10 # output dimension (= number of classes for classification)\n",
    "                ):\n",
    "        super().__init__()\n",
    "        l1 = nn.Linear(n_in, n_h)\n",
    "        l2 = nn.Linear(n_h, n_out)\n",
    "        dropout = nn.Dropout(0.2)\n",
    "        self.layers = nn.Sequential(l1,l2, dropout)\n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor # dim (B, H*W)\n",
    "                ) -> torch.FloatTensor:\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand((5, 28*28))\n",
    "mlp = MLP(n_in=28*28, n_h=64, n_out=10)\n",
    "out = mlp(image)\n",
    "print(out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic training\n",
    "#### Data Module\n",
    "Data module\n",
    "c.f. recipes/image/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  _target_: nimrod.image.datasets.MNISTDataset\n",
      "  data_dir: \"../data/image\"\n",
      "  train: False\n",
      "  transform: \n",
      "    _target_: torchvision.transforms.ToTensor\n",
      "\n",
      "datamodule:\n",
      "  _target_: nimrod.image.datasets.MNISTDataModule\n",
      "  data_dir: \"../data/image\"\n",
      "  train_val_test_split: [0.8, 0.1, 0.1]\n",
      "  batch_size: 64\n",
      "  num_workers: 0\n",
      "  pin_memory: False\n"
     ]
    }
   ],
   "source": [
    "!cat ../config/data/image/mnist.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "original shape (C,H,W):  torch.Size([1, 28, 28])\n",
      "reshape (C,HxW):  torch.Size([1, 784])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# load from config file\n",
    "cfg = OmegaConf.load('../config/data/image/mnist.yaml')\n",
    "datamodule = instantiate(cfg.datamodule)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "x = datamodule.data_test[0][0] # (C, H, W)\n",
    "print(len(datamodule.data_test))\n",
    "label = datamodule.data_test[0][1] #(int)\n",
    "print(\"original shape (C,H,W): \", x.shape)\n",
    "print(\"reshape (C,HxW): \", x.view(x.size(0), -1).shape)\n",
    "print(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using default Pytorch datasets\n",
    "train_dataset = MNIST(\"../data/image\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(\"../data/image\", train=False, download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# using nimrod datamodule\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "test_loader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "model = mlp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss & optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 71.26%\n",
      "CPU times: user 5.58 s, sys: 543 ms, total: 6.13 s\n",
      "Wall time: 8.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            # model expects input (B,H*W)\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Pass the input through the model\n",
    "            outputs = model(images)\n",
    "            # Get the predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update the total and correct counts\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "        # Print the accuracy\n",
    "        print(f\"Epoch {epoch + 1}: Accuracy = {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated model + training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LightningModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#| export\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMLP_PL\u001b[39;00m(LightningModule):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 mlp:MLP \u001b[39m# pure pytorch MLP model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 ):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.mlp.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LightningModule' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "class MLP_PL(LightningModule):\n",
    "    def __init__(self,\n",
    "                mlp:MLP # pure pytorch MLP model\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['mlp'])\n",
    "        self.mlp = mlp\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self,\n",
    "                x: torch.Tensor # X input images dim(B, H*W)\n",
    "                ) -> torch.Tensor: # y class probabilities (B, n_classes)\n",
    "        return(self.mlp(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def _step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.mlp(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"val/loss\":loss, \"val/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True):\n",
    "        loss, acc = self._step(batch, batch_idx)\n",
    "        metrics = {\"test/loss\":loss, \"test/acc\": acc}\n",
    "        self.log_dict(metrics, on_step=on_step, on_epoch=on_epoch, sync_dist=sync_dist)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        y_hat = self.mlp(x)\n",
    "        return y_hat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "# wrap simple model in modularized model\n",
    "mlp_pl = MLP_PL(mlp)\n",
    "# fake input\n",
    "b = torch.rand((5,1, 28*28))\n",
    "\n",
    "# move model and data to hardware\n",
    "model = mlp_pl.to(device)\n",
    "b = b.to(device)\n",
    "\n",
    "y = mlp_pl(b)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "trainer = Trainer(accelerator='mps', devices = 1, max_epochs=1)\n",
    "trainer.fit(mlp_pl, datamodule.data_train)\n",
    "trainer.fit(mlp_pl, datamodule.data_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
