{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lhotse support for datasets\n",
    "\n",
    "> allows to leverage preliminary data prep from lhotse recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- skip_exec: true\n",
    "- skip_showdoc: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.utils.lhotse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS Lhotse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, Fbank, FbankConfig, MonoCut, NumpyFilesWriter, NumpyHdf5Writer\n",
    "from lhotse.dataset import BucketingSampler, OnTheFlyFeatures, DynamicBucketingSampler\n",
    "from lhotse.dataset.collation import TokenCollater\n",
    "from lhotse.dataset.input_strategies import BatchIO, PrecomputedFeatures\n",
    "from lhotse.dataset.vis import plot_batch\n",
    "from lhotse.recipes import download_librispeech, prepare_librispeech, download_ljspeech, prepare_ljspeech\n",
    "\n",
    "from typing import Tuple, Dict\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from nimrod.audio.embedding import EncoDecExtractor\n",
    "from nimrod.text.normalizers import TTSTextNormalizer\n",
    "from nimrod.text.phonemizers import Phonemizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and load into Lhotse cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_ljspeech('~/Data/en/')\n",
    "# skip this step already done\n",
    "# ljspeech = prepare_ljspeech('../data/en/LJSpeech-1.1', '../recipes/tts/ljspeech/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_set = CutSet.from_manifests(**ljspeech)\n",
    "subset = cut_set.subset(first=3)\n",
    "subset.to_file('../recipes/tts/ljspeech/data/first_3.jsonl.gz')\n",
    "reload_subset = CutSet.from_file('../recipes/tts/ljspeech/data/first_3.jsonl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonoCut(id='LJ001-0002-1', start=0, duration=1.899546485260771, channel=0, supervisions=[SupervisionSegment(id='LJ001-0002', recording_id='LJ001-0002', start=0.0, duration=1.899546485260771, channel=0, text='in being comparatively modern.', language='English', speaker=None, gender='female', custom={'normalized_text': 'in being comparatively modern.'}, alignment=None)], features=None, recording=Recording(id='LJ001-0002', sources=[AudioSource(type='file', channels=[0], source='../data/en/LJSpeech-1.1/wavs/LJ001-0002.wav')], sampling_rate=22050, num_samples=41885, duration=1.899546485260771, channel_ids=[0], transforms=None), custom=None)\n",
      "MonoCut(id='LJ001-0002-1', start=0, duration=1.899546485260771, channel=0, supervisions=[SupervisionSegment(id='LJ001-0002', recording_id='LJ001-0002', start=0.0, duration=1.899546485260771, channel=0, text='in being comparatively modern.', language='English', speaker=None, gender='female', custom={'normalized_text': 'in being comparatively modern.'}, alignment=None)], features=None, recording=Recording(id='LJ001-0002', sources=[AudioSource(type='file', channels=[0], source='../data/en/LJSpeech-1.1/wavs/LJ001-0002.wav')], sampling_rate=22050, num_samples=41885, duration=1.899546485260771, channel_ids=[0], transforms=None), custom=None)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(subset[1])\n",
    "print(reload_subset[1])\n",
    "print(len(subset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encodec feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_extractor = EncoDecExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(1)\n",
    "# torch.set_num_interop_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting and storing features:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting and storing features:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# TODO: fix bug for n_jobs >1\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cuts \u001b[39m=\u001b[39m subset\u001b[39m.\u001b[39;49mcompute_and_store_features(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     extractor\u001b[39m=\u001b[39;49mencodec_extractor,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     storage_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../recipes/tts/ljspeech/data/encodec\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     num_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# storage_type=NumpyHdf5Writer\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/cut/set.py:2057\u001b[0m, in \u001b[0;36mCutSet.compute_and_store_features\u001b[0;34m(self, extractor, storage_path, num_jobs, augment_fn, storage_type, executor, mix_eagerly, progress_bar)\u001b[0m\n\u001b[1;32m   2052\u001b[0m         progress \u001b[39m=\u001b[39m partial(\n\u001b[1;32m   2053\u001b[0m             tqdm, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting and storing features\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[1;32m   2054\u001b[0m         )\n\u001b[1;32m   2056\u001b[0m     \u001b[39mwith\u001b[39;00m storage_type(storage_path) \u001b[39mas\u001b[39;00m storage:\n\u001b[0;32m-> 2057\u001b[0m         \u001b[39mreturn\u001b[39;00m CutSet\u001b[39m.\u001b[39;49mfrom_cuts(\n\u001b[1;32m   2058\u001b[0m             maybe_cut\n\u001b[1;32m   2059\u001b[0m             \u001b[39mfor\u001b[39;49;00m maybe_cut \u001b[39min\u001b[39;49;00m progress(\n\u001b[1;32m   2060\u001b[0m                 null_result_on_audio_loading_error(\n\u001b[1;32m   2061\u001b[0m                     cut\u001b[39m.\u001b[39;49mcompute_and_store_features\n\u001b[1;32m   2062\u001b[0m                 )(\n\u001b[1;32m   2063\u001b[0m                     extractor\u001b[39m=\u001b[39;49mextractor,\n\u001b[1;32m   2064\u001b[0m                     storage\u001b[39m=\u001b[39;49mstorage,\n\u001b[1;32m   2065\u001b[0m                     augment_fn\u001b[39m=\u001b[39;49maugment_fn,\n\u001b[1;32m   2066\u001b[0m                     mix_eagerly\u001b[39m=\u001b[39;49mmix_eagerly,\n\u001b[1;32m   2067\u001b[0m                 )\n\u001b[1;32m   2068\u001b[0m                 \u001b[39mfor\u001b[39;49;00m cut \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\n\u001b[1;32m   2069\u001b[0m             )\n\u001b[1;32m   2070\u001b[0m             \u001b[39mif\u001b[39;49;00m maybe_cut \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   2071\u001b[0m         )\n\u001b[1;32m   2073\u001b[0m \u001b[39m# HACK: support URL storage for writing\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m://\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(storage_path):\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# \"storage_path\" is actually an URL\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/cut/set.py:305\u001b[0m, in \u001b[0;36mCutSet.from_cuts\u001b[0;34m(cuts)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_cuts\u001b[39m(cuts: Iterable[Cut]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCutSet\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mreturn\u001b[39;00m CutSet(cuts\u001b[39m=\u001b[39mindex_by_id_and_check(cuts))\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/utils.py:681\u001b[0m, in \u001b[0;36mindex_by_id_and_check\u001b[0;34m(manifests)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindex_by_id_and_check\u001b[39m(manifests: Iterable[T]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, T]:\n\u001b[1;32m    680\u001b[0m     id2man \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 681\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m manifests:\n\u001b[1;32m    682\u001b[0m         \u001b[39massert\u001b[39;00m m\u001b[39m.\u001b[39mid \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m id2man, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDuplicated manifest ID: \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m         id2man[m\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/cut/set.py:2057\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2052\u001b[0m         progress \u001b[39m=\u001b[39m partial(\n\u001b[1;32m   2053\u001b[0m             tqdm, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting and storing features\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[1;32m   2054\u001b[0m         )\n\u001b[1;32m   2056\u001b[0m     \u001b[39mwith\u001b[39;00m storage_type(storage_path) \u001b[39mas\u001b[39;00m storage:\n\u001b[0;32m-> 2057\u001b[0m         \u001b[39mreturn\u001b[39;00m CutSet\u001b[39m.\u001b[39mfrom_cuts(\n\u001b[1;32m   2058\u001b[0m             maybe_cut\n\u001b[1;32m   2059\u001b[0m             \u001b[39mfor\u001b[39;00m maybe_cut \u001b[39min\u001b[39;00m progress(\n\u001b[1;32m   2060\u001b[0m                 null_result_on_audio_loading_error(\n\u001b[1;32m   2061\u001b[0m                     cut\u001b[39m.\u001b[39mcompute_and_store_features\n\u001b[1;32m   2062\u001b[0m                 )(\n\u001b[1;32m   2063\u001b[0m                     extractor\u001b[39m=\u001b[39mextractor,\n\u001b[1;32m   2064\u001b[0m                     storage\u001b[39m=\u001b[39mstorage,\n\u001b[1;32m   2065\u001b[0m                     augment_fn\u001b[39m=\u001b[39maugment_fn,\n\u001b[1;32m   2066\u001b[0m                     mix_eagerly\u001b[39m=\u001b[39mmix_eagerly,\n\u001b[1;32m   2067\u001b[0m                 )\n\u001b[1;32m   2068\u001b[0m                 \u001b[39mfor\u001b[39;00m cut \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   2069\u001b[0m             )\n\u001b[1;32m   2070\u001b[0m             \u001b[39mif\u001b[39;00m maybe_cut \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m         )\n\u001b[1;32m   2073\u001b[0m \u001b[39m# HACK: support URL storage for writing\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m://\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(storage_path):\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# \"storage_path\" is actually an URL\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/cut/set.py:2060\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2052\u001b[0m         progress \u001b[39m=\u001b[39m partial(\n\u001b[1;32m   2053\u001b[0m             tqdm, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting and storing features\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[1;32m   2054\u001b[0m         )\n\u001b[1;32m   2056\u001b[0m     \u001b[39mwith\u001b[39;00m storage_type(storage_path) \u001b[39mas\u001b[39;00m storage:\n\u001b[1;32m   2057\u001b[0m         \u001b[39mreturn\u001b[39;00m CutSet\u001b[39m.\u001b[39mfrom_cuts(\n\u001b[1;32m   2058\u001b[0m             maybe_cut\n\u001b[1;32m   2059\u001b[0m             \u001b[39mfor\u001b[39;00m maybe_cut \u001b[39min\u001b[39;00m progress(\n\u001b[0;32m-> 2060\u001b[0m                 null_result_on_audio_loading_error(\n\u001b[1;32m   2061\u001b[0m                     cut\u001b[39m.\u001b[39;49mcompute_and_store_features\n\u001b[1;32m   2062\u001b[0m                 )(\n\u001b[1;32m   2063\u001b[0m                     extractor\u001b[39m=\u001b[39;49mextractor,\n\u001b[1;32m   2064\u001b[0m                     storage\u001b[39m=\u001b[39;49mstorage,\n\u001b[1;32m   2065\u001b[0m                     augment_fn\u001b[39m=\u001b[39;49maugment_fn,\n\u001b[1;32m   2066\u001b[0m                     mix_eagerly\u001b[39m=\u001b[39;49mmix_eagerly,\n\u001b[1;32m   2067\u001b[0m                 )\n\u001b[1;32m   2068\u001b[0m                 \u001b[39mfor\u001b[39;00m cut \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   2069\u001b[0m             )\n\u001b[1;32m   2070\u001b[0m             \u001b[39mif\u001b[39;00m maybe_cut \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m         )\n\u001b[1;32m   2073\u001b[0m \u001b[39m# HACK: support URL storage for writing\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m://\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(storage_path):\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# \"storage_path\" is actually an URL\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/audio.py:2524\u001b[0m, in \u001b[0;36mnull_result_on_audio_loading_error.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   2522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional:\n\u001b[1;32m   2523\u001b[0m     \u001b[39mwith\u001b[39;00m suppress_audio_loading_errors():\n\u001b[0;32m-> 2524\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/cut/data.py:467\u001b[0m, in \u001b[0;36mDataCut.compute_and_store_features\u001b[0;34m(self, extractor, storage, augment_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_and_store_features\u001b[39m(\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    452\u001b[0m     extractor: FeatureExtractor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    457\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataCut\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    458\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m    Compute the features from this cut, store them on disk, and attach a feature manifest to this cut.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m    This cut has to be able to load audio.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39m    :return: a new ``MonoCut`` instance with a ``Features`` manifest attached to it.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     features_info \u001b[39m=\u001b[39m extractor\u001b[39m.\u001b[39;49mextract_from_samples_and_store(\n\u001b[1;32m    468\u001b[0m         samples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_audio(),\n\u001b[1;32m    469\u001b[0m         storage\u001b[39m=\u001b[39;49mstorage,\n\u001b[1;32m    470\u001b[0m         sampling_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampling_rate,\n\u001b[1;32m    471\u001b[0m         offset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart,\n\u001b[1;32m    472\u001b[0m         channel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchannel,\n\u001b[1;32m    473\u001b[0m         augment_fn\u001b[39m=\u001b[39;49maugment_fn,\n\u001b[1;32m    474\u001b[0m     )\n\u001b[1;32m    475\u001b[0m     \u001b[39m# The fastest way to instantiate a copy of the cut with a Features object attached\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[39mreturn\u001b[39;00m fastcopy(\u001b[39mself\u001b[39m, features\u001b[39m=\u001b[39mfeatures_info)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/lhotse/features/base.py:245\u001b[0m, in \u001b[0;36mFeatureExtractor.extract_from_samples_and_store\u001b[0;34m(self, samples, storage, sampling_rate, offset, channel, augment_fn)\u001b[0m\n\u001b[1;32m    243\u001b[0m     samples \u001b[39m=\u001b[39m augment_fn(samples, sampling_rate)\n\u001b[1;32m    244\u001b[0m duration \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(samples\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m sampling_rate, ndigits\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m--> 245\u001b[0m feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract(samples\u001b[39m=\u001b[39;49msamples, sampling_rate\u001b[39m=\u001b[39;49msampling_rate)\n\u001b[1;32m    246\u001b[0m storage_key \u001b[39m=\u001b[39m store_feature_array(feats, storage\u001b[39m=\u001b[39mstorage)\n\u001b[1;32m    247\u001b[0m manifest \u001b[39m=\u001b[39m Features(\n\u001b[1;32m    248\u001b[0m     start\u001b[39m=\u001b[39moffset,\n\u001b[1;32m    249\u001b[0m     duration\u001b[39m=\u001b[39mduration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     storage_key\u001b[39m=\u001b[39mstorage_key,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/nimrod/nimrod/audio/embedding.py:87\u001b[0m, in \u001b[0;36mEncoDecExtractor.extract\u001b[0;34m(self, samples, sampling_rate)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract\u001b[39m(\u001b[39mself\u001b[39m, samples:Union[torch\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray], sampling_rate: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:    \n\u001b[0;32m---> 87\u001b[0m     codes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencodec(samples, sampling_rate)\n\u001b[1;32m     88\u001b[0m     duration \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(samples\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m sampling_rate, ndigits\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[1;32m     89\u001b[0m     expected_num_frames \u001b[39m=\u001b[39m compute_num_frames(\n\u001b[1;32m     90\u001b[0m         duration\u001b[39m=\u001b[39mduration,\n\u001b[1;32m     91\u001b[0m         frame_shift\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe_shift,\n\u001b[1;32m     92\u001b[0m         sampling_rate\u001b[39m=\u001b[39msampling_rate,\n\u001b[1;32m     93\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:489\u001b[0m, in \u001b[0;36m_BoundFunction.__call__\u001b[0;34m(self, _, *args, **kw_args)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, _, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw_args):\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_f(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:399\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw_args):\n\u001b[1;32m    398\u001b[0m     method, return_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_method_with_cache(args\u001b[39m=\u001b[39margs)\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert(method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw_args), return_type)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:40\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(obj, target_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m _promised_convert(obj, target_type)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# TODO: fix bug for n_jobs >1\n",
    "cuts = subset.compute_and_store_features(\n",
    "    extractor=encodec_extractor,\n",
    "    storage_path=\"../recipes/tts/ljspeech/data/encodec\",\n",
    "    num_jobs=1,\n",
    "    # storage_type=NumpyHdf5Writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonoCut(id='LJ001-0001-0', start=0, duration=9.65501133786848, channel=0, supervisions=[SupervisionSegment(id='LJ001-0001', recording_id='LJ001-0001', start=0.0, duration=9.65501133786848, channel=0, text='Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', language='English', speaker=None, gender='female', custom={'normalized_text': 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'}, alignment=None)], features=Features(type='encodec', num_frames=724, num_features=8, frame_shift=0.013333333333333334, sampling_rate=22050, start=0, duration=9.65501134, storage_type='lilcom_chunky', storage_path='../recipes/tts/ljspeech/data/encodec.lca', storage_key='0,8029,3610', recording_id='None', channels=0), recording=Recording(id='LJ001-0001', sources=[AudioSource(type='file', channels=[0], source='../data/en/LJSpeech-1.1/wavs/LJ001-0001.wav')], sampling_rate=22050, num_samples=212893, duration=9.65501133786848, channel_ids=[0], transforms=None), custom=None)\n"
     ]
    }
   ],
   "source": [
    "print(cuts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MonoCut(id='LJ001-0001-0', start=0, duration=9.65501133786848, channel=0, supervisions=[SupervisionSegment(id='LJ001-0001', recording_id='LJ001-0001', start=0.0, duration=9.65501133786848, channel=0, text='Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', language='English', speaker=None, gender='female', custom={'normalized_text': 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'}, alignment=None)], features=Features(type='encodec', num_frames=724, num_features=8, frame_shift=0.013333333333333334, sampling_rate=22050, start=0, duration=9.65501134, storage_type='lilcom_chunky', storage_path='../recipes/tts/ljspeech/data/encodec.lca', storage_key='0,8029,3610', recording_id='None', channels=0), recording=Recording(id='LJ001-0001', sources=[AudioSource(type='file', channels=[0], source='../data/en/LJSpeech-1.1/wavs/LJ001-0001.wav')], sampling_rate=22050, num_samples=212893, duration=9.65501133786848, channel_ids=[0], transforms=None), custom=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuts.to_file(\"../recipes/tts/ljspeech/data/first_3.encodec.jsonl.gz\")\n",
    "cuts[0]\n",
    "reload_cuts = CutSet.from_file(\"../recipes/tts/ljspeech/data/first_3.encodec.jsonl.gz\")\n",
    "reload_cuts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input File     : '../data/en/LJSpeech-1.1/wavs/LJ001-0001.wav'\n",
      "Channels       : 1\n",
      "Sample Rate    : 22050\n",
      "Precision      : 16-bit\n",
      "Duration       : 00:00:09.66 = 212893 samples ~ 724.126 CDDA sectors\n",
      "File Size      : 426k\n",
      "Bit Rate       : 353k\n",
      "Sample Encoding: 16-bit Signed Integer PCM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cuts[0].recording\n",
    "!soxi '../data/en/LJSpeech-1.1/wavs/LJ001-0001.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([725, 8]), torch.Size([725, 8]), torch.Size([725, 8])]\n",
      "[724, 142, 725]\n",
      "torch.Size([3, 725, 8]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "strategy = PrecomputedFeatures()\n",
    "feats, feats_len = strategy(cuts)\n",
    "\n",
    "# print([(f\"feat: {feat.shape}\", f\"len: {feat_len}\") for feat in feats for feat_len in feats_len])\n",
    "print([feat.shape for feat in feats])\n",
    "print([int(feat_len) for feat_len in feats_len])\n",
    "print(feats.shape, feats_len.shape)\n",
    "# TODO: debug OnTheFlyFeature case\n",
    "# strategy = OnTheFlyFeatures(extractor=encodec_extractor)\n",
    "# feats, feats_len = strategy(cuts)\n",
    "# print(feats, feats_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text normalization, tokenization and numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TTSTextNormalizer()\n",
    "tokenizer = Phonemizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cleaner(\u001b[39m\"\u001b[39;49m\u001b[39mtutu. this is ture!\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:489\u001b[0m, in \u001b[0;36m_BoundFunction.__call__\u001b[0;34m(self, _, *args, **kw_args)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, _, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw_args):\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_f(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:399\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw_args):\n\u001b[1;32m    398\u001b[0m     method, return_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_method_with_cache(args\u001b[39m=\u001b[39margs)\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert(method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw_args), return_type)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:40\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(obj, target_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m _promised_convert(obj, target_type)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "cleaner(\"tutu. this is ture!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb Cell 22\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m cut\u001b[39m.\u001b[39msupervisions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(text)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m normalized \u001b[39m=\u001b[39m cleaner(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(normalized)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/data.utils.lhotse.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m phonemes \u001b[39m=\u001b[39m tokenizer(text)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:489\u001b[0m, in \u001b[0;36m_BoundFunction.__call__\u001b[0;34m(self, _, *args, **kw_args)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, _, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw_args):\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_f(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:399\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw_args):\n\u001b[1;32m    398\u001b[0m     method, return_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_method_with_cache(args\u001b[39m=\u001b[39margs)\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert(method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw_args), return_type)\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/plum/function.py:40\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(obj, target_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m _promised_convert(obj, target_type)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "n_jobs = 1\n",
    "unique_phonemes = set()\n",
    "with CutSet.open_writer('../recipes/tts/ljspeech/data/first_3.final.jsonl.gz', overwrite=True) as writer:\n",
    "    for cut in cuts:\n",
    "        text = cut.supervisions[0].text\n",
    "        print(text)\n",
    "        normalized = cleaner(text)\n",
    "        print(normalized)\n",
    "        phonemes = tokenizer(text)\n",
    "        print(phonemes)\n",
    "        cut.custom = {'normalized': normalized, 'phonemes': phonemes}\n",
    "        writer.write(cut, flush=True)\n",
    "        unique_phonemes.update(list(phonemes))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export phoneme lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonoCut(id='LJ001-0001-0', start=0, duration=9.65501133786848, channel=0, supervisions=[SupervisionSegment(id='LJ001-0001', recording_id='LJ001-0001', start=0.0, duration=9.65501133786848, channel=0, text='Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', language='English', speaker=None, gender='female', custom=None, alignment=None)], features=Features(type='encodec', num_frames=724, num_features=8, frame_shift=0.013333333333333334, sampling_rate=22050, start=0, duration=9.65501134, storage_type='lilcom_chunky', storage_path='../data/en/LJSpeech-1.1/encodec.lca', storage_key='0,8029,3610', recording_id='None', channels=0), recording=Recording(id='LJ001-0001', sources=[AudioSource(type='file', channels=[0], source='/data/en/LJSpeech/LJSpeech-1.1/wavs/LJ001-0001.wav')], sampling_rate=22050, num_samples=212893, duration=9.65501133786848, channel_ids=[0], transforms=None), custom={'normalized': 'printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition', 'phonemes': 'pɹɪntɪŋ, ɪnðɪ oʊnli sɛns wɪð wɪtʃ wiː ɑːɹ æt pɹɛzənt kənsɜːnd, dɪfɚz fɹʌm moʊst ɪf nɑːt fɹʌm ɔːl ðɪ ɑːɹts ænd kɹæfts ɹɛpɹᵻzɛntᵻd ɪnðɪ ɛksɪbɪʃən'})\n",
      "{0: ' ', 1: ',', 2: '.', 3: 'a', 4: 'b', 5: 'd', 6: 'e', 7: 'f', 8: 'i', 9: 'k', 10: 'l', 11: 'm', 12: 'n', 13: 'o', 14: 'p', 15: 's', 16: 't', 17: 'v', 18: 'w', 19: 'z', 20: 'æ', 21: 'ð', 22: 'ŋ', 23: 'ɐ', 24: 'ɑ', 25: 'ɔ', 26: 'ə', 27: 'ɚ', 28: 'ɛ', 29: 'ɜ', 30: 'ɡ', 31: 'ɪ', 32: 'ɹ', 33: 'ɾ', 34: 'ʃ', 35: 'ʊ', 36: 'ʌ', 37: 'ː', 38: 'ᵻ', 39: '<eps>'} 40\n"
     ]
    }
   ],
   "source": [
    "cuts = CutSet.from_file(\"../data/en/LJSpeech-1.1/first_3.final.jsonl.gz\")\n",
    "print(cuts[0])\n",
    "map = {}\n",
    "unique_syms = set()\n",
    "for cut in cuts:\n",
    "    unique_syms.update(list(cut.custom['phonemes']))\n",
    "for (i, v) in enumerate(sorted(list(unique_syms))):\n",
    "    map[i] = v\n",
    "map[len(map)] = \"<eps>\"\n",
    "print(map, len(map))\n",
    "\n",
    "json_map = json.dumps(map)\n",
    "with open(\"../data/en/LJSpeech-1.1/map.json\",\"w\") as f:\n",
    "    f.write(json_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': ' ', '1': ',', '2': '.', '3': 'a', '4': 'b', '5': 'd', '6': 'e', '7': 'f', '8': 'i', '9': 'k', '10': 'l', '11': 'm', '12': 'n', '13': 'o', '14': 'p', '15': 's', '16': 't', '17': 'v', '18': 'w', '19': 'z', '20': 'æ', '21': 'ð', '22': 'ŋ', '23': 'ɐ', '24': 'ɑ', '25': 'ɔ', '26': 'ə', '27': 'ɚ', '28': 'ɛ', '29': 'ɜ', '30': 'ɡ', '31': 'ɪ', '32': 'ɹ', '33': 'ɾ', '34': 'ʃ', '35': 'ʊ', '36': 'ʌ', '37': 'ː', '38': 'ᵻ', '39': '<eps>'}\n"
     ]
    }
   ],
   "source": [
    "with open('../data/en/LJSpeech-1.1/map.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PhonemeCollater(TokenCollater):\n",
    "    def __init__(\n",
    "            self,  cuts: CutSet,\n",
    "            add_eos: bool = True,\n",
    "            add_bos: bool = True,\n",
    "            pad_symbol: str = \"<pad>\",\n",
    "            bos_symbol: str = \"<bos>\",\n",
    "            eos_symbol: str = \"<eos>\",\n",
    "            unk_symbol: str = \"<unk>\",\n",
    "        ):\n",
    "        super().__init__(\n",
    "            cuts,\n",
    "            add_eos=add_eos,\n",
    "            add_bos=add_bos,\n",
    "            pad_symbol=pad_symbol,\n",
    "            bos_symbol=bos_symbol,\n",
    "            eos_symbol=eos_symbol,\n",
    "            unk_symbol=unk_symbol\n",
    "            )\n",
    "        tokens = {char for cut in cuts for char in cut.custom['phonemes']}\n",
    "        tokens_unique = (\n",
    "            [pad_symbol, unk_symbol]\n",
    "            + ([bos_symbol] if add_bos else [])\n",
    "            + ([eos_symbol] if add_eos else [])\n",
    "            + sorted(tokens)\n",
    "        )\n",
    "\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(tokens_unique)}\n",
    "        self.idx2token = [token for token in tokens_unique]\n",
    "    \n",
    "    def __call__(self, cuts: CutSet) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        token_sequences = [\" \".join(cut.custom['phonemes']) for cut in cuts]\n",
    "        max_len = len(max(token_sequences, key=len))\n",
    "        seqs = [\n",
    "            ([self.bos_symbol] if self.add_bos else [])\n",
    "            + list(seq)\n",
    "            + ([self.eos_symbol] if self.add_eos else [])\n",
    "            + [self.pad_symbol] * (max_len - len(seq))\n",
    "            for seq in token_sequences\n",
    "        ]\n",
    "\n",
    "        tokens_batch = torch.from_numpy(\n",
    "            np.array(\n",
    "                [[self.token2idx[token] for token in seq] for seq in seqs],\n",
    "                dtype=np.int64,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        tokens_lens = torch.IntTensor(\n",
    "            [\n",
    "                len(seq) + int(self.add_eos) + int(self.add_bos)\n",
    "                for seq in token_sequences\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return tokens_batch, tokens_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MonoCut(id='LJ001-0001-0', start=0, duration=9.65501133786848, channel=0, supervisions=[SupervisionSegment(id='LJ001-0001', recording_id='LJ001-0001', start=0.0, duration=9.65501133786848, channel=0, text='Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', language='English', speaker=None, gender='female', custom=None, alignment=None)], features=Features(type='encodec', num_frames=724, num_features=8, frame_shift=0.013333333333333334, sampling_rate=22050, start=0, duration=9.65501134, storage_type='lilcom_chunky', storage_path='../data/en/LJSpeech-1.1/encodec.lca', storage_key='0,8029,3610', recording_id='None', channels=0), recording=Recording(id='LJ001-0001', sources=[AudioSource(type='file', channels=[0], source='/data/en/LJSpeech/LJSpeech-1.1/wavs/LJ001-0001.wav')], sampling_rate=22050, num_samples=212893, duration=9.65501133786848, channel_ids=[0], transforms=None), custom={'normalized': 'printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition', 'phonemes': 'pɹɪntɪŋ, ɪnðɪ oʊnli sɛns wɪð wɪtʃ wiː ɑːɹ æt pɹɛzənt kənsɜːnd, dɪfɚz fɹʌm moʊst ɪf nɑːt fɹʌm ɔːl ðɪ ɑːɹts ænd kɹæfts ɹɛpɹᵻzɛntᵻd ɪnðɪ ɛksɪbɪʃən'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 18,  4, 36,  4, 35,  4, 16,  4, 20,  4, 35,  4, 26,  4,  5,  4,  4,\n",
      "          4, 35,  4, 16,  4, 25,  4, 35,  4,  4,  4, 17,  4, 39,  4, 16,  4, 14,\n",
      "          4, 12,  4,  4,  4, 19,  4, 32,  4, 16,  4, 19,  4,  4,  4, 22,  4, 35,\n",
      "          4, 25,  4,  4,  4, 22,  4, 35,  4, 20,  4, 38,  4,  4,  4, 22,  4, 12,\n",
      "          4, 41,  4,  4,  4, 28,  4, 41,  4, 36,  4,  4,  4, 24,  4, 20,  4,  4,\n",
      "          4, 18,  4, 36,  4, 32,  4, 23,  4, 30,  4, 16,  4, 20,  4,  4,  4, 13,\n",
      "          4, 30,  4, 16,  4, 19,  4, 33,  4, 41,  4, 16,  4,  9,  4,  5,  4,  4,\n",
      "          4,  9,  4, 35,  4, 11,  4, 31,  4, 23,  4,  4,  4, 11,  4, 36,  4, 40,\n",
      "          4, 15,  4,  4,  4, 15,  4, 17,  4, 39,  4, 19,  4, 20,  4,  4,  4, 35,\n",
      "          4, 11,  4,  4,  4, 16,  4, 28,  4, 41,  4, 20,  4,  4,  4, 11,  4, 36,\n",
      "          4, 40,  4, 15,  4,  4,  4, 29,  4, 41,  4, 14,  4,  4,  4, 25,  4, 35,\n",
      "          4,  4,  4, 28,  4, 41,  4, 36,  4, 20,  4, 19,  4,  4,  4, 24,  4, 16,\n",
      "          4,  9,  4,  4,  4, 13,  4, 36,  4, 24,  4, 11,  4, 20,  4, 19,  4,  4,\n",
      "          4, 36,  4, 32,  4, 18,  4, 36,  4, 42,  4, 23,  4, 32,  4, 16,  4, 20,\n",
      "          4, 42,  4,  9,  4,  4,  4, 35,  4, 16,  4, 25,  4, 35,  4,  4,  4, 32,\n",
      "          4, 13,  4, 19,  4, 35,  4,  8,  4, 35,  4, 38,  4, 30,  4, 16,  3,  0,\n",
      "          0],\n",
      "        [ 2, 35,  4, 16,  4,  4,  4,  8,  4, 12,  4, 41,  4, 35,  4, 26,  4,  4,\n",
      "          4, 13,  4, 30,  4, 15,  4, 18,  4, 24,  4, 36,  4, 30,  4, 20,  4, 35,\n",
      "          4, 21,  4, 14,  4, 12,  4,  4,  4, 15,  4, 28,  4, 41,  4,  9,  4, 31,\n",
      "          4, 16,  4,  6,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 2, 11,  4, 29,  4, 41,  4, 36,  4,  4,  4, 29,  4, 41,  4, 14,  4, 25,\n",
      "          4, 17,  4, 39,  4,  4,  4, 25,  4, 30,  4,  4,  4, 20,  4, 38,  4,  7,\n",
      "          4, 35,  4, 16,  4, 12,  4, 41,  4, 23,  4,  4,  4, 20,  4, 39,  4, 13,\n",
      "          4,  4,  4, 35,  4, 15,  4, 18,  4, 36,  4, 32,  4, 38,  4, 30,  4, 16,\n",
      "          4, 23,  4,  4,  4, 11,  4, 36,  4, 40,  4, 15,  4,  4,  4, 22,  4, 39,\n",
      "          4,  9,  4,  4,  4,  8,  4, 14,  4, 28,  4, 41,  4, 13,  4, 19,  4,  4,\n",
      "          4, 32,  4, 26,  4, 34,  4, 36,  4, 10,  4, 35,  4, 21,  4,  9,  4,  4,\n",
      "          4, 35,  4, 16,  4,  4,  4, 36,  4, 42,  4, 14,  4, 12,  4, 41,  4, 11,\n",
      "          4,  4,  4, 11,  4, 29,  4, 41,  4, 36,  4,  4,  4, 19,  4, 32,  4, 16,\n",
      "          4, 20,  4, 38,  4, 31,  4, 36,  4, 12,  4, 23,  4,  4,  4,  8,  4, 42,\n",
      "          4, 11,  4, 17,  4, 41,  4, 36,  4,  4,  4, 25,  4, 30,  4,  4,  4, 22,\n",
      "          4, 39,  4,  9,  4, 13,  4, 40,  4, 37,  4, 31,  4, 23,  4,  4,  4, 40,\n",
      "          4, 21,  4, 25,  4, 30,  4,  4,  4, 16,  4, 32,  4, 25,  4, 33,  4, 41,\n",
      "          4, 14,  4, 30,  4, 16,  4,  9,  4, 23,  4,  5,  4,  4,  4,  8,  4,  7,\n",
      "          4, 35,  4,  4,  4, 27,  4,  4,  4, 19,  4, 35,  4, 15,  4, 35,  4, 14,\n",
      "          4, 31,  4,  4,  4, 18,  4, 36,  4, 28,  4, 41,  4, 19,  4, 32,  4, 19,\n",
      "          3]]) tensor([287,  59, 289], dtype=torch.int32)\n",
      "['p ɹ ɪ n t ɪ ŋ ,   ɪ n ð ɪ   o ʊ n l i   s ɛ n s   w ɪ ð   w ɪ t ʃ   w i ː   ɑ ː ɹ   æ t   p ɹ ɛ z ə n t   k ə n s ɜ ː n d ,   d ɪ f ɚ z   f ɹ ʌ m   m o ʊ s t   ɪ f   n ɑ ː t   f ɹ ʌ m   ɔ ː l   ð ɪ   ɑ ː ɹ t s   æ n d   k ɹ æ f t s   ɹ ɛ p ɹ ᵻ z ɛ n t ᵻ d   ɪ n ð ɪ   ɛ k s ɪ b ɪ ʃ ə n', 'ɪ n   b i ː ɪ ŋ   k ə m p æ ɹ ə t ɪ v l i   m ɑ ː d ɚ n .', 'f ɔ ː ɹ   ɔ ː l ð o ʊ   ð ə   t ʃ a ɪ n i ː z   t ʊ k   ɪ m p ɹ ɛ ʃ ə n z   f ɹ ʌ m   w ʊ d   b l ɑ ː k s   ɛ ŋ ɡ ɹ e ɪ v d   ɪ n   ɹ ᵻ l i ː f   f ɔ ː ɹ   s ɛ n t ʃ ɚ ɹ i z   b ᵻ f o ː ɹ   ð ə   w ʊ d k ʌ ɾ ɚ z   ʌ v ð ə   n ɛ ð ɜ ː l ə n d z ,   b a ɪ   ɐ   s ɪ m ɪ l ɚ   p ɹ ɑ ː s ɛ s']\n"
     ]
    }
   ],
   "source": [
    "pc = PhonemeCollater(cuts)\n",
    "tokens, tokens_len = pc(cuts)\n",
    "print(tokens, tokens_len)\n",
    "print(pc.inverse(tokens, tokens_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValleDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cuts:CutSet,\n",
    "            strategy:BatchIO=PrecomputedFeatures()\n",
    "        ):\n",
    "        self.extractor = strategy\n",
    "        self.tokenizer = PhonemeCollater(cuts)\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> Dict[str, torch.Tensor]:\n",
    "        # getitem is on full cutset not just one cut like usual for pytorch datasets\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"feats_lens\": feat_lens, \"tokens_pad\": tokens, \"tokens_lens\": token_lens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feats_pad': tensor([[[ 160.0000,  909.0000,  956.0117,  ...,  594.9853,  432.9870,\n",
      "           962.9949],\n",
      "         [ 438.0000,  876.0039,  486.0096,  ...,  602.0046,  997.9940,\n",
      "           262.0071],\n",
      "         [ 935.0078,  927.9921,  956.0148,  ...,  371.9996,  338.9874,\n",
      "           228.0006],\n",
      "         ...,\n",
      "         [ 475.0099,  856.9933,  653.0055,  ...,   95.9989,  853.0098,\n",
      "           467.0154],\n",
      "         [ 105.9963,  544.0138,  785.9864,  ...,  938.9966,  627.9919,\n",
      "           899.0155],\n",
      "         [ 474.9892,  913.0139,  981.9944,  ...,   40.9858,  771.9880,\n",
      "          1012.0151]]]), 'feats_lens': tensor([725], dtype=torch.int32), 'tokens_pad': tensor([[ 2, 11,  4, 29,  4, 41,  4, 36,  4,  4,  4, 29,  4, 41,  4, 14,  4, 25,\n",
      "          4, 17,  4, 39,  4,  4,  4, 25,  4, 30,  4,  4,  4, 20,  4, 38,  4,  7,\n",
      "          4, 35,  4, 16,  4, 12,  4, 41,  4, 23,  4,  4,  4, 20,  4, 39,  4, 13,\n",
      "          4,  4,  4, 35,  4, 15,  4, 18,  4, 36,  4, 32,  4, 38,  4, 30,  4, 16,\n",
      "          4, 23,  4,  4,  4, 11,  4, 36,  4, 40,  4, 15,  4,  4,  4, 22,  4, 39,\n",
      "          4,  9,  4,  4,  4,  8,  4, 14,  4, 28,  4, 41,  4, 13,  4, 19,  4,  4,\n",
      "          4, 32,  4, 26,  4, 34,  4, 36,  4, 10,  4, 35,  4, 21,  4,  9,  4,  4,\n",
      "          4, 35,  4, 16,  4,  4,  4, 36,  4, 42,  4, 14,  4, 12,  4, 41,  4, 11,\n",
      "          4,  4,  4, 11,  4, 29,  4, 41,  4, 36,  4,  4,  4, 19,  4, 32,  4, 16,\n",
      "          4, 20,  4, 38,  4, 31,  4, 36,  4, 12,  4, 23,  4,  4,  4,  8,  4, 42,\n",
      "          4, 11,  4, 17,  4, 41,  4, 36,  4,  4,  4, 25,  4, 30,  4,  4,  4, 22,\n",
      "          4, 39,  4,  9,  4, 13,  4, 40,  4, 37,  4, 31,  4, 23,  4,  4,  4, 40,\n",
      "          4, 21,  4, 25,  4, 30,  4,  4,  4, 16,  4, 32,  4, 25,  4, 33,  4, 41,\n",
      "          4, 14,  4, 30,  4, 16,  4,  9,  4, 23,  4,  5,  4,  4,  4,  8,  4,  7,\n",
      "          4, 35,  4,  4,  4, 27,  4,  4,  4, 19,  4, 35,  4, 15,  4, 35,  4, 14,\n",
      "          4, 31,  4,  4,  4, 18,  4, 36,  4, 28,  4, 41,  4, 19,  4, 32,  4, 19,\n",
      "          3]]), 'tokens_lens': tensor([289], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "ds = ValleDataset(cuts)\n",
    "# Dataset performs batching by itself, so we have to indicate that to the DataLoader with batch_size=None\n",
    "# train_sampler = BucketingSampler(cuts, max_duration=300, shuffle=True, bucket_method=\"equal_duration\")\n",
    "train_sampler = DynamicBucketingSampler(cuts, max_duration=300, shuffle=True, num_buckets=2)\n",
    "dl = DataLoader(ds, sampler=train_sampler, batch_size=None, num_workers=1)\n",
    "print(next(iter(dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
