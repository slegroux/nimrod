{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net\n",
    "\n",
    "> Neural net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nimrod.models.conv import ConvBlock, DeconvBlock\n",
    "from nimrod.models.resnet import ResBlock\n",
    "from nimrod.models.core import Regressor\n",
    "from nimrod.utils import get_device, set_seed\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from typing import List, Optional, Callable, Any\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "logger = logging.getLogger(__name__)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def init_weights(m, leaky=0.):\n",
    "    if isinstance(m, (nn.Conv1d,nn.Conv2d,nn.Conv3d)): nn.init.kaiming_normal_(m.weight, a=leaky)\n",
    "\n",
    "def zero_weights(layer):\n",
    "    with torch.no_grad():\n",
    "        layer.weight.zero_()\n",
    "        if hasattr(layer, 'bias') and hasattr(layer.bias, 'zero_'): layer.bias.zero_()\n",
    "\n",
    "class TinyUnet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features:List[int]=[3, 32, 64, 128, 256, 512, 1024], # Number of features in each layer\n",
    "        activation=partial(nn.LeakyReLU, negative_slope=0.1), # Activation function\n",
    "        leaky:float=0.1,# Leaky ReLU negative slope\n",
    "        normalization=nn.BatchNorm2d # Normalization function\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if len(n_features) < 3:\n",
    "            raise ValueError(\"n_features must be at least 3\")\n",
    "        # first layer\n",
    "        self.start = ResBlock(n_features[0], n_features[1], kernel_size=3, stride=1, activation=activation, normalization=normalization)\n",
    "        self.encoder = nn.ModuleList()\n",
    "        # encoder downsample receptive field\n",
    "        down = partial(ResBlock, kernel_size=3,  stride=2, activation=activation, normalization=normalization)\n",
    "        for i in range(1, len(n_features)-1):\n",
    "            self.encoder.append(down(n_features[i], n_features[i+1]))\n",
    "\n",
    "        # decoder upsampling receptive field\n",
    "        up = partial(DeconvBlock, kernel_size=3, activation=activation, normalization=normalization)\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i in range(len(n_features)-1, 1, -1):\n",
    "            self.decoder.append(up(n_features[i], n_features[i-1]))\n",
    "        self.decoder += [down(n_features[1], n_features[0], stride=1)]\n",
    "        self.end = ResBlock(n_features[0], n_features[0], kernel_size=3, stride=1, activation=nn.Identity, normalization=normalization)\n",
    "\n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        layers = [] # store the output of each layer\n",
    "        layers.append(x)\n",
    "        x = self.start(x)\n",
    "        for layer in self.encoder:\n",
    "            layers.append(x)\n",
    "            x = layer(x)\n",
    "        n = len(layers)\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            if i != 0:\n",
    "                x += layers[n-i]\n",
    "            x = layer(x)\n",
    "        return self.end(x+layers[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:33:27] WARNING - setting conv bias back to False as Batchnorm is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TinyUnet(n_features=[3, 16, 32])\n",
    "x = torch.randn(1, 3, 64, 64)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class TinyUnetX(Regressor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nnet:TinyUnet, # super res autoencoder neural net\n",
    "        optimizer: Callable[...,torch.optim.Optimizer], # optimizer partial\n",
    "        scheduler: Optional[Callable[...,Any]]=None, # scheduler partial\n",
    "    ):\n",
    "        logger.info(\"SuperResAutoencoderX: init\")\n",
    "        super().__init__(\n",
    "            nnet=nnet,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler\n",
    "            )\n",
    "        self.nnet = nnet\n",
    "        self.register_module('nnet', self.nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:42] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias back to False as Batchnorm is used\n",
      "[17:43:43] WARNING - setting conv bias back to False as Batchnorm is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = OmegaConf.load('../config/model/image/unetx.yaml')\n",
    "model = instantiate(cfg.nnet)\n",
    "x = torch.randn(1, 3, 64, 64)\n",
    "model(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
