{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to Text Datasets\n",
    "\n",
    "> Speech to text datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp audio.datasets.stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from lightning import LightningDataModule, LightningModule\n",
    "from matplotlib import pyplot as plt\n",
    "from lhotse.dataset import BucketingSampler, OnTheFlyFeatures\n",
    "from lhotse.dataset.collation import TokenCollater\n",
    "from lhotse.recipes import download_librispeech, prepare_librispeech\n",
    "from lhotse.dataset.vis import plot_batch\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, Fbank, FbankConfig\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class STTDataset(Dataset):\n",
    "    def __init__(self,\n",
    "        tokenizer:TokenCollater, # text tokenizer\n",
    "        num_mel_bins:int=80 # number of mel spectrogram bins\n",
    "        ):\n",
    "        self.extractor = OnTheFlyFeatures(Fbank(FbankConfig(num_mel_bins=num_mel_bins)))\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> dict:\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"ilens\": feat_lens, \"tokens_pad\": tokens}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LibriSpeech DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LibriSpeechDataModule(LightningDataModule):\n",
    "    def __init__(self,\n",
    "        target_dir=\"../data/en\", # where data will be saved / retrieved\n",
    "        dataset_parts=\"mini_librispeech\", # either full librispeech or mini subset\n",
    "        output_dir=\"../recipes/stt/librispeech/data\", # where to save manifest\n",
    "        num_jobs=1 # num_jobs depending on number of cpus available\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.libri = {}\n",
    "\n",
    "    def prepare_data(self,) -> None:\n",
    "        download_librispeech(target_dir=self.hparams.target_dir, dataset_parts=self.hparams.dataset_parts)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        self.libri = prepare_librispeech(Path(self.hparams.target_dir) / \"LibriSpeech\", dataset_parts=self.hparams.dataset_parts, output_dir=self.hparams.output_dir, num_jobs=self.hparams.num_jobs)\n",
    "        if stage == \"fit\" or stage == None:\n",
    "            self.cuts_train = CutSet.from_manifests(**self.libri[\"train-clean-5\"])\n",
    "            self.cuts_test = CutSet.from_manifests(**self.libri[\"dev-clean-2\"])\n",
    "            self.tokenizer = TokenCollater(self.cuts_train)\n",
    "            self.tokenizer(self.cuts_test.subset(first=2))\n",
    "            self.tokenizer.inverse(*self.tokenizer(self.cuts_test.subset(first=2)))\n",
    "        if stage == \"test\":\n",
    "            self.cuts_test = CutSet.from_manifests(**self.libri[\"dev-clean-2\"])\n",
    "            self.tokenizer = TokenCollater(self.cuts_test)\n",
    "            self.tokenizer(self.cuts_test.subset(first=2))\n",
    "            self.tokenizer.inverse(*self.tokenizer(self.cuts_test.subset(first=2)))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_sampler = BucketingSampler(self.cuts_train, max_duration=300, shuffle=True) #, bucket_method=\"equal_duration\")\n",
    "        return DataLoader(STTDataset(self.tokenizer), sampler=train_sampler, batch_size=None, num_workers=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_sampler = BucketingSampler(self.cuts_test, max_duration=400, shuffle=False) #, bucket_method=\"equal_duration\")\n",
    "        return DataLoader(STTDataset(self.tokenizer), sampler=test_sampler, batch_size=None, num_workers=2)\n",
    "\n",
    "    @property\n",
    "    def model_kwargs(self):\n",
    "        return {\n",
    "            \"odim\": len(self.tokenizer.idx2token),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LibriSpeechDataModule(\n",
    "    target_dir=\"../data/en\", \n",
    "    dataset_parts=\"mini_librispeech\",\n",
    "    output_dir=\"../data/en/LibriSpeech\",\n",
    "    num_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this at export time to not waste time\n",
    "# download\n",
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libri = prepare_librispeech(\"../data/en/LibriSpeech\", dataset_parts='mini_librispeech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ../data/en/LibriSpeech/*.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.cuts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = RecordingSet.from_file(\"../data/en/LibriSpeech/librispeech_recordings_dev-clean-2.jsonl.gz\")\n",
    "sup = SupervisionSet(\"../data/en/LibriSpeech/librispeech_supervisions_dev-clean-2.jsonl.gz\")\n",
    "print(len(recs),len(sup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dm.test_dataloader()\n",
    "b = next(iter(test_dl))\n",
    "print(b[\"feats_pad\"].shape, b[\"tokens_pad\"].shape, b[\"ilens\"].shape)\n",
    "plt.imshow(b[\"feats_pad\"][0].transpose(0,1), origin='lower')\n",
    "\n",
    "# dm.tokenizer.idx2token(b[\"tokens_pad\"][0])\n",
    "# dm.tokenizer.inverse(b[\"tokens_pad\"][0], b[\"ilens\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dm.cuts_test)\n",
    "cut = dm.cuts_test[0]\n",
    "# pprint(cut.to_dict())\n",
    "cut.plot_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
