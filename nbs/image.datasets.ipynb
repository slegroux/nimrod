{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Datasets\n",
    "\n",
    "> Image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp image.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from lightning import LightningDataModule\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from typing import Any, Dict, Optional, Tuple, List\n",
    "from nimrod.data.core import DataModule\n",
    "from nimrod.utils import set_seed\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "set_seed(42)\n",
    "logger = logging.getLogger(__name__)\n",
    "# plt.set_loglevel('INFO')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDataset base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImageDataset(Dataset):\n",
    "    \" Base class for image datasets providing visualization of (image, label) samples\"\n",
    "\n",
    "    def __init__(self):\n",
    "        logger.info(\"ImageDataset: init\")\n",
    "        super().__init__()\n",
    "\n",
    "    def show_idx(self,\n",
    "            index:int # Index of the (image,label) sample to visualize\n",
    "        ):\n",
    "        \"display image from data point index of a image dataset\"\n",
    "        X, y = self.__getitem__(index)\n",
    "        plt.figure(figsize = (1, 1))\n",
    "        plt.imshow(X.numpy().reshape(28,28),cmap='gray')\n",
    "        plt.title(f\"Label: {int(y)}\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def show_grid(\n",
    "            imgs: List[torch.Tensor], # python list of images dim (C,H,W)\n",
    "            save_path=None, # path where image can be saved\n",
    "            dims:Tuple[int,int] = (28,28)\n",
    "        ):\n",
    "        \"display list of mnist-like images (C,H,W)\"\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "        for i, img in enumerate(imgs):\n",
    "            img = img.detach()\n",
    "            axs[0, i].imshow(img.numpy().reshape(dims[0],dims[1]))\n",
    "            axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "    def show_random(\n",
    "            self,\n",
    "            n:int=3, # number of images to display\n",
    "            dims:Tuple[int,int] = (28,28)\n",
    "        ):\n",
    "        \"display grid of random images\"\n",
    "        indices = torch.randint(0,len(self), (n,))\n",
    "        images = []\n",
    "        for index in indices:\n",
    "            X, y = self.__getitem__(index)\n",
    "            X = X.reshape(dims[0],dims[1])\n",
    "            images.append(X)\n",
    "        self.show_grid(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/image/datasets.py#L47){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ImageDataset.show_idx\n",
       "\n",
       ">      ImageDataset.show_idx (index:int)\n",
       "\n",
       "*display image from data point index of a image dataset*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| index | int | Index of the (image,label) sample to visualize |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/image/datasets.py#L47){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ImageDataset.show_idx\n",
       "\n",
       ">      ImageDataset.show_idx (index:int)\n",
       "\n",
       "*display image from data point index of a image dataset*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| index | int | Index of the (image,label) sample to visualize |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ImageDataset.show_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def download_mnist_from_mirror(root='.', train=False, transform=None):\n",
    "    \"\"\"\n",
    "    Download MNIST dataset from alternative mirror and ensure it's ready\n",
    "    \n",
    "    Args:\n",
    "        root (str): Root directory for dataset\n",
    "        train (bool): Whether to download train or test dataset\n",
    "        transform (callable, optional): Optional transform to apply to dataset\n",
    "    \n",
    "    Returns:\n",
    "        MNIST dataset from alternative mirror\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import urllib.request\n",
    "    from torchvision.datasets import MNIST\n",
    "    \n",
    "    # Alternative mirror URL\n",
    "    mirror_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/'\n",
    "    \n",
    "    # Filenames\n",
    "    filenames = [\n",
    "        'train-images-idx3-ubyte.gz' if train else 't10k-images-idx3-ubyte.gz',\n",
    "        'train-labels-idx1-ubyte.gz' if train else 't10k-labels-idx1-ubyte.gz'\n",
    "    ]\n",
    "    \n",
    "    # Ensure MNIST folder structure exists\n",
    "    mnist_folder = os.path.join(root, 'MNIST')\n",
    "    raw_folder = os.path.join(mnist_folder, 'raw')\n",
    "    processed_folder = os.path.join(mnist_folder, 'processed')\n",
    "    \n",
    "    os.makedirs(raw_folder, exist_ok=True)\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "    \n",
    "    # Download files\n",
    "    for filename in filenames:\n",
    "        url = mirror_url + filename\n",
    "        local_path = os.path.join(raw_folder, filename)\n",
    "        \n",
    "        # Download file if not exists\n",
    "        if not os.path.exists(local_path):\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, local_path)\n",
    "                print(f\"Downloaded {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {filename}: {e}\")\n",
    "    \n",
    "    # Force download to process files if needed\n",
    "    try:\n",
    "        return MNIST(root, train=train, download=True, transform=transform)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create MNIST dataset: {e}\")\n",
    "        raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class MNISTDataset(ImageDataset):\n",
    "    \"MNIST digit dataset\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir:str='../data/image', # path where data is saved\n",
    "        train = True, # train or test dataset\n",
    "        transform:torchvision.transforms.transforms=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "        # TODO: add noramlization?\n",
    "        # torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(0.1307,), (0.3081,))])\n",
    "\n",
    "    ):\n",
    "        logger.info(\"MNISTDataset: init\")\n",
    "        abs_data_dir = os.path.abspath(data_dir)\n",
    "        logger.info(f\"Data directory: {abs_data_dir}\")\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        super().__init__()\n",
    "        self.ds = None\n",
    "        \n",
    "        try:\n",
    "            self.ds = download_mnist_from_mirror(\n",
    "                data_dir,\n",
    "                train = train,\n",
    "                transform=transform, \n",
    "            )\n",
    "            logger.info(f\"MNIST dataset loaded with total {len(self.ds)} samples\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load MNIST dataset: {e}\")\n",
    "\n",
    "    def __len__(self) -> int: # length of dataset\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx # index into the dataset\n",
    "                    ) -> tuple[torch.FloatTensor, int]: # Y image data, x digit number\n",
    "        x = self.ds[idx][0]\n",
    "        y = self.ds[idx][1]\n",
    "        return x, y\n",
    "    \n",
    "    def train_dev_split(\n",
    "            self,\n",
    "            ratio:float, # percentage of train/dev split,\n",
    "        ) -> tuple[torchvision.datasets.MNIST, torchvision.datasets.MNIST]: # train and set mnnist datasets\n",
    "\n",
    "        train_set_size = int(len(self.ds) * ratio)\n",
    "        valid_set_size = len(self.ds) - train_set_size\n",
    "\n",
    "        # split the train set into two\n",
    "        train_set, valid_set = data.random_split(self.ds, [train_set_size, valid_set_size])\n",
    "        # TODO: cast to ImageDataset to allow for drawing\n",
    "        # train_set, valid_set = Dataset(train_set),j Dataset(valid_set)\n",
    "        return train_set, valid_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/image/datasets.py#L131){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MNISTDataset.train_dev_split\n",
       "\n",
       ">      MNISTDataset.train_dev_split (ratio:float)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| ratio | float | percentage of train/dev split, |\n",
       "| **Returns** | **tuple** | **train and set mnnist datasets** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/slegroux/nimrod/blob/main/nimrod/image/datasets.py#L131){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MNISTDataset.train_dev_split\n",
       "\n",
       ">      MNISTDataset.train_dev_split (ratio:float)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| ratio | float | percentage of train/dev split, |\n",
       "| **Returns** | **tuple** | **train and set mnnist datasets** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MNISTDataset.train_dev_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "Setup MNIST dataset. Download data if not found in specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:36:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:36:42</span><span style=\"font-weight: bold\">]</span>                                                                     <a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2293772608.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:36:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[1;92m20:36:42\u001b[0m\u001b[1m]\u001b[0m                                                                     \u001b]8;id=48050;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py\u001b\\\u001b[2m2293772608.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=693384;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:36:42</span><span style=\"font-weight: bold\">]</span>                                                                     <a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2293772608.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py#20\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[1;92m20:36:42\u001b[0m\u001b[1m]\u001b[0m                                                                     \u001b]8;id=896865;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py\u001b\\\u001b[2m2293772608.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=244098;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py#20\u001b\\\u001b[2m20\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:36:42</span><span style=\"font-weight: bold\">]</span>                                                                      <a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2189827711.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2189827711.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2189827711.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[1;92m20:36:42\u001b[0m\u001b[1m]\u001b[0m                                                                      \u001b]8;id=475435;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2189827711.py\u001b\\\u001b[2m2189827711.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=666563;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2189827711.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:36:42</span><span style=\"font-weight: bold\">]</span>                                                                     <a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2293772608.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[1;92m20:36:42\u001b[0m\u001b[1m]\u001b[0m                                                                     \u001b]8;id=372528;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py\u001b\\\u001b[2m2293772608.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=219684;file:///var/folders/b5/v9y3kpzs29g41d99xvrdp3yr0000gn/T/ipykernel_81728/2293772608.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = MNISTDataset('../data/image', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data/image\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor() torch.float32 <class 'int'>\n",
      "Number of samples in the dataset: 10000\n",
      "torch.Size([1, 28, 28]) 7 torch.FloatTensor <class 'int'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output ( (C,H,W), int)\n",
    "print(test.ds, test.ds[0][0].dtype, type(test.ds[0][1]))\n",
    "print(f\"Number of samples in the dataset: {len(test)}\")\n",
    "\n",
    "# get item helper\n",
    "X, y = test[0]\n",
    "print(X.shape, y, X.type(), type(y))\n",
    "\n",
    "# display each digit\n",
    "test.show_idx(0)\n",
    "\n",
    "# split data\n",
    "train, dev = test.train_dev_split(0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate from config file\n",
    "It is convenient to keep setup of specific dataset for an experiment in a config file for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset from yaml config file\n",
    "cfg = OmegaConf.load(\"../config/image/data/mnist.yaml\")\n",
    "print(cfg.dataset)\n",
    "test = instantiate(cfg.dataset)\n",
    "type(test)\n",
    "\n",
    "# output ( (B,C, H,W), int)\n",
    "print(test.ds, test.ds[0][0].dtype, type(test.ds[0][1]))\n",
    "print(f\"Number of samples in the dataset: {len(test)}\")\n",
    "\n",
    "# get item helper\n",
    "X, y = test[0]\n",
    "print(X.shape, y, X.type(), type(y))\n",
    "\n",
    "# display each digit\n",
    "test.show_idx(0)\n",
    "\n",
    "# split data\n",
    "train, dev = test.train_dev_split(0.8)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MNISTDataModule(DataModule, LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 data_dir: str | os.PathLike = \"~/Data/\", # path to source data dir\n",
    "                 train_val_test_split:List[float] = [0.8, 0.1, 0.1], # train val test %\n",
    "                 batch_size: int = 64, # size of compute batch\n",
    "                 num_workers: int = 0, # num_workers equal 0 means that it’s the main process that will do the data loading when needed, num_workers equal 1 is the same as any n, but you’ll only have a single worker, so it might be slow\n",
    "                 pin_memory: bool = False, # If you load your samples in the Dataset on CPU and would like to push it during training to the GPU, you can speed up the host to device transfer by enabling pin_memory. This lets your DataLoader allocate the samples in page-locked memory, which speeds-up the transfer\n",
    "                 persistent_workers: bool = False\n",
    "                 ):\n",
    "\n",
    "        logger.info(\"Init MNIST DataModule\")\n",
    "        super().__init__(train_val_test_split, batch_size, num_workers, pin_memory, persistent_workers)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int: # num of classes in dataset\n",
    "        return 10\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"Download data if needed + format with MNISTDataset\n",
    "        \"\"\"\n",
    "        # train set\n",
    "        MNISTDataset(self.hparams.data_dir, train=True)\n",
    "        # test set\n",
    "        MNISTDataset(self.hparams.data_dir, train=False)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        # stage: {fit,validate,test,predict}\\n\",\n",
    "        # concat train & test mnist dataset and randomly generate train, eval, test sets\n",
    "        if not self.data_train or not self.data_val or not self.data_test:\n",
    "            # ((B, H, W), int)\n",
    "            trainset = MNISTDataset(self.hparams.data_dir, train=True, transform=self.transforms)\n",
    "            testset = MNISTDataset(self.hparams.data_dir, train=False, transform=self.transforms)\n",
    "            dataset = ConcatDataset(datasets=[trainset, testset])\n",
    "            # TODO: keep test set untouched\n",
    "            lengths = [int(split * len(dataset)) for split in self.hparams.train_val_test_split]\n",
    "            self.data_train, self.data_val, self.data_test = random_split(dataset=dataset, lengths=lengths)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# check for abstract methods\n",
    "pprint([(name, getattr(method,\"__isabstractmethod__\", False)) for (name, method) in DataModule.__dict__.items()])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "dm = MNISTDataModule(\n",
    "    data_dir=\"../data/image\",\n",
    "    train_val_test_split=[0.8, 0.1, 0.1],\n",
    "    batch_size = 64,\n",
    "    num_workers = 0, # main process\n",
    "    pin_memory= False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "# download or reference data from dir\n",
    "dm.prepare_data()\n",
    "\n",
    "# define train, eval, test subsets\n",
    "dm.setup()\n",
    "\n",
    "# len of splits\n",
    "print(len(dm.data_train), len(dm.data_val), len(dm.data_test))\n",
    "\n",
    "# access data batches via dataloader\n",
    "test_dl = dm.test_dataloader()\n",
    "X,Y = next(iter(test_dl))\n",
    "print(\"X dim(B,C,W,H): \", X.shape, \"Y: dim(B)\", Y.shape)\n",
    "\n",
    "# access data points directly by index\n",
    "print(len(dm.data_test[0]), print(dm.data_test[0][0].shape))\n",
    "imgs = [dm.data_test[i][0] for i in range(5)]\n",
    "\n",
    "# display image samples\n",
    "ImageDataset.show_grid(imgs)\n",
    "\n",
    "# labels are ints\n",
    "lbls = [dm.data_test[i][1] for i in range(5)]\n",
    "print(lbls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../config/image/data/mnist.yaml\")\n",
    "print(cfg.datamodule)\n",
    "dm = instantiate(cfg.datamodule)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "test_dl = dm.test_dataloader()\n",
    "len(dm.data_test[0])\n",
    "imgs = [dm.data_test[i][0] for i in range(5)]\n",
    "ImageDataset.show_grid(imgs)\n",
    "print(type(dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
