{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer LM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal implemention of transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import SGD\n",
    "# from torchtext.vocab import vocab\n",
    "\n",
    "# hf\n",
    "import datasets\n",
    "\n",
    "# data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ui\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# python\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from collections import Counter, OrderedDict\n",
    "from dataclasses import dataclass, asdict\n",
    "from plum import dispatch\n",
    "\n",
    "# nimrod\n",
    "from nimrod.models.lm import Vocab\n",
    "from nimrod.utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting\n",
    "- https://buomsoo-kim.github.io/attention/2020/04/21/Attention-mechanism-19.md/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset['train'][88])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read each line of text data into a dataframe row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:                                                 0\n",
      "0                                 First Citizen:\n",
      "1  Before we proceed any further, hear me speak.\n",
      "List:  ['First Citizen:', 'Before we proceed any further, hear me speak.']\n",
      "Vocab:  68  !$&',-.3:;<bos><eos><pad><unk>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# read unstructured text into pd\n",
    "df = pd.read_fwf('../data/text/tiny_shakespeare.txt', header=None)\n",
    "print(\"Dataframe: \", df.head(2))\n",
    "sentences = df[0].tolist()\n",
    "print(\"List: \", sentences[:2])\n",
    "v = Vocab(sentences)\n",
    "print(\"Vocab: \", len(v), ''.join(v.vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform data into one long string where each row is separated par blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', ' ', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', ' ', 'A', 'l', 'l', ':', ' ', 'S', 'p', 'e', 'a', 'k', ',', ' ', 's', 'p', 'e', 'a', 'k', '.', ' ', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', ' ', 'Y', 'o', 'u', ' ', 'a']\n"
     ]
    }
   ],
   "source": [
    "# squash list of sentences into one large list of characters\n",
    "data = []\n",
    "for line in sentences:\n",
    "    data.extend(line + ' ')\n",
    "print(data[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create validation and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ' ', 'b', 'a', 'r', 'e', '-', 'f', 'o', 'o', 't', ' ', 'o', 'n', ' ', 'h', 'e', 'r', ' ', 'w', 'e', 'd', 'd', 'i', 'n']\n"
     ]
    }
   ],
   "source": [
    "n = len(data)\n",
    "train = data[:int(n*0.9)]\n",
    "val = data[int(n*0.9):]\n",
    "print(val[:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X and Y training pairs of size \"context length\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'i', 'r'] ['i', 'r', 's']\n",
      "['F'] i\n",
      "['F', 'i'] r\n",
      "['F', 'i', 'r'] s\n"
     ]
    }
   ],
   "source": [
    "context_length = 3\n",
    "x = data[:context_length]\n",
    "y = data[1:context_length+1]\n",
    "print(x, y)\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(context, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = v.stoi(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 13, 11, 10, 6, 4, 40, 13, 6, 13]\n",
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(ids[:10])\n",
    "print(v.itos(ids[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(token_sequence, context_length, batch_size, device=device):\n",
    "    ix = torch.randint(len(token_sequence) - context_length, (batch_size,)) # max index is (L - context_length)\n",
    "    x = torch.stack([token_sequence[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([token_sequence[i+1:i+1+context_length] for i in ix])\n",
    "    return (x.to(device),y.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches X: torch.Size([8, 10]), Y: torch.Size([8, 10])\n",
      "X:  [' ', 'D', 'E', 'R', 'B', 'Y', ':', ' ', 'I', ' ']\n",
      "Y:  ['D', 'E', 'R', 'B', 'Y', ':', ' ', 'I', ' ', 'p']\n",
      "X:  ['b', 'e', ' ', 'r', 'e', 's', 't', 'r', 'a', 'i']\n",
      "Y:  ['e', ' ', 'r', 'e', 's', 't', 'r', 'a', 'i', 'n']\n",
      "X:  ['y', 'o', 'u', ' ', 'c', 'a', 'n', ',', ' ', 'p']\n",
      "Y:  ['o', 'u', ' ', 'c', 'a', 'n', ',', ' ', 'p', 'a']\n",
      "X:  [' ', 'p', 'e', 'r', 'p', 'e', 't', 'u', 'a', 'l']\n",
      "Y:  ['p', 'e', 'r', 'p', 'e', 't', 'u', 'a', 'l', ' ']\n",
      "X:  ['l', 'o', 'r', 'd', ';', ' ', 'f', 'o', 'r', ' ']\n",
      "Y:  ['o', 'r', 'd', ';', ' ', 'f', 'o', 'r', ' ', 't']\n",
      "X:  [' ', 'M', 'o', 'r', 'e', ' ', 'g', 'r', 'a', 'v']\n",
      "Y:  ['M', 'o', 'r', 'e', ' ', 'g', 'r', 'a', 'v', 'e']\n",
      "X:  ['o', 'n', ' ', 't', 'o', 'w', 'a', 'r', 'd', 's']\n",
      "Y:  ['n', ' ', 't', 'o', 'w', 'a', 'r', 'd', 's', ' ']\n",
      "X:  ['n', 't', 'l', 'e', 'n', 'e', 's', 's', ',', ' ']\n",
      "Y:  ['t', 'l', 'e', 'n', 'e', 's', 's', ',', ' ', 'K']\n"
     ]
    }
   ],
   "source": [
    "context_length = 10\n",
    "batch_size = 8\n",
    "x, y = get_random_batch(torch.LongTensor(ids), context_length, batch_size)\n",
    "print(f'Batches X: {x.shape}, Y: {y.shape}')\n",
    "for i in range(batch_size):\n",
    "    # v.itos(int(x[i]))\n",
    "    print('X: ', [v.itos(int(el)) for el in x[i]])\n",
    "    print('Y: ', [v.itos(int(el)) for el in y[i]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\" self attention head \"\"\"\n",
    "    def __init__(self, n_embd, head_size, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n",
      "torch.Size([5, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "batch_size = 5\n",
    "embed_dim = 20\n",
    "context_size = 8\n",
    "dropout = 0.2\n",
    "head_size = 16\n",
    "# embedded input (float)\n",
    "x = torch.randn(batch_size, context_size, embed_dim) #(B,T,C)\n",
    "print(x.shape)\n",
    "att = AttentionHead(embed_dim, head_size, context_size, dropout)\n",
    "xx = att(x)\n",
    "print(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(n_embd, head_size, block_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "num_heads = 3\n",
    "multi_att = MultiHeadAttention(num_heads, head_size, embed_dim, context_size, dropout)\n",
    "xxx = multi_att(x)\n",
    "print(xxx.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "ff = FeedFoward(embed_dim, dropout)\n",
    "ff_x = ff(x)\n",
    "print(ff_x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, block_size, dropout):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size, dropout)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "b = Block(embed_dim, num_heads, context_length, dropout)\n",
    "bb = b(x)\n",
    "print(bb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head, block_size, dropout) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None, device='cuda'):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = get_device()\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "vocab_size = len(v)\n",
    "m = GPTLanguageModel(vocab_size, n_embd, block_size, n_head, n_layer, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb Cell 33\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m m \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(vocab_size, (batch_size, block_size))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m logits, loss \u001b[39m=\u001b[39m m(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# print(logits.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb Cell 33\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# idx and targets are both (B,T) tensor of integers\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m tok_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_embedding_table(idx) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m pos_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_table(torch\u001b[39m.\u001b[39;49marange(T, device\u001b[39m=\u001b[39;49mdevice)) \u001b[39m# (T,C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m x \u001b[39m=\u001b[39m tok_emb \u001b[39m+\u001b[39m pos_emb \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syl20/Projects/nimrod/nbs/models.transformer.ipynb#X44sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks(x) \u001b[39m# (B,T,C)\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/nimrod/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "m = m.to(device)\n",
    "x = torch.randint(vocab_size, (batch_size, block_size)).to(device)\n",
    "logits, loss = m(x)\n",
    "# print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def estimate_loss():\n",
    "#     out = {}\n",
    "#     model.eval()\n",
    "#     for split in ['train', 'val']:\n",
    "#         losses = torch.zeros(eval_iters)\n",
    "#         for k in range(eval_iters):\n",
    "#             X, Y = get_batch(split)\n",
    "#             logits, loss = model(X, Y)\n",
    "#             losses[k] = loss.item()\n",
    "#         out[split] = losses.mean()\n",
    "#     model.train()\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1705524921417236\n",
      "2.950320243835449\n",
      "2.371941328048706\n",
      "2.4078457355499268\n",
      "2.359858512878418\n",
      "2.304844379425049\n",
      "2.3548460006713867\n",
      "2.318650007247925\n",
      "2.296562910079956\n",
      "2.2918810844421387\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "acc_loss = []\n",
    "max_iters = 1\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_random_batch(torch.LongTensor(ids), block_size, batch_size, device=device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb.to(device), yb.to(device))\n",
    "    print(loss.item())\n",
    "    acc_loss.append(loss.item())\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>imerr otho ne the miouetwhe of ooureshart APlate L\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(''.join(v.itos(m.generate(context, max_new_tokens=50)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
