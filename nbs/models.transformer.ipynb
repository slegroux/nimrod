{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer LM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat basic implemention of transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import SGD\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "# hf\n",
    "import datasets\n",
    "\n",
    "# data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ui\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# python\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from collections import Counter, OrderedDict\n",
    "from dataclasses import dataclass, asdict\n",
    "from plum import dispatch\n",
    "\n",
    "# nimrod\n",
    "from nimrod.models.lm import Vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting\n",
    "- https://buomsoo-kim.github.io/attention/2020/04/21/Attention-mechanism-19.md/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/syl20/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a038059fe3924842982835efaa2018dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' This ammunition , and that which I brought with me , was rapidly prepared for use at the Laboratory established at the Little Rock Arsenal for that purpose . As illustrating as the pitiful scarcity of material in the country , the fact may be stated that it was found necessary to use public documents of the State Library for cartridge paper . Gunsmiths were employed or conscripted , tools purchased or impressed , and the repair of the damaged guns I brought with me and about an equal number found at Little Rock commenced at once . But , after inspecting the work and observing the spirit of the men I decided that a garrison 500 strong could hold out against Fitch and that I would lead the remainder - about 1500 - to Gen \\'l Rust as soon as shotguns and rifles could be obtained from Little Rock instead of pikes and lances , with which most of them were armed . Two days elapsed before the change could be effected . \" \\n'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:                                                 0\n",
      "0                                 First Citizen:\n",
      "1  Before we proceed any further, hear me speak.\n",
      "List:  ['First Citizen:', 'Before we proceed any further, hear me speak.']\n",
      "Vocab:  68  !$&',-.3:;<bos><eos><pad><unk>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# read unstructured text into pd\n",
    "df = pd.read_fwf('../data/en/tiny_shakespeare.txt', header=None)\n",
    "print(\"Dataframe: \", df.head(2))\n",
    "sentences = df[0].tolist()\n",
    "print(\"List: \", sentences[:2])\n",
    "v = Vocab(sentences)\n",
    "print(\"Vocab: \", len(v), ''.join(v.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', ' ', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', ' ', 'A', 'l', 'l', ':', ' ', 'S', 'p', 'e', 'a', 'k', ',', ' ', 's', 'p', 'e', 'a', 'k', '.', ' ', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', ' ', 'Y', 'o', 'u', ' ', 'a']\n"
     ]
    }
   ],
   "source": [
    "# squash list of sentences into one large list of characters\n",
    "data = []\n",
    "for line in sentences:\n",
    "    data.extend(line + ' ')\n",
    "print(data[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ' ', 'b', 'a', 'r', 'e', '-', 'f', 'o', 'o', 't', ' ', 'o', 'n', ' ', 'h', 'e', 'r', ' ', 'w', 'e', 'd', 'd', 'i', 'n']\n"
     ]
    }
   ],
   "source": [
    "n = len(data)\n",
    "train = data[:int(n*0.9)]\n",
    "val = data[int(n*0.9):]\n",
    "print(val[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'i', 'r'] ['i', 'r', 's']\n",
      "['F'] i\n",
      "['F', 'i'] r\n",
      "['F', 'i', 'r'] s\n"
     ]
    }
   ],
   "source": [
    "context_length = 3\n",
    "x = data[:context_length]\n",
    "y = data[1:context_length+1]\n",
    "print(x, y)\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(context, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 13, 11, 10, 6, 4, 40, 13, 6, 13]\n"
     ]
    }
   ],
   "source": [
    "ids = v.stoi(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 13, 11, 10, 6, 4, 40, 13, 6, 13]\n",
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(ids[:10])\n",
    "print(v.itos(ids[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(token_sequence, context_length, batch_size, device='cuda'):\n",
    "    ix = torch.randint(len(token_sequence) - context_length, (batch_size,)) # max index is (L - context_length)\n",
    "    x = torch.stack([token_sequence[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([token_sequence[i+1:i+1+context_length] for i in ix])\n",
    "    return (x.to(device),y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches X: torch.Size([8, 10]), Y: torch.Size([8, 10])\n",
      "X:  ['e', 'e', 'p', 's', ' ', 'i', 'n', ' ', 'C', 'a']\n",
      "Y:  ['e', 'p', 's', ' ', 'i', 'n', ' ', 'C', 'a', 'p']\n",
      "X:  ['e', ' ', 'a', 's', ' ', 'f', 'r', 'e', 'e', 'l']\n",
      "Y:  [' ', 'a', 's', ' ', 'f', 'r', 'e', 'e', 'l', 'y']\n",
      "X:  ['e', \"'\", 's', ' ', 'n', 'o', ' ', 'v', 'i', 'r']\n",
      "Y:  [\"'\", 's', ' ', 'n', 'o', ' ', 'v', 'i', 'r', 't']\n",
      "X:  ['e', 's', 's', 'i', 'o', 'n', ' ', 'l', 'i', 'k']\n",
      "Y:  ['s', 's', 'i', 'o', 'n', ' ', 'l', 'i', 'k', 'e']\n",
      "X:  ['n', ' ', 'l', 'u', 's', 't', ' ', 't', 'h', 'a']\n",
      "Y:  [' ', 'l', 'u', 's', 't', ' ', 't', 'h', 'a', 'n']\n",
      "X:  ['f', 'u', 'l', 'l', 'y', ' ', 'A', 'b', 'o', 'u']\n",
      "Y:  ['u', 'l', 'l', 'y', ' ', 'A', 'b', 'o', 'u', 't']\n",
      "X:  ['o', 'u', 's', 'a', 'n', 'd', ' ', 'f', 'l', 'a']\n",
      "Y:  ['u', 's', 'a', 'n', 'd', ' ', 'f', 'l', 'a', 't']\n",
      "X:  ['e', 'l', 'l', 'o', 'w', ' ', 'w', 'i', 'l', 'l']\n",
      "Y:  ['l', 'l', 'o', 'w', ' ', 'w', 'i', 'l', 'l', ' ']\n"
     ]
    }
   ],
   "source": [
    "context_length = 10\n",
    "batch_size = 8\n",
    "x, y = get_random_batch(torch.LongTensor(ids), context_length, batch_size)\n",
    "print(f'Batches X: {x.shape}, Y: {y.shape}')\n",
    "for i in range(batch_size):\n",
    "    # v.itos(int(x[i]))\n",
    "    print('X: ', [v.itos(int(el)) for el in x[i]])\n",
    "    print('Y: ', [v.itos(int(el)) for el in y[i]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\" self attention head \"\"\"\n",
    "    def __init__(self, n_embd, head_size, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n",
      "torch.Size([5, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "batch_size = 5\n",
    "embed_dim = 20\n",
    "context_size = 8\n",
    "dropout = 0.2\n",
    "head_size = 16\n",
    "# embedded input (float)\n",
    "x = torch.randn(batch_size, context_size, embed_dim) #(B,T,C)\n",
    "print(x.shape)\n",
    "att = AttentionHead(embed_dim, head_size, context_size, dropout)\n",
    "xx = att(x)\n",
    "print(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(n_embd, head_size, block_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "num_heads = 3\n",
    "multi_att = MultiHeadAttention(num_heads, head_size, embed_dim, context_size, dropout)\n",
    "xxx = multi_att(x)\n",
    "print(xxx.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "ff = FeedFoward(embed_dim, dropout)\n",
    "ff_x = ff(x)\n",
    "print(ff_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, block_size, dropout):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size, dropout)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "b = Block(embed_dim, num_heads, context_length, dropout)\n",
    "bb = b(x)\n",
    "print(bb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head, block_size, dropout) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None, device='cuda'):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 1500\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "vocab_size = len(v)\n",
    "m = GPTLanguageModel(vocab_size, n_embd, block_size, n_head, n_layer, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 68])\n"
     ]
    }
   ],
   "source": [
    "m = m.to(device)\n",
    "x = torch.randint(vocab_size, (batch_size, block_size)).to(device)\n",
    "logits, loss = m(x)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def estimate_loss():\n",
    "#     out = {}\n",
    "#     model.eval()\n",
    "#     for split in ['train', 'val']:\n",
    "#         losses = torch.zeros(eval_iters)\n",
    "#         for k in range(eval_iters):\n",
    "#             X, Y = get_batch(split)\n",
    "#             logits, loss = model(X, Y)\n",
    "#             losses[k] = loss.item()\n",
    "#         out[split] = losses.mean()\n",
    "#     model.train()\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.237611770629883\n",
      "3.668224573135376\n",
      "3.5153965950012207\n",
      "3.453238010406494\n",
      "3.3735945224761963\n",
      "3.301738977432251\n",
      "3.294670581817627\n",
      "3.284370183944702\n",
      "3.2831122875213623\n",
      "3.277216911315918\n",
      "3.2383873462677\n",
      "3.2362399101257324\n",
      "3.232257843017578\n",
      "3.2340004444122314\n",
      "3.1968603134155273\n",
      "3.227483034133911\n",
      "3.2294533252716064\n",
      "3.2520651817321777\n",
      "3.2137036323547363\n",
      "3.18528151512146\n",
      "3.192403793334961\n",
      "3.1876022815704346\n",
      "3.1739635467529297\n",
      "3.154836893081665\n",
      "3.157893657684326\n",
      "3.1191647052764893\n",
      "3.0763254165649414\n",
      "3.078655958175659\n",
      "3.010364294052124\n",
      "3.015746593475342\n",
      "3.0476701259613037\n",
      "3.0183606147766113\n",
      "3.004340410232544\n",
      "2.97774600982666\n",
      "2.972032308578491\n",
      "2.9110677242279053\n",
      "2.952284097671509\n",
      "2.901395797729492\n",
      "2.89970326423645\n",
      "2.8884830474853516\n",
      "2.88486647605896\n",
      "2.8800742626190186\n",
      "2.8329224586486816\n",
      "2.8124606609344482\n",
      "2.82620906829834\n",
      "2.8399529457092285\n",
      "2.7874515056610107\n",
      "2.7931418418884277\n",
      "2.810406446456909\n",
      "2.773569345474243\n",
      "2.7823173999786377\n",
      "2.747957944869995\n",
      "2.7632975578308105\n",
      "2.7435717582702637\n",
      "2.749009847640991\n",
      "2.72147536277771\n",
      "2.7103378772735596\n",
      "2.727952241897583\n",
      "2.708634853363037\n",
      "2.712721586227417\n",
      "2.657771587371826\n",
      "2.670025587081909\n",
      "2.676088571548462\n",
      "2.670344114303589\n",
      "2.653330087661743\n",
      "2.6511542797088623\n",
      "2.6106321811676025\n",
      "2.6366987228393555\n",
      "2.615344524383545\n",
      "2.6232285499572754\n",
      "2.592043876647949\n",
      "2.6118223667144775\n",
      "2.6011343002319336\n",
      "2.6146445274353027\n",
      "2.5612242221832275\n",
      "2.5956878662109375\n",
      "2.59489369392395\n",
      "2.574826717376709\n",
      "2.6083903312683105\n",
      "2.5810086727142334\n",
      "2.5845508575439453\n",
      "2.5839407444000244\n",
      "2.593541145324707\n",
      "2.5735042095184326\n",
      "2.5748300552368164\n",
      "2.556199312210083\n",
      "2.5720293521881104\n",
      "2.571443796157837\n",
      "2.554752826690674\n",
      "2.5684287548065186\n",
      "2.5803823471069336\n",
      "2.5343563556671143\n",
      "2.549131393432617\n",
      "2.557257890701294\n",
      "2.5370495319366455\n",
      "2.549870491027832\n",
      "2.5422980785369873\n",
      "2.542269468307495\n",
      "2.534816026687622\n",
      "2.5450005531311035\n",
      "2.527108669281006\n",
      "2.5357799530029297\n",
      "2.544656753540039\n",
      "2.550973415374756\n",
      "2.5238654613494873\n",
      "2.5377941131591797\n",
      "2.5337860584259033\n",
      "2.5315985679626465\n",
      "2.53029727935791\n",
      "2.5327506065368652\n",
      "2.540785789489746\n",
      "2.5161051750183105\n",
      "2.5131139755249023\n",
      "2.526421308517456\n",
      "2.5088107585906982\n",
      "2.523425579071045\n",
      "2.532075881958008\n",
      "2.51859974861145\n",
      "2.530080556869507\n",
      "2.505828857421875\n",
      "2.5071938037872314\n",
      "2.504840850830078\n",
      "2.5026938915252686\n",
      "2.5173697471618652\n",
      "2.4906935691833496\n",
      "2.514716625213623\n",
      "2.508256435394287\n",
      "2.5292346477508545\n",
      "2.518237590789795\n",
      "2.4970176219940186\n",
      "2.4979870319366455\n",
      "2.519716262817383\n",
      "2.5204455852508545\n",
      "2.508650302886963\n",
      "2.5067691802978516\n",
      "2.4973738193511963\n",
      "2.5015058517456055\n",
      "2.510571241378784\n",
      "2.48772931098938\n",
      "2.482154607772827\n",
      "2.4967215061187744\n",
      "2.5031228065490723\n",
      "2.49641489982605\n",
      "2.505680799484253\n",
      "2.517423152923584\n",
      "2.4888651371002197\n",
      "2.4788036346435547\n",
      "2.5006866455078125\n",
      "2.5075817108154297\n",
      "2.4803433418273926\n",
      "2.5213396549224854\n",
      "2.4916603565216064\n",
      "2.5092170238494873\n",
      "2.513650417327881\n",
      "2.4983513355255127\n",
      "2.4938619136810303\n",
      "2.4680087566375732\n",
      "2.5001704692840576\n",
      "2.500981569290161\n",
      "2.493119239807129\n",
      "2.4724299907684326\n",
      "2.4862279891967773\n",
      "2.474513292312622\n",
      "2.491579055786133\n",
      "2.4861278533935547\n",
      "2.4769792556762695\n",
      "2.47739315032959\n",
      "2.485548734664917\n",
      "2.4884121417999268\n",
      "2.481083393096924\n",
      "2.4829392433166504\n",
      "2.474637269973755\n",
      "2.466085195541382\n",
      "2.4634511470794678\n",
      "2.4517977237701416\n",
      "2.4724678993225098\n",
      "2.473787546157837\n",
      "2.4827866554260254\n",
      "2.49228572845459\n",
      "2.477703332901001\n",
      "2.4615538120269775\n",
      "2.472402811050415\n",
      "2.4503157138824463\n",
      "2.472838878631592\n",
      "2.45365047454834\n",
      "2.4619479179382324\n",
      "2.4668703079223633\n",
      "2.4623374938964844\n",
      "2.450087785720825\n",
      "2.4386849403381348\n",
      "2.476008176803589\n",
      "2.4569783210754395\n",
      "2.4551589488983154\n",
      "2.4643473625183105\n",
      "2.466799259185791\n",
      "2.4732489585876465\n",
      "2.456763744354248\n",
      "2.457519769668579\n",
      "2.437918186187744\n",
      "2.4425151348114014\n",
      "2.4441683292388916\n",
      "2.4586856365203857\n",
      "2.4550886154174805\n",
      "2.469003438949585\n",
      "2.462383985519409\n",
      "2.460841178894043\n",
      "2.4501829147338867\n",
      "2.449486255645752\n",
      "2.465451717376709\n",
      "2.4476537704467773\n",
      "2.446920156478882\n",
      "2.433297872543335\n",
      "2.439516067504883\n",
      "2.4681246280670166\n",
      "2.4698033332824707\n",
      "2.450242042541504\n",
      "2.444446563720703\n",
      "2.460594892501831\n",
      "2.432729721069336\n",
      "2.437356948852539\n",
      "2.4335076808929443\n",
      "2.4373414516448975\n",
      "2.4336137771606445\n",
      "2.4503097534179688\n",
      "2.44972562789917\n",
      "2.432175397872925\n",
      "2.429809331893921\n",
      "2.4409022331237793\n",
      "2.440152168273926\n",
      "2.4206557273864746\n",
      "2.432236909866333\n",
      "2.422577381134033\n",
      "2.4394028186798096\n",
      "2.432875633239746\n",
      "2.4303276538848877\n",
      "2.4322614669799805\n",
      "2.429750442504883\n",
      "2.432891368865967\n",
      "2.412318229675293\n",
      "2.431819438934326\n",
      "2.438947916030884\n",
      "2.4422197341918945\n",
      "2.4149811267852783\n",
      "2.4235591888427734\n",
      "2.4281883239746094\n",
      "2.4314358234405518\n",
      "2.422473192214966\n",
      "2.423992872238159\n",
      "2.414466381072998\n",
      "2.426238536834717\n",
      "2.4319748878479004\n",
      "2.409558057785034\n",
      "2.4042980670928955\n",
      "2.437337636947632\n",
      "2.4045822620391846\n",
      "2.406981945037842\n",
      "2.4178245067596436\n",
      "2.415519952774048\n",
      "2.4243431091308594\n",
      "2.4085140228271484\n",
      "2.404081344604492\n",
      "2.426095724105835\n",
      "2.3997440338134766\n",
      "2.408092498779297\n",
      "2.428487539291382\n",
      "2.397831439971924\n",
      "2.4124343395233154\n",
      "2.389554977416992\n",
      "2.4072351455688477\n",
      "2.384620428085327\n",
      "2.38710355758667\n",
      "2.3952603340148926\n",
      "2.403320789337158\n",
      "2.388996124267578\n",
      "2.3923425674438477\n",
      "2.3898561000823975\n",
      "2.3726234436035156\n",
      "2.3922557830810547\n",
      "2.394134521484375\n",
      "2.374596357345581\n",
      "2.3748135566711426\n",
      "2.3785643577575684\n",
      "2.3793559074401855\n",
      "2.3694751262664795\n",
      "2.388981342315674\n",
      "2.374627113342285\n",
      "2.375711679458618\n",
      "2.376230001449585\n",
      "2.3585610389709473\n",
      "2.372584819793701\n",
      "2.384566068649292\n",
      "2.3807196617126465\n",
      "2.3652429580688477\n",
      "2.358999490737915\n",
      "2.3674302101135254\n",
      "2.3556253910064697\n",
      "2.344358205795288\n",
      "2.355469226837158\n",
      "2.3581371307373047\n",
      "2.336068868637085\n",
      "2.3569815158843994\n",
      "2.341959238052368\n",
      "2.3295044898986816\n",
      "2.357168197631836\n",
      "2.3281266689300537\n",
      "2.3211352825164795\n",
      "2.353095054626465\n",
      "2.3434529304504395\n",
      "2.3282206058502197\n",
      "2.3408823013305664\n",
      "2.3169496059417725\n",
      "2.3248932361602783\n",
      "2.3574013710021973\n",
      "2.3369674682617188\n",
      "2.3363635540008545\n",
      "2.3300626277923584\n",
      "2.3256359100341797\n",
      "2.322016716003418\n",
      "2.3226284980773926\n",
      "2.32511305809021\n",
      "2.313577651977539\n",
      "2.3200392723083496\n",
      "2.319521903991699\n",
      "2.3192503452301025\n",
      "2.304893970489502\n",
      "2.3032002449035645\n",
      "2.326732635498047\n",
      "2.313433885574341\n",
      "2.320669174194336\n",
      "2.3233978748321533\n",
      "2.3059756755828857\n",
      "2.312190532684326\n",
      "2.267479181289673\n",
      "2.292567253112793\n",
      "2.2970998287200928\n",
      "2.2994534969329834\n",
      "2.3068411350250244\n",
      "2.295017719268799\n",
      "2.3052141666412354\n",
      "2.284940481185913\n",
      "2.289902687072754\n",
      "2.2634198665618896\n",
      "2.304166316986084\n",
      "2.282097578048706\n",
      "2.274641275405884\n",
      "2.2879045009613037\n",
      "2.2817697525024414\n",
      "2.2849349975585938\n",
      "2.2589409351348877\n",
      "2.282027244567871\n",
      "2.251422643661499\n",
      "2.2695400714874268\n",
      "2.268193483352661\n",
      "2.262186288833618\n",
      "2.2519874572753906\n",
      "2.259462356567383\n",
      "2.255464553833008\n",
      "2.26086688041687\n",
      "2.273467779159546\n",
      "2.2792916297912598\n",
      "2.2530858516693115\n",
      "2.257138729095459\n",
      "2.2487707138061523\n",
      "2.2577147483825684\n",
      "2.239043712615967\n",
      "2.2340590953826904\n",
      "2.2338132858276367\n",
      "2.255059003829956\n",
      "2.243640184402466\n",
      "2.2239906787872314\n",
      "2.236067056655884\n",
      "2.2259457111358643\n",
      "2.2169182300567627\n",
      "2.23042368888855\n",
      "2.2313523292541504\n",
      "2.2242538928985596\n",
      "2.1997220516204834\n",
      "2.220341920852661\n",
      "2.204338550567627\n",
      "2.219759702682495\n",
      "2.2197537422180176\n",
      "2.205265998840332\n",
      "2.1888930797576904\n",
      "2.191584587097168\n",
      "2.202275037765503\n",
      "2.182248115539551\n",
      "2.1848864555358887\n",
      "2.176250457763672\n",
      "2.188668966293335\n",
      "2.1994309425354004\n",
      "2.182612180709839\n",
      "2.1670870780944824\n",
      "2.1679375171661377\n",
      "2.174408197402954\n",
      "2.161085605621338\n",
      "2.140303134918213\n",
      "2.152092933654785\n",
      "2.14809513092041\n",
      "2.156268358230591\n",
      "2.1771047115325928\n",
      "2.1468820571899414\n",
      "2.152829170227051\n",
      "2.119239091873169\n",
      "2.1374430656433105\n",
      "2.1545956134796143\n",
      "2.1241557598114014\n",
      "2.1191046237945557\n",
      "2.1263339519500732\n",
      "2.127082586288452\n",
      "2.1306960582733154\n",
      "2.1541154384613037\n",
      "2.121490001678467\n",
      "2.1318519115448\n",
      "2.1338491439819336\n",
      "2.1207964420318604\n",
      "2.0876858234405518\n",
      "2.1045949459075928\n",
      "2.1205103397369385\n",
      "2.1102864742279053\n",
      "2.114366054534912\n",
      "2.1058900356292725\n",
      "2.097212553024292\n",
      "2.0828239917755127\n",
      "2.102679491043091\n",
      "2.117152690887451\n",
      "2.0807807445526123\n",
      "2.0965607166290283\n",
      "2.062530517578125\n",
      "2.0867152214050293\n",
      "2.064502000808716\n",
      "2.0827975273132324\n",
      "2.0697004795074463\n",
      "2.0772671699523926\n",
      "2.070157051086426\n",
      "2.057271718978882\n",
      "2.0619218349456787\n",
      "2.06215238571167\n",
      "2.0376172065734863\n",
      "2.0540964603424072\n",
      "2.030501365661621\n",
      "2.0801501274108887\n",
      "2.051295757293701\n",
      "2.0250751972198486\n",
      "2.049323558807373\n",
      "2.0375730991363525\n",
      "2.042344331741333\n",
      "2.032209873199463\n",
      "2.045428991317749\n",
      "2.04533314704895\n",
      "2.0242180824279785\n",
      "2.0300283432006836\n",
      "2.0426816940307617\n",
      "2.013805389404297\n",
      "2.0100364685058594\n",
      "2.0221543312072754\n",
      "2.0079612731933594\n",
      "2.0207724571228027\n",
      "1.9854520559310913\n",
      "2.0080413818359375\n",
      "2.016697883605957\n",
      "2.0024173259735107\n",
      "1.9713884592056274\n",
      "2.0081305503845215\n",
      "1.9915541410446167\n",
      "1.989277720451355\n",
      "1.999292254447937\n",
      "1.9856398105621338\n",
      "1.9887845516204834\n",
      "1.9697535037994385\n",
      "1.9740469455718994\n",
      "1.9997810125350952\n",
      "1.9715063571929932\n",
      "1.9588489532470703\n",
      "1.954158902168274\n",
      "1.968106746673584\n",
      "1.958175539970398\n",
      "1.9747182130813599\n",
      "2.00199556350708\n",
      "1.9761234521865845\n",
      "1.977392315864563\n",
      "1.981090784072876\n",
      "1.9650992155075073\n",
      "1.9563148021697998\n",
      "1.9686472415924072\n",
      "1.96706223487854\n",
      "1.9868464469909668\n",
      "1.9593987464904785\n",
      "1.9727387428283691\n",
      "1.9424889087677002\n",
      "1.9465231895446777\n",
      "1.9552502632141113\n",
      "1.9391975402832031\n",
      "1.9488518238067627\n",
      "1.956162691116333\n",
      "1.9432415962219238\n",
      "1.9467600584030151\n",
      "1.9404633045196533\n",
      "1.9285571575164795\n",
      "1.9329969882965088\n",
      "1.9372516870498657\n",
      "1.9611120223999023\n",
      "1.9353082180023193\n",
      "1.9604885578155518\n",
      "1.9083430767059326\n",
      "1.932296633720398\n",
      "1.9323869943618774\n",
      "1.9228217601776123\n",
      "1.9175541400909424\n",
      "1.9319862127304077\n",
      "1.927799940109253\n",
      "1.943075180053711\n",
      "1.9134984016418457\n",
      "1.8924345970153809\n",
      "1.8996374607086182\n",
      "1.9106471538543701\n",
      "1.907042145729065\n",
      "1.912325143814087\n",
      "1.8943413496017456\n",
      "1.9173511266708374\n",
      "1.9130654335021973\n",
      "1.9195959568023682\n",
      "1.8969095945358276\n",
      "1.9010125398635864\n",
      "1.8844329118728638\n",
      "1.9033273458480835\n",
      "1.9002474546432495\n",
      "1.8966963291168213\n",
      "1.9028122425079346\n",
      "1.8955185413360596\n",
      "1.8857930898666382\n",
      "1.8945685625076294\n",
      "1.8926723003387451\n",
      "1.9052181243896484\n",
      "1.9015369415283203\n",
      "1.8699454069137573\n",
      "1.8654561042785645\n",
      "1.8728115558624268\n",
      "1.9010995626449585\n",
      "1.8407081365585327\n",
      "1.8724056482315063\n",
      "1.8872946500778198\n",
      "1.8604395389556885\n",
      "1.8729374408721924\n",
      "1.8497425317764282\n",
      "1.8676303625106812\n",
      "1.8552258014678955\n",
      "1.8763511180877686\n",
      "1.878718614578247\n",
      "1.8662570714950562\n",
      "1.8658215999603271\n",
      "1.8921763896942139\n",
      "1.8339672088623047\n",
      "1.8741555213928223\n",
      "1.8382655382156372\n",
      "1.8380210399627686\n",
      "1.8439700603485107\n",
      "1.8542476892471313\n",
      "1.850113868713379\n",
      "1.8503550291061401\n",
      "1.8585569858551025\n",
      "1.8405293226242065\n",
      "1.8681668043136597\n",
      "1.8713195323944092\n",
      "1.8784325122833252\n",
      "1.8484079837799072\n",
      "1.8590152263641357\n",
      "1.8476506471633911\n",
      "1.8134244680404663\n",
      "1.8443361520767212\n",
      "1.8553476333618164\n",
      "1.820940375328064\n",
      "1.816701054573059\n",
      "1.8306175470352173\n",
      "1.8658411502838135\n",
      "1.8445119857788086\n",
      "1.8277643918991089\n",
      "1.8307180404663086\n",
      "1.8114264011383057\n",
      "1.8293578624725342\n",
      "1.7980386018753052\n",
      "1.828889012336731\n",
      "1.8190317153930664\n",
      "1.8386967182159424\n",
      "1.8411517143249512\n",
      "1.809621810913086\n",
      "1.8146164417266846\n",
      "1.8009053468704224\n",
      "1.8079946041107178\n",
      "1.8414156436920166\n",
      "1.8288986682891846\n",
      "1.822141170501709\n",
      "1.8224186897277832\n",
      "1.8275518417358398\n",
      "1.8090142011642456\n",
      "1.8068662881851196\n",
      "1.7727376222610474\n",
      "1.7899045944213867\n",
      "1.8463139533996582\n",
      "1.791808843612671\n",
      "1.8154176473617554\n",
      "1.8251924514770508\n",
      "1.8182525634765625\n",
      "1.8138394355773926\n",
      "1.8365486860275269\n",
      "1.8292845487594604\n",
      "1.7849315404891968\n",
      "1.8025850057601929\n",
      "1.8055287599563599\n",
      "1.7873975038528442\n",
      "1.7849130630493164\n",
      "1.7959387302398682\n",
      "1.8019028902053833\n",
      "1.7603501081466675\n",
      "1.7582459449768066\n",
      "1.7934651374816895\n",
      "1.776136040687561\n",
      "1.7750264406204224\n",
      "1.7794151306152344\n",
      "1.8141210079193115\n",
      "1.7847980260849\n",
      "1.7749756574630737\n",
      "1.7610323429107666\n",
      "1.7965762615203857\n",
      "1.7977992296218872\n",
      "1.8254762887954712\n",
      "1.769750714302063\n",
      "1.7581398487091064\n",
      "1.7492114305496216\n",
      "1.7934976816177368\n",
      "1.7745401859283447\n",
      "1.7644857168197632\n",
      "1.779913306236267\n",
      "1.7794986963272095\n",
      "1.7688109874725342\n",
      "1.787401556968689\n",
      "1.7708908319473267\n",
      "1.7575443983078003\n",
      "1.7877461910247803\n",
      "1.744678020477295\n",
      "1.7649023532867432\n",
      "1.7471811771392822\n",
      "1.744338035583496\n",
      "1.76913321018219\n",
      "1.771905541419983\n",
      "1.7428884506225586\n",
      "1.7833387851715088\n",
      "1.788345217704773\n",
      "1.7545439004898071\n",
      "1.7709482908248901\n",
      "1.7478026151657104\n",
      "1.73661470413208\n",
      "1.726203441619873\n",
      "1.7591313123703003\n",
      "1.7440004348754883\n",
      "1.7349448204040527\n",
      "1.7343758344650269\n",
      "1.7503538131713867\n",
      "1.7352806329727173\n",
      "1.7655094861984253\n",
      "1.7605911493301392\n",
      "1.738580346107483\n",
      "1.7377840280532837\n",
      "1.7103819847106934\n",
      "1.761218547821045\n",
      "1.7246195077896118\n",
      "1.761171817779541\n",
      "1.7430704832077026\n",
      "1.7015348672866821\n",
      "1.7602487802505493\n",
      "1.7503817081451416\n",
      "1.743369460105896\n",
      "1.7500193119049072\n",
      "1.733449935913086\n",
      "1.7240080833435059\n",
      "1.7205541133880615\n",
      "1.7324820756912231\n",
      "1.7233755588531494\n",
      "1.7220157384872437\n",
      "1.72860848903656\n",
      "1.7337958812713623\n",
      "1.707427740097046\n",
      "1.70937979221344\n",
      "1.7158535718917847\n",
      "1.72314453125\n",
      "1.7469018697738647\n",
      "1.7191174030303955\n",
      "1.713577389717102\n",
      "1.7376099824905396\n",
      "1.7306112051010132\n",
      "1.6991803646087646\n",
      "1.7127447128295898\n",
      "1.7220557928085327\n",
      "1.740635871887207\n",
      "1.7069923877716064\n",
      "1.693280577659607\n",
      "1.7360726594924927\n",
      "1.7377158403396606\n",
      "1.7215867042541504\n",
      "1.725118637084961\n",
      "1.7344759702682495\n",
      "1.6954052448272705\n",
      "1.750836730003357\n",
      "1.7321771383285522\n",
      "1.7437840700149536\n",
      "1.6935462951660156\n",
      "1.6937390565872192\n",
      "1.7115254402160645\n",
      "1.7157368659973145\n",
      "1.724153995513916\n",
      "1.704942226409912\n",
      "1.705313801765442\n",
      "1.7322255373001099\n",
      "1.6983047723770142\n",
      "1.6902109384536743\n",
      "1.703163743019104\n",
      "1.7026292085647583\n",
      "1.705464482307434\n",
      "1.6893258094787598\n",
      "1.6890350580215454\n",
      "1.6704343557357788\n",
      "1.6992720365524292\n",
      "1.7056299448013306\n",
      "1.685464859008789\n",
      "1.708076000213623\n",
      "1.6834118366241455\n",
      "1.6860814094543457\n",
      "1.7114107608795166\n",
      "1.6902838945388794\n",
      "1.682970404624939\n",
      "1.6880251169204712\n",
      "1.6886340379714966\n",
      "1.6755942106246948\n",
      "1.6902457475662231\n",
      "1.6711411476135254\n",
      "1.686452865600586\n",
      "1.6888389587402344\n",
      "1.6727001667022705\n",
      "1.672960877418518\n",
      "1.672027826309204\n",
      "1.6628185510635376\n",
      "1.6758500337600708\n",
      "1.6884819269180298\n",
      "1.6925599575042725\n",
      "1.695796251296997\n",
      "1.7016351222991943\n",
      "1.6946390867233276\n",
      "1.689710021018982\n",
      "1.6864304542541504\n",
      "1.666512370109558\n",
      "1.7022110223770142\n",
      "1.6629540920257568\n",
      "1.652120590209961\n",
      "1.6632534265518188\n",
      "1.683276653289795\n",
      "1.6532577276229858\n",
      "1.6724212169647217\n",
      "1.7002053260803223\n",
      "1.6702097654342651\n",
      "1.6665093898773193\n",
      "1.6823629140853882\n",
      "1.689160704612732\n",
      "1.6571873426437378\n",
      "1.6806532144546509\n",
      "1.6421723365783691\n",
      "1.6591041088104248\n",
      "1.6722081899642944\n",
      "1.663377285003662\n",
      "1.655313491821289\n",
      "1.6482311487197876\n",
      "1.642632007598877\n",
      "1.677566647529602\n",
      "1.6766785383224487\n",
      "1.6614186763763428\n",
      "1.6411164999008179\n",
      "1.6698909997940063\n",
      "1.638339638710022\n",
      "1.6572378873825073\n",
      "1.644177794456482\n",
      "1.6582361459732056\n",
      "1.6484304666519165\n",
      "1.6327883005142212\n",
      "1.6529515981674194\n",
      "1.6349014043807983\n",
      "1.6612327098846436\n",
      "1.6321797370910645\n",
      "1.625281810760498\n",
      "1.642306923866272\n",
      "1.6273332834243774\n",
      "1.6321378946304321\n",
      "1.6291093826293945\n",
      "1.6630432605743408\n",
      "1.6399227380752563\n",
      "1.66703200340271\n",
      "1.6226314306259155\n",
      "1.667101502418518\n",
      "1.6521631479263306\n",
      "1.6563574075698853\n",
      "1.656368613243103\n",
      "1.646369457244873\n",
      "1.6407660245895386\n",
      "1.6429896354675293\n",
      "1.656864881515503\n",
      "1.6312566995620728\n",
      "1.6708838939666748\n",
      "1.636813998222351\n",
      "1.6336575746536255\n",
      "1.6444923877716064\n",
      "1.6317344903945923\n",
      "1.6412492990493774\n",
      "1.6418100595474243\n",
      "1.6454271078109741\n",
      "1.603646993637085\n",
      "1.6257505416870117\n",
      "1.6259788274765015\n",
      "1.6016557216644287\n",
      "1.6105347871780396\n",
      "1.6284383535385132\n",
      "1.6434895992279053\n",
      "1.6235220432281494\n",
      "1.6367101669311523\n",
      "1.6084178686141968\n",
      "1.6172351837158203\n",
      "1.6444616317749023\n",
      "1.6098531484603882\n",
      "1.6291265487670898\n",
      "1.6356000900268555\n",
      "1.6195597648620605\n",
      "1.6203211545944214\n",
      "1.6194664239883423\n",
      "1.619584560394287\n",
      "1.6446253061294556\n",
      "1.6187363862991333\n",
      "1.5903379917144775\n",
      "1.615378737449646\n",
      "1.6556305885314941\n",
      "1.6356232166290283\n",
      "1.620100736618042\n",
      "1.6225459575653076\n",
      "1.6282544136047363\n",
      "1.5909446477890015\n",
      "1.6075358390808105\n",
      "1.6435980796813965\n",
      "1.6022942066192627\n",
      "1.6291838884353638\n",
      "1.6030821800231934\n",
      "1.6291290521621704\n",
      "1.5903946161270142\n",
      "1.6242834329605103\n",
      "1.5975701808929443\n",
      "1.6011518239974976\n",
      "1.6314525604248047\n",
      "1.60097074508667\n",
      "1.616750717163086\n",
      "1.6104148626327515\n",
      "1.6357742547988892\n",
      "1.5966823101043701\n",
      "1.5965749025344849\n",
      "1.5918433666229248\n",
      "1.62884521484375\n",
      "1.6099967956542969\n",
      "1.605026125907898\n",
      "1.5848356485366821\n",
      "1.6243995428085327\n",
      "1.5831875801086426\n",
      "1.595189094543457\n",
      "1.6391124725341797\n",
      "1.5799143314361572\n",
      "1.5926183462142944\n",
      "1.583918571472168\n",
      "1.5943567752838135\n",
      "1.5914146900177002\n",
      "1.573745608329773\n",
      "1.589125633239746\n",
      "1.5686253309249878\n",
      "1.5771701335906982\n",
      "1.6003923416137695\n",
      "1.5984913110733032\n",
      "1.6140122413635254\n",
      "1.5551148653030396\n",
      "1.596973180770874\n",
      "1.5957224369049072\n",
      "1.5654863119125366\n",
      "1.5765674114227295\n",
      "1.6004506349563599\n",
      "1.6089199781417847\n",
      "1.5922737121582031\n",
      "1.5645191669464111\n",
      "1.5872052907943726\n",
      "1.6055011749267578\n",
      "1.5997509956359863\n",
      "1.5760396718978882\n",
      "1.619322657585144\n",
      "1.59628164768219\n",
      "1.5752151012420654\n",
      "1.5492733716964722\n",
      "1.5909020900726318\n",
      "1.5768256187438965\n",
      "1.5792769193649292\n",
      "1.5722874402999878\n",
      "1.582060694694519\n",
      "1.6021314859390259\n",
      "1.6036086082458496\n",
      "1.5555416345596313\n",
      "1.5992144346237183\n",
      "1.5919780731201172\n",
      "1.578892707824707\n",
      "1.5876718759536743\n",
      "1.5542851686477661\n",
      "1.5625574588775635\n",
      "1.5833494663238525\n",
      "1.5764503479003906\n",
      "1.5544579029083252\n",
      "1.5799665451049805\n",
      "1.59656822681427\n",
      "1.5719690322875977\n",
      "1.5829248428344727\n",
      "1.5718921422958374\n",
      "1.5823791027069092\n",
      "1.589428186416626\n",
      "1.5833910703659058\n",
      "1.5702881813049316\n",
      "1.5495967864990234\n",
      "1.5718226432800293\n",
      "1.5843292474746704\n",
      "1.5890415906906128\n",
      "1.5932713747024536\n",
      "1.5828006267547607\n",
      "1.5394716262817383\n",
      "1.5689295530319214\n",
      "1.5655802488327026\n",
      "1.550886631011963\n",
      "1.5528119802474976\n",
      "1.5808149576187134\n",
      "1.5604959726333618\n",
      "1.5583276748657227\n",
      "1.5572553873062134\n",
      "1.5632128715515137\n",
      "1.5525749921798706\n",
      "1.564041256904602\n",
      "1.5509254932403564\n",
      "1.5517927408218384\n",
      "1.5116596221923828\n",
      "1.5780613422393799\n",
      "1.575051188468933\n",
      "1.5573325157165527\n",
      "1.559656023979187\n",
      "1.5364556312561035\n",
      "1.5846960544586182\n",
      "1.5622869729995728\n",
      "1.5685704946517944\n",
      "1.5476276874542236\n",
      "1.5613380670547485\n",
      "1.5481973886489868\n",
      "1.5842657089233398\n",
      "1.5284934043884277\n",
      "1.5384283065795898\n",
      "1.5435560941696167\n",
      "1.5222358703613281\n",
      "1.5916407108306885\n",
      "1.5637160539627075\n",
      "1.5256056785583496\n",
      "1.5392754077911377\n",
      "1.5292768478393555\n",
      "1.5465102195739746\n",
      "1.5505763292312622\n",
      "1.5710422992706299\n",
      "1.544367790222168\n",
      "1.5508053302764893\n",
      "1.5554172992706299\n",
      "1.5129412412643433\n",
      "1.5673130750656128\n",
      "1.5533498525619507\n",
      "1.5445969104766846\n",
      "1.5546404123306274\n",
      "1.551551103591919\n",
      "1.5562424659729004\n",
      "1.5188019275665283\n",
      "1.5643168687820435\n",
      "1.5515531301498413\n",
      "1.5391331911087036\n",
      "1.567751407623291\n",
      "1.5605672597885132\n",
      "1.5406877994537354\n",
      "1.5574067831039429\n",
      "1.578627586364746\n",
      "1.5757389068603516\n",
      "1.5696901082992554\n",
      "1.5486383438110352\n",
      "1.5354708433151245\n",
      "1.5205928087234497\n",
      "1.5564919710159302\n",
      "1.5250754356384277\n",
      "1.534836769104004\n",
      "1.5643813610076904\n",
      "1.529829502105713\n",
      "1.5585569143295288\n",
      "1.5556055307388306\n",
      "1.5277479887008667\n",
      "1.5127366781234741\n",
      "1.5725847482681274\n",
      "1.543241262435913\n",
      "1.530943512916565\n",
      "1.509772539138794\n",
      "1.5199400186538696\n",
      "1.5457837581634521\n",
      "1.523078203201294\n",
      "1.5132807493209839\n",
      "1.528496265411377\n",
      "1.552133560180664\n",
      "1.5690306425094604\n",
      "1.5315635204315186\n",
      "1.5321292877197266\n",
      "1.5167813301086426\n",
      "1.5393693447113037\n",
      "1.5088551044464111\n",
      "1.5535132884979248\n",
      "1.570457100868225\n",
      "1.5332512855529785\n",
      "1.5147947072982788\n",
      "1.5730284452438354\n",
      "1.5488691329956055\n",
      "1.5224133729934692\n",
      "1.5386862754821777\n",
      "1.51304292678833\n",
      "1.4968650341033936\n",
      "1.5066993236541748\n",
      "1.5137584209442139\n",
      "1.517533540725708\n",
      "1.5133123397827148\n",
      "1.5618616342544556\n",
      "1.5169843435287476\n",
      "1.5231685638427734\n",
      "1.5406132936477661\n",
      "1.5295159816741943\n",
      "1.545262336730957\n",
      "1.5284528732299805\n",
      "1.5142062902450562\n",
      "1.5311700105667114\n",
      "1.5232019424438477\n",
      "1.521271824836731\n",
      "1.5349668264389038\n",
      "1.522747278213501\n",
      "1.5045753717422485\n",
      "1.5150641202926636\n",
      "1.5107342004776\n",
      "1.5361027717590332\n",
      "1.5169174671173096\n",
      "1.5174362659454346\n",
      "1.5431022644042969\n",
      "1.5595836639404297\n",
      "1.5273504257202148\n",
      "1.5123134851455688\n",
      "1.5115095376968384\n",
      "1.5539919137954712\n",
      "1.5074703693389893\n",
      "1.4906973838806152\n",
      "1.5174659490585327\n",
      "1.507218599319458\n",
      "1.5320804119110107\n",
      "1.5297858715057373\n",
      "1.5051109790802002\n",
      "1.507272481918335\n",
      "1.5430326461791992\n",
      "1.5186249017715454\n",
      "1.5250024795532227\n",
      "1.4970029592514038\n",
      "1.5134719610214233\n",
      "1.516276240348816\n",
      "1.5356965065002441\n",
      "1.5004633665084839\n",
      "1.5269520282745361\n",
      "1.5194514989852905\n",
      "1.5198559761047363\n",
      "1.497151255607605\n",
      "1.4959750175476074\n",
      "1.5205129384994507\n",
      "1.4938645362854004\n",
      "1.5335516929626465\n",
      "1.480735182762146\n",
      "1.5379612445831299\n",
      "1.4937868118286133\n",
      "1.512526512145996\n",
      "1.522072672843933\n",
      "1.5147513151168823\n",
      "1.4927438497543335\n",
      "1.5262699127197266\n",
      "1.5260226726531982\n",
      "1.5091407299041748\n",
      "1.50767183303833\n",
      "1.4909400939941406\n",
      "1.5298113822937012\n",
      "1.5172501802444458\n",
      "1.4895236492156982\n",
      "1.4675445556640625\n",
      "1.5118898153305054\n",
      "1.502258062362671\n",
      "1.4918681383132935\n",
      "1.5099247694015503\n",
      "1.4833807945251465\n",
      "1.4841586351394653\n",
      "1.5023140907287598\n",
      "1.4916967153549194\n",
      "1.5274704694747925\n",
      "1.4659850597381592\n",
      "1.4879529476165771\n",
      "1.493740439414978\n",
      "1.5032023191452026\n",
      "1.4863426685333252\n",
      "1.4923155307769775\n",
      "1.4424830675125122\n",
      "1.506213665008545\n",
      "1.4881097078323364\n",
      "1.51073157787323\n",
      "1.4801052808761597\n",
      "1.488942265510559\n",
      "1.453436017036438\n",
      "1.5136878490447998\n",
      "1.511358380317688\n",
      "1.4971493482589722\n",
      "1.5047829151153564\n",
      "1.4826635122299194\n",
      "1.4787604808807373\n",
      "1.4868780374526978\n",
      "1.509904384613037\n",
      "1.487711787223816\n",
      "1.4977595806121826\n",
      "1.477266788482666\n",
      "1.4777060747146606\n",
      "1.5256599187850952\n",
      "1.4645479917526245\n",
      "1.475233793258667\n",
      "1.4673446416854858\n",
      "1.4935024976730347\n",
      "1.4691342115402222\n",
      "1.4692833423614502\n",
      "1.499106526374817\n",
      "1.470899224281311\n",
      "1.47881281375885\n",
      "1.4887522459030151\n",
      "1.519195318222046\n",
      "1.473394751548767\n",
      "1.4674732685089111\n",
      "1.4964160919189453\n",
      "1.487027645111084\n",
      "1.4759740829467773\n",
      "1.5046513080596924\n",
      "1.4907373189926147\n",
      "1.498530387878418\n",
      "1.4416593313217163\n",
      "1.4759706258773804\n",
      "1.449526071548462\n",
      "1.4820952415466309\n",
      "1.4997174739837646\n",
      "1.484573483467102\n",
      "1.489986777305603\n",
      "1.485128402709961\n",
      "1.4760931730270386\n",
      "1.5156818628311157\n",
      "1.456456184387207\n",
      "1.4832234382629395\n",
      "1.4826830625534058\n",
      "1.480488657951355\n",
      "1.5047398805618286\n",
      "1.4881746768951416\n",
      "1.4705162048339844\n",
      "1.4864413738250732\n",
      "1.4570937156677246\n",
      "1.5010727643966675\n",
      "1.4430590867996216\n",
      "1.4650115966796875\n",
      "1.485539436340332\n",
      "1.4657083749771118\n",
      "1.478752851486206\n",
      "1.4862209558486938\n",
      "1.48902428150177\n",
      "1.473686695098877\n",
      "1.4886364936828613\n",
      "1.4553340673446655\n",
      "1.460054874420166\n",
      "1.437849760055542\n",
      "1.479331612586975\n",
      "1.4905041456222534\n",
      "1.4508620500564575\n",
      "1.495826005935669\n",
      "1.4699020385742188\n",
      "1.494356393814087\n",
      "1.5025099515914917\n",
      "1.4579439163208008\n",
      "1.4508721828460693\n",
      "1.4751096963882446\n",
      "1.4889090061187744\n",
      "1.4673131704330444\n",
      "1.4975241422653198\n",
      "1.4946414232254028\n",
      "1.480339527130127\n",
      "1.4712773561477661\n",
      "1.474057674407959\n",
      "1.465356707572937\n",
      "1.490147590637207\n",
      "1.4718589782714844\n",
      "1.488579511642456\n",
      "1.4690333604812622\n",
      "1.4942489862442017\n",
      "1.4609320163726807\n",
      "1.4699386358261108\n",
      "1.477202296257019\n",
      "1.4957243204116821\n",
      "1.468218445777893\n",
      "1.4732909202575684\n",
      "1.4718323945999146\n",
      "1.4612207412719727\n",
      "1.4615199565887451\n",
      "1.4797786474227905\n",
      "1.4495205879211426\n",
      "1.486041784286499\n",
      "1.4894753694534302\n",
      "1.47454833984375\n",
      "1.458306074142456\n",
      "1.460465669631958\n",
      "1.4506784677505493\n",
      "1.468207597732544\n",
      "1.4704598188400269\n",
      "1.49012291431427\n",
      "1.4622002840042114\n",
      "1.4635616540908813\n",
      "1.473955750465393\n",
      "1.4452407360076904\n",
      "1.4659953117370605\n",
      "1.4631327390670776\n",
      "1.4513170719146729\n",
      "1.4501214027404785\n",
      "1.4563624858856201\n",
      "1.472809076309204\n",
      "1.4784760475158691\n",
      "1.4485678672790527\n",
      "1.453516960144043\n",
      "1.4362609386444092\n",
      "1.4435285329818726\n",
      "1.4298784732818604\n",
      "1.4490445852279663\n",
      "1.4753206968307495\n",
      "1.4368818998336792\n",
      "1.442601203918457\n",
      "1.4454922676086426\n",
      "1.4456971883773804\n",
      "1.460544228553772\n",
      "1.4720555543899536\n",
      "1.4604007005691528\n",
      "1.421811819076538\n",
      "1.4488797187805176\n",
      "1.4499589204788208\n",
      "1.4506888389587402\n",
      "1.461927056312561\n",
      "1.452351689338684\n",
      "1.457726240158081\n",
      "1.4461437463760376\n",
      "1.4579651355743408\n",
      "1.4604604244232178\n",
      "1.4488849639892578\n",
      "1.4572563171386719\n",
      "1.4418044090270996\n",
      "1.4626986980438232\n",
      "1.4696720838546753\n",
      "1.456803560256958\n",
      "1.449994444847107\n",
      "1.4128776788711548\n",
      "1.4384979009628296\n",
      "1.470974087715149\n",
      "1.428322434425354\n",
      "1.4479888677597046\n",
      "1.4137170314788818\n",
      "1.424380898475647\n",
      "1.4380104541778564\n",
      "1.4312853813171387\n",
      "1.4606151580810547\n",
      "1.4198936223983765\n",
      "1.4634864330291748\n",
      "1.4561257362365723\n",
      "1.4285224676132202\n",
      "1.4485100507736206\n",
      "1.4514585733413696\n",
      "1.4804365634918213\n",
      "1.4681743383407593\n",
      "1.437371015548706\n",
      "1.4635087251663208\n",
      "1.4445946216583252\n",
      "1.4447418451309204\n",
      "1.4623732566833496\n",
      "1.424210786819458\n",
      "1.4586271047592163\n",
      "1.4353610277175903\n",
      "1.4449719190597534\n",
      "1.4474523067474365\n",
      "1.4319343566894531\n",
      "1.428220510482788\n",
      "1.4529187679290771\n",
      "1.4833163022994995\n",
      "1.4602031707763672\n",
      "1.4231224060058594\n",
      "1.4009352922439575\n",
      "1.4500150680541992\n",
      "1.4532967805862427\n",
      "1.4065505266189575\n",
      "1.4523935317993164\n",
      "1.4430392980575562\n",
      "1.4355700016021729\n",
      "1.4251365661621094\n",
      "1.4583263397216797\n",
      "1.4313266277313232\n",
      "1.4054250717163086\n",
      "1.4344408512115479\n",
      "1.4427893161773682\n",
      "1.4163146018981934\n",
      "1.4630018472671509\n",
      "1.4332116842269897\n",
      "1.4317721128463745\n",
      "1.450616478919983\n",
      "1.4432175159454346\n",
      "1.4469386339187622\n",
      "1.4542467594146729\n",
      "1.4526287317276\n",
      "1.4400275945663452\n",
      "1.423122525215149\n",
      "1.4321706295013428\n",
      "1.4231069087982178\n",
      "1.452531337738037\n",
      "1.4562567472457886\n",
      "1.423092007637024\n",
      "1.423975944519043\n",
      "1.4304808378219604\n",
      "1.4480797052383423\n",
      "1.4235323667526245\n",
      "1.4590179920196533\n",
      "1.409253716468811\n",
      "1.446639895439148\n",
      "1.447119116783142\n",
      "1.4028221368789673\n",
      "1.4412813186645508\n",
      "1.4194056987762451\n",
      "1.4105349779129028\n",
      "1.4420239925384521\n",
      "1.4304890632629395\n",
      "1.4173277616500854\n",
      "1.4310613870620728\n",
      "1.4368674755096436\n",
      "1.42423677444458\n",
      "1.439359426498413\n",
      "1.4165773391723633\n",
      "1.4474074840545654\n",
      "1.403998851776123\n",
      "1.439146876335144\n",
      "1.4671810865402222\n",
      "1.486107349395752\n",
      "1.4582687616348267\n",
      "1.3961291313171387\n",
      "1.4394046068191528\n",
      "1.4530339241027832\n",
      "1.4096267223358154\n",
      "1.4269887208938599\n",
      "1.4442570209503174\n",
      "1.4484307765960693\n",
      "1.4584476947784424\n",
      "1.4246368408203125\n",
      "1.420856237411499\n",
      "1.4277818202972412\n",
      "1.4600114822387695\n",
      "1.4204258918762207\n",
      "1.4387476444244385\n",
      "1.4364306926727295\n",
      "1.4171267747879028\n",
      "1.4314044713974\n",
      "1.430797815322876\n",
      "1.4181255102157593\n",
      "1.4009554386138916\n",
      "1.4419214725494385\n",
      "1.4152199029922485\n",
      "1.4037153720855713\n",
      "1.4200446605682373\n",
      "1.4093775749206543\n",
      "1.4050920009613037\n",
      "1.4237332344055176\n",
      "1.3963284492492676\n",
      "1.4348750114440918\n",
      "1.4653254747390747\n",
      "1.4067840576171875\n",
      "1.430193543434143\n",
      "1.4012529850006104\n",
      "1.4162718057632446\n",
      "1.4053000211715698\n",
      "1.4044848680496216\n",
      "1.4062734842300415\n",
      "1.4328256845474243\n",
      "1.3931187391281128\n",
      "1.4268519878387451\n",
      "1.4195945262908936\n",
      "1.4190152883529663\n",
      "1.4542195796966553\n",
      "1.4497251510620117\n",
      "1.4160436391830444\n",
      "1.4423418045043945\n",
      "1.3962008953094482\n",
      "1.397275686264038\n",
      "1.4146240949630737\n",
      "1.4182188510894775\n",
      "1.4124157428741455\n",
      "1.4047397375106812\n",
      "1.4150303602218628\n",
      "1.4119986295700073\n",
      "1.4289450645446777\n",
      "1.386380910873413\n",
      "1.397492527961731\n",
      "1.3896645307540894\n",
      "1.432678461074829\n",
      "1.423550009727478\n",
      "1.4194401502609253\n",
      "1.412132978439331\n",
      "1.4177368879318237\n",
      "1.4040164947509766\n",
      "1.4369006156921387\n",
      "1.4034000635147095\n",
      "1.4002721309661865\n",
      "1.4224809408187866\n",
      "1.3936856985092163\n",
      "1.3841300010681152\n",
      "1.4094539880752563\n",
      "1.4309641122817993\n",
      "1.4157145023345947\n",
      "1.3941209316253662\n",
      "1.3834208250045776\n",
      "1.4262930154800415\n",
      "1.413318395614624\n",
      "1.398178219795227\n",
      "1.3973907232284546\n",
      "1.4286164045333862\n",
      "1.4178622961044312\n",
      "1.4003950357437134\n",
      "1.3764020204544067\n",
      "1.4134618043899536\n",
      "1.4170082807540894\n",
      "1.376449704170227\n",
      "1.4222813844680786\n",
      "1.3902976512908936\n",
      "1.4212572574615479\n",
      "1.4088964462280273\n",
      "1.4074938297271729\n",
      "1.3785830736160278\n",
      "1.4312753677368164\n",
      "1.3877902030944824\n",
      "1.4152179956436157\n",
      "1.413947343826294\n",
      "1.414840579032898\n",
      "1.3852458000183105\n",
      "1.4253849983215332\n",
      "1.4091300964355469\n",
      "1.4225536584854126\n",
      "1.412453532218933\n",
      "1.4234116077423096\n",
      "1.3865108489990234\n",
      "1.3837947845458984\n",
      "1.390491247177124\n",
      "1.3985302448272705\n",
      "1.4035648107528687\n",
      "1.410038948059082\n",
      "1.4154125452041626\n",
      "1.393479585647583\n",
      "1.4276293516159058\n",
      "1.3798779249191284\n",
      "1.389825463294983\n",
      "1.4046614170074463\n",
      "1.418703556060791\n",
      "1.4201749563217163\n",
      "1.4004968404769897\n",
      "1.4285786151885986\n",
      "1.388317346572876\n",
      "1.4213597774505615\n",
      "1.379804253578186\n",
      "1.3918129205703735\n",
      "1.4297856092453003\n",
      "1.408982515335083\n",
      "1.413875937461853\n",
      "1.4064147472381592\n",
      "1.4126648902893066\n",
      "1.3675285577774048\n",
      "1.3688745498657227\n",
      "1.4288500547409058\n",
      "1.4005012512207031\n",
      "1.3969600200653076\n",
      "1.4088528156280518\n",
      "1.3997900485992432\n",
      "1.404333233833313\n",
      "1.4181349277496338\n",
      "1.3969690799713135\n",
      "1.3714910745620728\n",
      "1.406038761138916\n",
      "1.3882672786712646\n",
      "1.3751155138015747\n",
      "1.373070240020752\n",
      "1.4149863719940186\n",
      "1.3877071142196655\n",
      "1.4050644636154175\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "acc_loss = []\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_random_batch(torch.LongTensor(ids), block_size, batch_size, device=device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb.to(device), yb.to(device))\n",
    "    print(loss.item())\n",
    "    acc_loss.append(loss.item())\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe39c59c3d0>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>pester obyal to the wars leave. Met make prison women with teet, cendempth, To save it us, Hazarding to Loved of Norfolk, banishman: Who pity, post to Warms, And by raise? He thou saw not luttens thy spoke country. GLOUCESTER: Lord, I do rush thou an thought 'Land not Adie To allso, say, how now it thee sights; And better, true none; for neither Mantuua. I them must say, I have medicery hath we these heeld to make an it. Uncle, prospais writ, madam; whay the father said, must auffirant ye: he is\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(''.join(v.itos(m.generate(context, max_new_tokens=500)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
