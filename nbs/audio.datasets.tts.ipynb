{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio TTS Datasets\n",
    "\n",
    "> TTS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp audio.datasets.tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, Fbank, FbankConfig\n",
    "from lhotse.dataset import BucketingSampler, OnTheFlyFeatures\n",
    "from lhotse.dataset.collation import TokenCollater\n",
    "from lhotse.dataset.vis import plot_batch\n",
    "from lhotse.recipes import download_librispeech, prepare_librispeech\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Optional, Union"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LibriTTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lhotse-based Base Class\n",
    "https://github.com/Lightning-AI/lightning/issues/10358\n",
    "https://colab.research.google.com/drive/1HKSYPsWx_HoCdrnLpaPdYj5zwlPsM3NH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LhotseTTSDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                tokenizer=TokenCollater, # text tokenizer\n",
    "                extractor=OnTheFlyFeatures(Fbank(FbankConfig(num_mel_bins=80))) # feature extractor\n",
    "                ):\n",
    "        self.extractor = extractor\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> dict:\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"feats_lens\": feat_lens, \"tokens_pad\": tokens, \"tokens_lens\": token_lens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok = TokenCollater()\n",
    "# ds = LhotseTTSDataset(tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTS Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class TTSDataset(Dataset):\n",
    "    def __init__(self,\n",
    "        tokenizer, # text tokenizer\n",
    "        num_mel_bins:int=80,  # number of mel spectrogram bins\n",
    "        sampling_rate:int=16000 # sampling rate\n",
    "        ):\n",
    "        self.extractor = OnTheFlyFeatures(Fbank(FbankConfig(num_mel_bins=num_mel_bins, sampling_rate=sampling_rate)))\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> dict:\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"feats_lens\": feat_lens, \"tokens_pad\": tokens, \"tokens_lens\": token_lens}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibriTTS DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from lhotse.recipes import download_libritts, prepare_libritts\n",
    "from nimrod.text.tokenizers import Tokenizer\n",
    "from nimrod.audio.embedding import EncoDec\n",
    "from torchaudio.datasets import LIBRITTS\n",
    "from nimrod.audio.utils import plot_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Waveform, Sample_rate, Original_text, Normalized_text, Speaker_ID, Chapter_ID, Utterance_ID)\n",
    "ds = LIBRITTS(\"../data/en\", 'test-clean')\n",
    "print(ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(ds[0][0], ds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LibriTTSDataModule(LightningDataModule):\n",
    "    def __init__(self,\n",
    "        target_dir=\"/data/en/libriTTS\", # where data will be saved / retrieved\n",
    "        dataset_parts=[\"dev-clean\", \"test-clean\"], # either full libritts or subset\n",
    "        output_dir=\"/home/syl20/slg/nimrod/recipes/libritts/data\", # where to save manifest\n",
    "        num_jobs=0 # num_jobs depending on number of cpus available\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "    def prepare_data(self,) -> None:\n",
    "        # takes a while to download from openslr mirror (~15 min each for test/dev-clean)\n",
    "        download_libritts(target_dir=self.hparams.target_dir, dataset_parts=self.hparams.dataset_parts)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        self.libri = prepare_libritts(corpus_dir=Path(self.hparams.target_dir) / \"LibriTTS\", dataset_parts=self.hparams.dataset_parts, output_dir=self.hparams.output_dir, num_jobs=self.hparams.num_jobs)\n",
    "        if stage == 'fit' or stage == None:\n",
    "            self.cuts_train = CutSet.from_manifests(**self.libri[\"dev-clean\"])\n",
    "            self.cuts_test = CutSet.from_manifests(**self.libri[\"test-clean\"])\n",
    "            self.tokenizer = TokenCollater(self.cuts_train)\n",
    "            self.tokenizer(self.cuts_test.subset(first=2))\n",
    "            # self.tokenizer.inverse(*self.tokenizer(self.cuts_test.subset(first=2)))\n",
    "        if stage == \"test\":\n",
    "            self.cuts_test = CutSet.from_manifests(**self.libri[\"test-clean\"])\n",
    "            self.tokenizer = TokenCollater(self.cuts_test)\n",
    "            self.tokenizer(self.cuts_test.subset(first=2))\n",
    "            # self.tokenizer.inverse(*self.tokenizer(self.cuts_test.subset(first=2)))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_sampler = BucketingSampler(self.cuts_train, max_duration=300, shuffle=True) #, bucket_method=\"equal_duration\")\n",
    "        return DataLoader(TTSDataset(self.tokenizer, sampling_rate=24000), sampler=train_sampler, batch_size=None, num_workers=self.hparams.num_jobs)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_sampler = BucketingSampler(self.cuts_test, max_duration=400, shuffle=False) #, bucket_method=\"equal_duration\")\n",
    "        return DataLoader(TTSDataset(self.tokenizer, sampling_rate=24000), sampler=test_sampler, batch_size=None, num_workers=self.hparams.num_jobs)\n",
    "\n",
    "    @property\n",
    "    def model_kwargs(self):\n",
    "        return {\n",
    "            \"odim\": len(self.tokenizer.idx2token),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_jobs=0 turns parallel computing off within jupyter notebook. Else it fails.\n",
    "dm = LibriTTSDataModule(\n",
    "    target_dir=\"../data/en\", \n",
    "    dataset_parts=\"test-clean\",\n",
    "    output_dir=\"../data/en/LibriTTS/test-clean\",\n",
    "    num_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip download and use local data folder\n",
    "# dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libri = prepare_libritts(\"../data/en/LibriTTS\", dataset_parts=\"test-clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dm.test_dataloader()\n",
    "batch = next(iter(test_dl))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['feats_pad'].shape)\n",
    "plt.imshow(batch['feats_pad'][3].transpose(0,1))\n",
    "print(batch['feats_lens'])\n",
    "print(batch['tokens_pad'][3], batch['tokens_lens'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = dm.tokenizer.inverse(batch['tokens_pad'], batch['tokens_lens'])\n",
    "print(original_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
