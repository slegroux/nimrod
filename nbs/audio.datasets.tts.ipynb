{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio TTS Datasets\n",
    "\n",
    "> TTS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp audio.datasets.tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, Fbank, FbankConfig\n",
    "from lhotse.dataset import BucketingSampler, OnTheFlyFeatures\n",
    "from lhotse.dataset.collation import TokenCollater\n",
    "from lhotse.dataset.vis import plot_batch\n",
    "from lhotse.recipes import download_librispeech, prepare_librispeech\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Optional, Union"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-To-Speech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lhotse-based Base Class\n",
    "https://github.com/Lightning-AI/lightning/issues/10358\n",
    "https://colab.research.google.com/drive/1HKSYPsWx_HoCdrnLpaPdYj5zwlPsM3NH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LhotseTTSDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                tokenizer=TokenCollater, # text tokenizer\n",
    "                extractor=OnTheFlyFeatures(Fbank(FbankConfig(num_mel_bins=80))) # feature extractor\n",
    "                ):\n",
    "        self.extractor = extractor\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> dict:\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"feats_lens\": feat_lens, \"tokens_pad\": tokens, \"tokens_lens\": token_lens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'cuts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tok \u001b[39m=\u001b[39m TokenCollater()\n\u001b[1;32m      2\u001b[0m ds \u001b[39m=\u001b[39m LhotseTTSDataset(tok)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'cuts'"
     ]
    }
   ],
   "source": [
    "# tok = TokenCollater()\n",
    "# ds = LhotseTTSDataset(tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class TTSDataset(Dataset):\n",
    "    def __init__(self,\n",
    "        tokenizer, # text tokenizer\n",
    "        num_mel_bins:int=80 # number of mel spectrogram bins\n",
    "        ):\n",
    "        self.extractor = OnTheFlyFeatures(Fbank(FbankConfig(num_mel_bins=num_mel_bins)))\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, cuts: CutSet) -> dict:\n",
    "        cuts = cuts.sort_by_duration()\n",
    "        feats, feat_lens = self.extractor(cuts)\n",
    "        tokens, token_lens = self.tokenizer(cuts)\n",
    "        return {\"feats_pad\": feats, \"feats_lens\": feat_lens, \"tokens_pad\": tokens, \"tokens_lens\": token_lens}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibriTTS DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syl20/anaconda3/envs/nimrod/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from lhotse.recipes import download_libritts, prepare_libritts\n",
    "from nimrod.text.tokenizers import Tokenizer\n",
    "from nimrod.audio.embedding import EncoDec\n",
    "from torchaudio.datasets import LIBRITTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0007, 0.0008, 0.0012,  ..., 0.0039, 0.0042, 0.0042]]), 24000, 'He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour-fattened sauce. Stuff it into you, his belly counselled him.', 'He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour fattened sauce. Stuff it into you, his belly counselled him.', 1089, 134686, '1089_134686_000001_000001')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(Waveform, Sample_rate, Original_text, Normalized_text, Speaker_ID, Chapter_ID, Utterance_ID)\n",
    "ds = LIBRITTS(\"../data/en\", 'test-clean')\n",
    "print(ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LibriTTSDataModule(LightningDataModule):\n",
    "    def __init__(self,\n",
    "        target_dir=\"/data/en/libriTTS\", # where data will be saved / retrieved\n",
    "        dataset_parts=[\"dev-clean\", \"test-clean\"], # either full libritts or subset\n",
    "        output_dir=\"/home/syl20/slg/nimrod/recipes/libritts/data\", # where to save manifest\n",
    "        num_jobs=1 # num_jobs depending on number of cpus available\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "    def prepare_data(self,) -> None:\n",
    "        # takes a while to download from openslr mirror (~15 min each for test/dev-clean)\n",
    "        download_libritts(target_dir=self.hparams.target_dir, dataset_parts=self.hparams.dataset_parts)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        self.libri = prepare_libritts(corpus_dir=Path(self.hparams.target_dir) / \"LibriTTS\", output_dir=self.hparams.output_dir, num_jobs=self.hparams.num_jobs)\n",
    "        if stage == 'fit' or stage == None:\n",
    "            self.cuts_train = CutSet.from_manifests(**self.libri[\"dev-clean\"])\n",
    "            self.cuts_test = CutSet.from_manifests(**self.libri[\"test-clean\"])\n",
    "            self.tokenizer = TokenCollater(self.cuts_train)\n",
    "            self.tokenizer(self.cuts_test.subset(first=2))\n",
    "            self.tokenizer.inverse(*self.tokenizer(self.cuts_test.subset(first=2)))\n",
    "        if stage == \"test\":\n",
    "            self.cuts_test = CutSet.from_manifests(**self.libri[\"test-clean\"])\n",
    "            self.tokenizer = TokenCollater(self.cuts_test)\n",
    "            self.tokenizer(self.cuts_test.subset(first=2))\n",
    "            self.tokenizer.inverse(*self.tokenizer(self.cuts_test.subset(first=2)))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_sampler = BucketingSampler(self.cuts_train, max_duration=300, shuffle=True, bucket_method=\"equal_duration\")\n",
    "        return DataLoader(TTSDataset(self.tokenizer), sampler=train_sampler, batch_size=None, num_workers=100)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_sampler = BucketingSampler(self.cuts_test, max_duration=400, shuffle=False, bucket_method=\"equal_duration\")\n",
    "        return DataLoader(TTSDataset(self.tokenizer), sampler=test_sampler, batch_size=None, num_workers=2)\n",
    "\n",
    "    @property\n",
    "    def model_kwargs(self):\n",
    "        return {\n",
    "            \"odim\": len(self.tokenizer.idx2token),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LibriTTSDataModule(\n",
    "    target_dir=\"../data/en\", \n",
    "    dataset_parts=\"test-clean\",\n",
    "    output_dir=\"../data/en/LibriTTS/test-clean\",\n",
    "    num_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip download and use local data folder\n",
    "# dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]00:00<?, ?it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Scanning audio files (*.wav): 95it [00:00, 5596.18it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]00:00<00:00, 46.46it/s]\n",
      "Scanning audio files (*.wav): 0it [00:00, ?it/s]\n",
      "Preparing LibriTTS parts: 100%|██████████| 7/7 [00:00<00:00, 53.83it/s]\n"
     ]
    }
   ],
   "source": [
    "dm.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
