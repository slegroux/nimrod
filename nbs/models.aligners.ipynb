{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligners\n",
    "\n",
    "> Collection of Aligner models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.aligners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wav2Vec2.0 Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nimrod.text.normalizers import TTSTextNormalizer\n",
    "from nimrod.text.normalizers import Punctuation\n",
    "import torch\n",
    "import torchaudio\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass\n",
    "class Segment:\n",
    "    label: str\n",
    "    start: int\n",
    "    end: int\n",
    "    score: float\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n",
    "\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.end - self.start\n",
    "\n",
    "@dataclass\n",
    "class Point:\n",
    "    token_index: int\n",
    "    time_index: int\n",
    "    score: float\n",
    "\n",
    "\n",
    "class AlignerWAV2VEC2():\n",
    "    def __init__(self, text_normalizer, device='cuda'):\n",
    "        self._asr = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "        self.model = self._asr.get_model().to(device)\n",
    "        self.labels = self._asr.get_labels()\n",
    "        self._dictionary = {c: i for i, c in enumerate(self.labels)}\n",
    "        self.device = device\n",
    "        self.text_normalizer = text_normalizer\n",
    "    \n",
    "    @property\n",
    "    def dictionary(self):\n",
    "        return self._dictionary\n",
    "\n",
    "    @property\n",
    "    def asr(self):\n",
    "        return self._asr\n",
    "\n",
    "    def get_emission(self, waveform):\n",
    "        with torch.inference_mode():\n",
    "            # waveform, _ = torchaudio.load(speech_file)\n",
    "            emissions, _ = self.model(waveform.to(self.device))\n",
    "            emissions = torch.log_softmax(emissions, dim=-1)\n",
    "        emission = emissions[0].cpu().detach()\n",
    "        return emission, waveform\n",
    "\n",
    "    def get_trellis(self, emission, tokens, blank_id=0):\n",
    "        num_frame = emission.size(0)\n",
    "        num_tokens = len(tokens)\n",
    "        trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
    "        trellis[0, 0] = 0\n",
    "        trellis[1:, 0] = torch.cumsum(emission[:, 0], 0)\n",
    "        trellis[0, -num_tokens:] = -float(\"inf\")\n",
    "        trellis[-num_tokens:, 0] = float(\"inf\")\n",
    "\n",
    "        for t in range(num_frame):\n",
    "            trellis[t + 1, 1:] = torch.maximum(\n",
    "                # Score for staying at the same token\n",
    "                trellis[t, 1:] + emission[t, blank_id],\n",
    "                # Score for changing to the next token\n",
    "                trellis[t, :-1] + emission[t, tokens],\n",
    "            )\n",
    "        return trellis\n",
    "\n",
    "    def backtrack(self, trellis, emission, tokens, blank_id=0):\n",
    "        j = trellis.size(1) - 1\n",
    "        t_start = torch.argmax(trellis[:, j]).item()\n",
    "\n",
    "        path = []\n",
    "        for t in range(t_start, 0, -1):\n",
    "            stayed = trellis[t - 1, j] + emission[t - 1, blank_id]\n",
    "            changed = trellis[t - 1, j - 1] + emission[t - 1, tokens[j - 1]]\n",
    "            prob = emission[t - 1, tokens[j - 1] if changed > stayed else 0].exp().item()\n",
    "            path.append(Point(j - 1, t - 1, prob))\n",
    "            if changed > stayed:\n",
    "                j -= 1\n",
    "                if j == 0:\n",
    "                    break\n",
    "        else:\n",
    "            raise ValueError(\"Failed to align\")\n",
    "        return path[::-1]\n",
    "\n",
    "    def merge_repeats(self, path, transcript):\n",
    "        i1, i2 = 0, 0\n",
    "        segments = []\n",
    "        while i1 < len(path):\n",
    "            while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
    "                i2 += 1\n",
    "            score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
    "            segments.append(\n",
    "                Segment(\n",
    "                    transcript[path[i1].token_index],\n",
    "                    path[i1].time_index,\n",
    "                    path[i2 - 1].time_index + 1,\n",
    "                    score,\n",
    "                )\n",
    "            )\n",
    "            i1 = i2\n",
    "        return segments\n",
    "\n",
    "    def merge_words(self, segments, separator=\"|\"):\n",
    "        words = []\n",
    "        i1, i2 = 0, 0\n",
    "        while i1 < len(segments):\n",
    "            if i2 >= len(segments) or segments[i2].label == separator:\n",
    "                if i1 != i2:\n",
    "                    segs = segments[i1:i2]\n",
    "                    word = \"\".join([seg.label for seg in segs])\n",
    "                    score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
    "                    words.append(Segment(word, segments[i1].start, segments[i2 - 1].end, score))\n",
    "                i1 = i2 + 1\n",
    "                i2 = i1\n",
    "            else:\n",
    "                i2 += 1\n",
    "        return words\n",
    "    \n",
    "    def text_processing(self, text:str):\n",
    "        cleaned = self.text_normalizer(text)\n",
    "        punc = Punctuation()\n",
    "        depuncted = punc.strip(cleaned)\n",
    "        return depuncted.upper().replace(\" \", \"|\")\n",
    "\n",
    "    def get_alignments(self, speech_waveform, transcript):\n",
    "        # with open(transcript_file, \"r\") as f:\n",
    "        #     transcript = f.read()\n",
    "        transcript = self.text_processing(transcript)\n",
    "        emission, waveform = self.get_emission(speech_waveform)\n",
    "        tokens = [self.dictionary[c] for c in transcript]\n",
    "        trellis = self.get_trellis(emission, tokens)\n",
    "        path = self.backtrack(trellis, emission, tokens)\n",
    "        segments = self.merge_repeats(path, transcript)\n",
    "        word_segments = self.merge_words(segments)\n",
    "        alignments = []\n",
    "        for i in range(len(word_segments)):\n",
    "            ratio = waveform.size(1) / (trellis.size(0) - 1)\n",
    "            word = word_segments[i]\n",
    "            x0 = int(ratio * word.start)\n",
    "            x1 = int(ratio * word.end)\n",
    "            start = x0 / self.asr.sample_rate\n",
    "            end = x1 / self.asr.sample_rate\n",
    "            alignments.append(\n",
    "                {\"word\": word.label, \"score\": word.score, \"start_time\": start, \"end_time\": end}\n",
    "            )\n",
    "            print(f\"Word: {word.label}, Confidence: {word.score:.2f}, Start:{x0 / self.asr.sample_rate:.3f},  End: {x1 / self.asr.sample_rate:.3f} sec\")\n",
    "        return(alignments)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: HE, Confidence: 1.00, Start:0.121,  End: 0.242 sec\n",
      "Word: TRIED, Confidence: 0.91, Start:0.323,  End: 0.625 sec\n",
      "Word: TO, Confidence: 1.00, Start:0.686,  End: 0.787 sec\n",
      "Word: THINK, Confidence: 0.93, Start:0.948,  End: 1.311 sec\n",
      "Word: HOW, Confidence: 0.91, Start:1.473,  End: 1.675 sec\n",
      "Word: IT, Confidence: 0.71, Start:1.755,  End: 1.836 sec\n",
      "Word: COULD, Confidence: 0.75, Start:1.917,  End: 2.118 sec\n",
      "Word: BE, Confidence: 1.00, Start:2.239,  End: 2.461 sec\n"
     ]
    }
   ],
   "source": [
    "text_normalizer = TTSTextNormalizer().english_cleaners\n",
    "aligner = AlignerWAV2VEC2(text_normalizer, device='cpu') # for CI on cpu\n",
    "wav_path = \"../data/en/LibriTTS/test-clean/1089/134686/1089_134686_000015_000001.wav\"\n",
    "txt_path = \"../data/en/LibriTTS/test-clean/1089/134686/1089_134686_000015_000001.original.txt\"\n",
    "wav, sr = torchaudio.load(wav_path)\n",
    "with open(txt_path, 'r') as f: txt = f.read()\n",
    "alignments = aligner.get_alignments(wav, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
