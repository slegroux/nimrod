# Nimrod

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

[![python](https://img.shields.io/badge/-Python_3.7_%7C_3.8_%7C_3.9_%7C_3.10-blue?logo=python&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![pytorch](https://img.shields.io/badge/PyTorch_1.10+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)
[![hydra](https://img.shields.io/badge/Config-Hydra_1.3-89b8cd)](https://hydra.cc/)
[![pre-commit](https://img.shields.io/badge/Pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white.png)](https://github.com/pre-commit/pre-commit)

## Description

This is a repo with minimal tooling, modules, models and recipes to get
easily get started with deep learning training and experimentation with
an emphasis on speech, audio and language modeling.

## Install

you need python \<3.12

``` sh
pip install slg-nimrod
```

## Usage

Check recipes in `recipes/` folder. For instance:

``` bash
git clone https://github.com/slegroux/nimrod.git
cd nimrod/recipes/images/mnist
python train.py datamodule.num_workers=10 trainer.max_epochs=20 trainer.accelerator='gpu'
head conf/train.yaml
```

All the parameters of the experiment are editable and read from a .yaml
file which details:

- data and logging directory paths
- data module with data source path and batching parameters
- model architecture
- trainer with hardware acceleration and number of epochs
- callbacks for early stopping and automatic logging to Wandb

## Docker

You might want to use docker containers for reproductible development
environment or run your project in the cloud

``` bash
make container
docker pull slegroux/nimrod
docker run -it --rm -p 8888:8888 slegroux/nimrod /bin/bash
```

You can also use docker-compose to define services and volumes

``` bash
cd .devcontainer
docker-compose up
docker-compose down
```

## Develop

``` bash
pip install -e .
```

## Authors

2023 Sylvain Le Groux <sylvain.legroux@gmail.com>
